{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "from xgbsurv.datasets import (load_metabric, load_flchain, load_rgbsg, load_support, load_tcga)\n",
    "from xgbsurv.models.utils import sort_X_y_pandas, transform_back, transform\n",
    "from xgbsurv.models.breslow_final import get_cumulative_hazard_function_breslow, breslow_estimator_loop\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.decomposition import PCA\n",
    "from loss_functions_pytorch import BreslowLoss, breslow_likelihood_torch\n",
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import EarlyStopping, Callback, LRScheduler\n",
    "import skorch.callbacks\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import check_cv\n",
    "from numbers import Number\n",
    "import torch.utils.data\n",
    "from skorch.utils import flatten\n",
    "from skorch.utils import is_pandas_ndframe\n",
    "from skorch.utils import check_indexing\n",
    "from skorch.utils import multi_indexing\n",
    "from skorch.utils import to_numpy\n",
    "from skorch.dataset import get_len\n",
    "from skorch.dataset import ValidSplit\n",
    "from pycox.evaluation import EvalSurv\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform\n",
    "import random\n",
    "import os\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 50\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "\n",
    "# set seed for scipy\n",
    "np.random.seed(rand_state)\n",
    "\n",
    "param_grid_breslow = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    #'estimator__lr': scloguniform(0.001,0.01), # scheduler unten einbauen\n",
    "    # use callback instead\n",
    "    'estimator__lr':[0.01],\n",
    "    'estimator__max_epochs':  scrandint(150,250) # corresponds to num_rounds\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=rand_state):\n",
    "    \"\"\"Sets all seeds within torch and adjacent libraries.\n",
    "\n",
    "    Args:\n",
    "        seed: Random seed to be used by the seeding functions.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "\n",
    "class FixSeed(Callback):\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "    def initialize(self):\n",
    "        seed_torch(self.seed)\n",
    "        return super().initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Scorer\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "\n",
    "        #y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, np.ndarray):\n",
    "            y_pred = torch.from_numpy(y_pred)\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, pd.Series):\n",
    "            y_pred = torch.tensor(y_pred.values)\n",
    "        if isinstance(y_true, pd.Series):\n",
    "            y_true = torch.tensor(y_true.values)\n",
    "        score = breslow_likelihood_torch(y_true, y_pred).to(torch.float32)\n",
    "        return score.numpy()\n",
    "\n",
    "scoring_function = make_scorer(custom_scoring_function, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, n_layers, input_units, num_nodes, dropout, out_features):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.in_features = input_units\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dropout = dropout\n",
    "        self.out_features = out_features\n",
    "        model = []\n",
    "        # first layer\n",
    "        model.append(torch.nn.Linear(input_units, num_nodes))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout))\n",
    "        model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            model.append(torch.nn.Linear(num_nodes, num_nodes))\n",
    "            #init.kaiming_normal_(model[-1].weight, nonlinearity='relu')\n",
    "            model.append(torch.nn.ReLU())\n",
    "            model.append(torch.nn.Dropout(dropout))\n",
    "            model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        # output layer\n",
    "        model.append(torch.nn.Linear(num_nodes, out_features))\n",
    "    \n",
    "        self.layers = nn.Sequential(*model)\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     if isinstance(layer, nn.Linear):\n",
    "        #         #nn.init.uniform_(layer.weight, a=-0.5, b=0.5)\n",
    "        #         nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.to(torch.float32)\n",
    "        res = self.layers(X)\n",
    "        #print(res)\n",
    "        return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = super().transform(X, y)\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        return X_transformed.astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define stratified inner k-fold cross-validation\n",
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=2, shuffle=True, random_state=rand_state):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        print('split', X.dtypes)\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = super().transform(X, y)\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "class CustomValidSplit():\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv=5,\n",
    "            stratified=False,\n",
    "            random_state=None,\n",
    "    ):\n",
    "        self.stratified = stratified\n",
    "        self.random_state = random_state\n",
    "\n",
    "        if isinstance(cv, Number) and (cv <= 0):\n",
    "            raise ValueError(\"Numbers less than 0 are not allowed for cv \"\n",
    "                             \"but ValidSplit got {}\".format(cv))\n",
    "\n",
    "        if not self._is_float(cv) and random_state is not None:\n",
    "            raise ValueError(\n",
    "                \"Setting a random_state has no effect since cv is not a float. \"\n",
    "                \"You should leave random_state to its default (None), or set cv \"\n",
    "                \"to a float value.\",\n",
    "            )\n",
    "\n",
    "        self.cv = cv\n",
    "\n",
    "    def _is_stratified(self, cv):\n",
    "        return isinstance(cv, (StratifiedKFold, StratifiedShuffleSplit))\n",
    "\n",
    "    def _is_float(self, x):\n",
    "        if not isinstance(x, Number):\n",
    "            return False\n",
    "        return not float(x).is_integer()\n",
    "\n",
    "    def _check_cv_float(self):\n",
    "        cv_cls = StratifiedShuffleSplit if self.stratified else ShuffleSplit\n",
    "        return cv_cls(test_size=self.cv, random_state=self.random_state)\n",
    "\n",
    "    def _check_cv_non_float(self, y):\n",
    "        return check_cv(\n",
    "            self.cv,\n",
    "            y=y,\n",
    "            classifier=self.stratified,\n",
    "        )\n",
    "\n",
    "    def check_cv(self, y):\n",
    "        \"\"\"Resolve which cross validation strategy is used.\"\"\"\n",
    "        y_arr = None\n",
    "        if self.stratified:\n",
    "            # Try to convert y to numpy for sklearn's check_cv; if conversion\n",
    "            # doesn't work, still try.\n",
    "            try:\n",
    "                y_arr = to_numpy(y)\n",
    "            except (AttributeError, TypeError):\n",
    "                y_arr = y\n",
    "\n",
    "        if self._is_float(self.cv):\n",
    "            return self._check_cv_float()\n",
    "        return self._check_cv_non_float(y_arr)\n",
    "\n",
    "    def _is_regular(self, x):\n",
    "        return (x is None) or isinstance(x, np.ndarray) or is_pandas_ndframe(x)\n",
    "\n",
    "    def __call__(self, dataset, y=None, groups=None):\n",
    "        # key change here\n",
    "        y = np.sign(y)\n",
    "        bad_y_error = ValueError(\n",
    "            \"Stratified CV requires explicitly passing a suitable y.\")\n",
    "        if (y is None) and self.stratified:\n",
    "            raise bad_y_error\n",
    "\n",
    "        cv = self.check_cv(y)\n",
    "        if self.stratified and not self._is_stratified(cv):\n",
    "            raise bad_y_error\n",
    "\n",
    "        # pylint: disable=invalid-name\n",
    "        len_dataset = get_len(dataset)\n",
    "        if y is not None:\n",
    "            len_y = get_len(y)\n",
    "            if len_dataset != len_y:\n",
    "                raise ValueError(\"Cannot perform a CV split if dataset and y \"\n",
    "                                 \"have different lengths.\")\n",
    "\n",
    "        args = (np.arange(len_dataset),)\n",
    "        if self._is_stratified(cv):\n",
    "            args = args + (to_numpy(y),)\n",
    "\n",
    "        idx_train, idx_valid = next(iter(cv.split(*args, groups=groups)))\n",
    "        dataset_train = torch.utils.data.Subset(dataset, idx_train)\n",
    "        dataset_valid = torch.utils.data.Subset(dataset, idx_valid)\n",
    "        return dataset_train, dataset_valid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Shape Setter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputShapeSetter(skorch.callbacks.Callback):\n",
    "    def on_train_begin(self, net, X, y):\n",
    "        net.set_params(module__input_units=X.shape[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "        model = 'skorch_breslow_'\n",
    "        dataset_name = filename.split('_')[0]\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                        'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        ct = make_column_transformer(\n",
    "                (StandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "                #(OneHotEncoder( handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['category', 'object'])),#sparse_output=False,\n",
    "                remainder='passthrough')\n",
    "\n",
    "        pipe = Pipeline([('scaler',ct),\n",
    "                        ('estimator', net)])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_breslow, scoring = scoring_function, n_jobs=-1, \n",
    "                                    n_iter=n_iter, refit=True, random_state=rand_state)\n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "                X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "                #print(X_train.shape, type(X_train))\n",
    "                #print(y_train.shape, type(y_train))\n",
    "                #print(X_test.shape, type(X_test))\n",
    "                #print(y_test.shape, type(y_test))\n",
    "                \n",
    "                # save splits and data\n",
    "                savetxt('splits/'+model+'train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/'+model+'test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                #savetxt('splits/X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                #savetxt('splits/X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                #savetxt('splits/y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                #savetxt('splits/y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "\n",
    "                rs.fit(X_train, y_train)\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "\n",
    "                savetxt('predictions/'+model+'best_preds_train_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "                savetxt('predictions/'+model+'best_preds_test_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "\n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "                try:\n",
    "                    cum_hazard_train = get_cumulative_hazard_function_breslow(\n",
    "                            X_train.values, X_train.values, y_train.values, y_train.values,\n",
    "                            best_preds_train.reshape(-1), best_preds_train.reshape(-1)\n",
    "                            )\n",
    "\n",
    "                    df_survival_train = np.exp(-cum_hazard_train)\n",
    "                    durations_train, events_train = transform_back(y_train.values)\n",
    "                    time_grid_train = np.linspace(durations_train.min(), durations_train.max(), 100)\n",
    "                    ev = EvalSurv(df_survival_train, durations_train, events_train, censor_surv='km')\n",
    "                    print('Concordance Index',ev.concordance_td('antolini'))\n",
    "                    print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_train))\n",
    "                    cindex_score_train = ev.concordance_td('antolini')\n",
    "                    ibs_score_train = ev.integrated_brier_score(time_grid_train)\n",
    "\n",
    "                    outer_scores['cindex_train_'+dataset_name] += [cindex_score_train]\n",
    "                    outer_scores['ibs_train_'+dataset_name] += [ibs_score_train]\n",
    "\n",
    "                except:\n",
    "                    outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "                    outer_scores['ibs_train_'+dataset_name] += [np.nan]\n",
    "                    \n",
    "                try:\n",
    "                    cum_hazard_test = get_cumulative_hazard_function_breslow(\n",
    "                            X_train.values, X_test.values, y_train.values, y_test.values,\n",
    "                            best_preds_train.reshape(-1), best_preds_test.reshape(-1)\n",
    "                            )\n",
    "                    df_survival_test = np.exp(-cum_hazard_test)\n",
    "                    durations_test, events_test = transform_back(y_test.values)\n",
    "                    time_grid_test = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "                    ev = EvalSurv(df_survival_test, durations_test, events_test, censor_surv='km')\n",
    "                    print('Concordance Index',ev.concordance_td('antolini'))\n",
    "                    print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_test))\n",
    "                    cindex_score_test = ev.concordance_td('antolini')\n",
    "                    ibs_score_test = ev.integrated_brier_score(time_grid_test)\n",
    "\n",
    "                    outer_scores['cindex_test_'+dataset_name] += [cindex_score_test]\n",
    "                    outer_scores['ibs_test_'+dataset_name] += [ibs_score_test]\n",
    "                except: \n",
    "                    outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "                    outer_scores['ibs_test_'+dataset_name] += [np.nan]\n",
    "            \n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "        df_metrics.to_csv('metrics/'+model+'metric_summary_'+'_'+filename, index=False)\n",
    "        \n",
    "        # cindex\n",
    "        df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                              'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "                                              'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "                                              'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "                                              'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "        # IBS\n",
    "        df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                              'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "                                              'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "                                              'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "                                              'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "\n",
    "        return df_agg_metrics_cindex, df_agg_metrics_ibs, best_model, best_params, outer_scores, best_preds_train, best_preds_test #, X_train, X_test, y_train, y_test\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split age                 float32\n",
      "sex                   uint8\n",
      "n_comorbidities     float32\n",
      "diabetes              uint8\n",
      "dementia              uint8\n",
      "blood_pressure      float32\n",
      "heart_rate          float32\n",
      "respiration_rate    float32\n",
      "temperature         float32\n",
      "white_blood_cell    float32\n",
      "serum_sodium        float32\n",
      "serum_creatinine    float32\n",
      "cancer_0.0            uint8\n",
      "cancer_1.0            uint8\n",
      "cancer_2.0            uint8\n",
      "race_0.0              uint8\n",
      "race_1.0              uint8\n",
      "race_2.0              uint8\n",
      "race_3.0              uint8\n",
      "race_4.0              uint8\n",
      "race_5.0              uint8\n",
      "race_6.0              uint8\n",
      "race_7.0              uint8\n",
      "race_8.0              uint8\n",
      "race_9.0              uint8\n",
      "dtype: object\n",
      "Concordance Index 0.6092034454057412\n",
      "Integrated Brier Score: 0.19817574921421613\n",
      "Concordance Index 0.5982227630068273\n",
      "Integrated Brier Score: 0.20341964201203153\n",
      "Concordance Index 0.5979460445204812\n",
      "Integrated Brier Score: 0.19715680167865088\n",
      "Concordance Index 0.5970365943119679\n",
      "Integrated Brier Score: 0.19418215263414756\n",
      "Concordance Index 0.6105236647380139\n",
      "Integrated Brier Score: 0.19151808682374516\n",
      "Concordance Index 0.6051037418400119\n",
      "Integrated Brier Score: 0.19715246918379384\n",
      "Concordance Index 0.6082853607547383\n",
      "Integrated Brier Score: 0.19412629827367217\n",
      "Concordance Index 0.582066211725533\n",
      "Integrated Brier Score: 0.19904530548246605\n",
      "Concordance Index 0.608479969753128\n",
      "Integrated Brier Score: 0.19428734456125119\n",
      "Concordance Index 0.5880969670545918\n",
      "Integrated Brier Score: 0.20046359426780114\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [  load_support] #load_metabric,  load_flchain,#, load_flchain, load_rgbsg, load_support, load_tcga]load_rgbsg,\n",
    "data_set_fns_str = [ 'load_support'] #'load_metabric', 'load_flchain','load_rgbsg', \n",
    "one_hot_dict = { 'load_support':['cancer','race'],}#'load_flchain': ['mgus'], 'load_rgbsg':['grade'],\n",
    "agg_metrics_cindex = []\n",
    "agg_metrics_ibs = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    #print(data_set_fns_str[idx])\n",
    "    if data_set_fns_str[idx] in one_hot_dict.keys():\n",
    "        X = pd.get_dummies(X, columns=one_hot_dict[data_set_fns_str[idx]])\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    \n",
    "    net = NeuralNet(\n",
    "        SurvivalModel, \n",
    "        #module__n_layers = 1,\n",
    "        module__input_units = X.shape[1],\n",
    "        #module__num_nodes = 32,\n",
    "        #module__dropout = 0.1, # these could also be removed\n",
    "        module__out_features = 1,\n",
    "        # for split sizes when result size = 1\n",
    "        iterator_train__drop_last=True,\n",
    "        #iterator_valid__drop_last=True,\n",
    "        criterion=BreslowLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer__weight_decay = 0.4,\n",
    "        batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "        callbacks=[\n",
    "            (\n",
    "                \"sched\",\n",
    "                LRScheduler(\n",
    "                    torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=5,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"es\",\n",
    "                EarlyStopping(\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=early_stopping_rounds,\n",
    "                    load_best=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"seed\", FixSeed(seed=42)),\n",
    "            #(\"Input Shape Setter\",InputShapeSetter())\n",
    "        ],\n",
    "        train_split = CustomValidSplit(0.2, stratified=True, random_state=rand_state), \n",
    "        verbose=0\n",
    "    )\n",
    "    df_agg_metrics_cindex, df_agg_metrics_ibs, best_model,params, outer_scores, best_preds_train, best_preds_test = train_eval(X, y, net, n_iter, data.filename)\n",
    "    agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "    agg_metrics_ibs.append(df_agg_metrics_ibs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cindex_train_mean</th>\n",
       "      <th>cindex_train_std</th>\n",
       "      <th>cindex_test_mean</th>\n",
       "      <th>cindex_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>0.6069</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  cindex_train_mean  cindex_train_std  cindex_test_mean  \\\n",
       "0  SUPPORT             0.6069            0.0051            0.5941   \n",
       "\n",
       "   cindex_test_std  \n",
       "0            0.009  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_breslow_1_cindex = pd.concat([df for df in agg_metrics_cindex]).round(4)\n",
    "df_final_breslow_1_cindex.to_csv('metrics/final_deep_learning_breslow_1_cindex.csv', index=False)\n",
    "df_final_breslow_1_cindex.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_deep_learning_breslow_1_cindex.csv', index=False)  #\n",
    "df_final_breslow_1_cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ibs_train_mean</th>\n",
       "      <th>ibs_train_std</th>\n",
       "      <th>ibs_test_mean</th>\n",
       "      <th>ibs_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  ibs_train_mean  ibs_train_std  ibs_test_mean  ibs_test_std\n",
       "0  SUPPORT          0.1951         0.0027         0.1989        0.0035"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_breslow_1_ibs = pd.concat([df for df in agg_metrics_ibs]).round(4)\n",
    "df_final_breslow_1_ibs.to_csv('metrics/final_deep_learning_breslow_1_ibs.csv', index=False)\n",
    "df_final_breslow_1_ibs.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_deep_learning_breslow_1_ibs.csv', index=False) \n",
    "df_final_breslow_1_ibs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_breslow_tcga = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    #'estimator__lr': scloguniform(0.001,0.01), # scheduler unten einbauen\n",
    "    # use callback instead\n",
    "    'estimator__lr':[0.01],\n",
    "    'estimator__max_epochs':  scrandint(150,250), # corresponds to num_rounds\n",
    "    #'pca__n_components': [8, 16, 32, 64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "        model = 'skorch_breslow_tcga_'\n",
    "        dataset_name = filename.split('_')[0]\n",
    "\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                        'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        ct = make_column_transformer(\n",
    "                (StandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "                #(OneHotEncoder(sparse_output=False), make_column_selector(dtype_include=['category', 'object'])),\n",
    "                remainder='drop')\n",
    "        pipe = Pipeline([('scaler',ct),\n",
    "                         #('pca', PCA()),\n",
    "                        ('estimator', net)])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_breslow_tcga, scoring = scoring_function, n_jobs=-1, \n",
    "                                    n_iter=n_iter, refit=True, random_state=rand_state)\n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "                X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "                # print(X_train.shape, type(X_train))\n",
    "                # print(y_train.shape, type(y_train))\n",
    "                # print(X_test.shape, type(X_test))\n",
    "                # print(y_test.shape, type(y_test))\n",
    "                # save splits and data\n",
    "                savetxt('splits/'+model+'train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/'+model+'test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                #savetxt('splits/X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                #savetxt('splits/X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                #savetxt('splits/y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                #savetxt('splits/y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                rs.fit(X_train, y_train)\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "                savetxt('predictions/'+model+'best_preds_train_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "                savetxt('predictions/'+model+'best_preds_test_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "\n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "                try:\n",
    "                    cum_hazard_train = get_cumulative_hazard_function_breslow(\n",
    "                            X_train.values, X_train.values, y_train.values, y_train.values,\n",
    "                            best_preds_train.reshape(-1), best_preds_train.reshape(-1)\n",
    "                            )\n",
    "\n",
    "                    df_survival_train = np.exp(-cum_hazard_train)\n",
    "                    durations_train, events_train = transform_back(y_train.values)\n",
    "                    time_grid_train = np.linspace(durations_train.min(), durations_train.max(), 100)\n",
    "                    ev = EvalSurv(df_survival_train, durations_train, events_train, censor_surv='km')\n",
    "                    print('Concordance Index',ev.concordance_td('antolini'))\n",
    "                    print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_train))\n",
    "                    cindex_score_train = ev.concordance_td('antolini')\n",
    "                    ibs_score_train = ev.integrated_brier_score(time_grid_train)\n",
    "\n",
    "                    outer_scores['cindex_train_'+dataset_name] += [cindex_score_train]\n",
    "                    outer_scores['ibs_train_'+dataset_name] += [ibs_score_train]\n",
    "\n",
    "                except:\n",
    "                    outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "                    outer_scores['ibs_train_'+dataset_name] += [np.nan]\n",
    "                    \n",
    "                try:\n",
    "                    cum_hazard_test = get_cumulative_hazard_function_breslow(\n",
    "                            X_train.values, X_test.values, y_train.values, y_test.values,\n",
    "                            best_preds_train.reshape(-1), best_preds_test.reshape(-1)\n",
    "                            )\n",
    "                    df_survival_test = np.exp(-cum_hazard_test)\n",
    "                    durations_test, events_test = transform_back(y_test.values)\n",
    "                    print('durations',durations_test.min(), durations_test.max())\n",
    "                    time_grid_test = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "                    ev = EvalSurv(df_survival_test, durations_test, events_test, censor_surv='km')\n",
    "                    print('Concordance Index',ev.concordance_td('antolini'))\n",
    "                    print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_test))\n",
    "                    cindex_score_test = ev.concordance_td('antolini')\n",
    "                    ibs_score_test = ev.integrated_brier_score(time_grid_test)\n",
    "\n",
    "                    outer_scores['cindex_test_'+dataset_name] += [cindex_score_test]\n",
    "                    outer_scores['ibs_test_'+dataset_name] += [ibs_score_test]\n",
    "                except: \n",
    "                    outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "                    outer_scores['ibs_test_'+dataset_name] += [np.nan]\n",
    "            \n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "        df_metrics.to_csv('metrics/'+model+'metric_summary_'+'_'+filename, index=False)\n",
    "        # cindex\n",
    "        df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                              'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "                                              'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "                                              'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "                                              'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "        # IBS\n",
    "        df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                              'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "                                              'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "                                              'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "                                              'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "        return df_agg_metrics_cindex, df_agg_metrics_ibs,best_model, best_params, outer_scores, best_preds_train, best_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n",
      "Concordance Index 0.6865297392971718\n",
      "Integrated Brier Score: 0.24073819193104293\n",
      "durations 17.0 4343.0\n",
      "Concordance Index 0.6027624309392265\n",
      "Integrated Brier Score: 0.22048646125462354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.7150806900389538\n",
      "Integrated Brier Score: 0.17974245817811713\n",
      "durations 15.0 3817.0\n",
      "Concordance Index 0.5548880393227744\n",
      "Integrated Brier Score: 0.28346270300502047\n",
      "Concordance Index 0.6818708369533739\n",
      "Integrated Brier Score: 0.20533589638426658\n",
      "durations 59.0 5050.0\n",
      "Concordance Index 0.5878136200716846\n",
      "Integrated Brier Score: 0.2534493172889495\n",
      "Concordance Index 0.6872096850883289\n",
      "Integrated Brier Score: 0.21303965768824187\n",
      "durations 55.0 5041.0\n",
      "Concordance Index 0.6025200458190149\n",
      "Integrated Brier Score: 0.3033755215942722\n",
      "Concordance Index 0.7270485450574227\n",
      "Integrated Brier Score: 0.18766475149697115\n",
      "durations 13.0 3432.0\n",
      "Concordance Index 0.5656108597285068\n",
      "Integrated Brier Score: 0.25119327956884474\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n",
      "Concordance Index 0.5461619842482661\n",
      "Integrated Brier Score: 0.18355656322680225\n",
      "durations 5.0 8605.0\n",
      "Concordance Index 0.4383680555555556\n",
      "Integrated Brier Score: 0.20781355816676114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5238727734161903\n",
      "Integrated Brier Score: 0.1880374423318559\n",
      "durations 5.0 8008.0\n",
      "Concordance Index 0.5103954341622503\n",
      "Integrated Brier Score: 0.18859614237535777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5251194721393397\n",
      "Integrated Brier Score: 0.18360544454616307\n",
      "durations 5.0 8556.0\n",
      "Concordance Index 0.5085820895522388\n",
      "Integrated Brier Score: 0.20030729613019166\n",
      "Concordance Index 0.5422024030719683\n",
      "Integrated Brier Score: 0.20947900948657192\n",
      "durations 1.0 7106.0\n",
      "Concordance Index 0.43394911118856744\n",
      "Integrated Brier Score: 0.19080975683857737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5116346223259619\n",
      "Integrated Brier Score: 0.20385366190870347\n",
      "durations 1.0 8391.0\n",
      "Concordance Index 0.6072684642438453\n",
      "Integrated Brier Score: 0.21383338502535842\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n",
      "Concordance Index 0.7116390732226576\n",
      "Integrated Brier Score: 0.3912594593229989\n",
      "durations 23.0 4760.0\n",
      "Concordance Index 0.564308121296619\n",
      "Integrated Brier Score: 0.5599550714892444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.6232340844062947\n",
      "Integrated Brier Score: 0.19154693999937855\n",
      "durations 14.0 4282.0\n",
      "Concordance Index 0.5905044510385756\n",
      "Integrated Brier Score: 0.210604136656739\n",
      "Concordance Index 0.5639498711225669\n",
      "Integrated Brier Score: 0.18033452932493985\n",
      "durations 11.0 6417.0\n",
      "Concordance Index 0.5789473684210527\n",
      "Integrated Brier Score: 0.2050914092668158\n",
      "Concordance Index 0.5611388384754991\n",
      "Integrated Brier Score: 0.16962283056859345\n",
      "durations 2.0 5480.0\n",
      "Concordance Index 0.5764541971438523\n",
      "Integrated Brier Score: 0.21708490442678716\n",
      "Concordance Index 0.5670484344532353\n",
      "Integrated Brier Score: 0.18352485075508992\n",
      "durations 14.0 5152.0\n",
      "Concordance Index 0.5777051561365287\n",
      "Integrated Brier Score: 0.18657243659927855\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.7366567624078354\n",
      "Integrated Brier Score: 0.1586454433472276\n",
      "durations 3.0 3431.0\n",
      "Concordance Index 0.6706638115631691\n",
      "Integrated Brier Score: 0.17021119442680066\n",
      "Concordance Index 0.5824812357228326\n",
      "Integrated Brier Score: 0.1937834688834565\n",
      "durations 3.0 4537.0\n",
      "Concordance Index 0.5403189066059225\n",
      "Integrated Brier Score: 0.20724791922148658\n",
      "Concordance Index 0.5767652774778665\n",
      "Integrated Brier Score: 0.1996279729321882\n",
      "durations 16.0 3987.0\n",
      "Concordance Index 0.5854922279792746\n",
      "Integrated Brier Score: 0.18757009115553533\n",
      "Concordance Index 0.7250973082616085\n",
      "Integrated Brier Score: 0.15387122433222522\n",
      "durations 13.0 4067.0\n",
      "Concordance Index 0.7052585064074238\n",
      "Integrated Brier Score: 0.18532130128360208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.6919998880711867\n",
      "Integrated Brier Score: 0.1795882945077531\n",
      "durations 2.0 3944.0\n",
      "Concordance Index 0.6236341562120599\n",
      "Integrated Brier Score: 0.18447520375801926\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n",
      "Concordance Index 0.8132323678974133\n",
      "Integrated Brier Score: 0.1637504525652532\n",
      "durations 3.0 4695.0\n",
      "Concordance Index 0.8232971372161896\n",
      "Integrated Brier Score: 0.1529292281402801\n",
      "Concordance Index 0.8011350737797956\n",
      "Integrated Brier Score: 0.14520852727836547\n",
      "durations 3.0 6423.0\n",
      "Concordance Index 0.7541557305336833\n",
      "Integrated Brier Score: 0.2263621622850644\n",
      "Concordance Index 0.8234325244317557\n",
      "Integrated Brier Score: 0.16662543752336234\n",
      "durations 4.0 5166.0\n",
      "Concordance Index 0.6666666666666666\n",
      "Integrated Brier Score: 0.1738406811110688\n",
      "Concordance Index 0.8536516216829213\n",
      "Integrated Brier Score: 0.1739725262783416\n",
      "durations 2.0 5255.0\n",
      "Concordance Index 0.7446074201898188\n",
      "Integrated Brier Score: 0.3847500134864905\n",
      "Concordance Index 0.8068786061771693\n",
      "Integrated Brier Score: 0.1732106182792589\n",
      "durations 1.0 5546.0\n",
      "Concordance Index 0.7603448275862069\n",
      "Integrated Brier Score: 0.15072588134557366\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n",
      "Concordance Index 0.5079461428098444\n",
      "Integrated Brier Score: 0.21213101075203958\n",
      "durations 6.0 3308.0\n",
      "Concordance Index 0.38929695697796435\n",
      "Integrated Brier Score: 0.21978390692600552\n",
      "Concordance Index 0.5463565022421525\n",
      "Integrated Brier Score: 0.213308317987782\n",
      "durations 1.0 3437.0\n",
      "Concordance Index 0.5077071290944123\n",
      "Integrated Brier Score: 0.20336285721139785\n",
      "Concordance Index 0.5756261206547516\n",
      "Integrated Brier Score: 0.20146177342830687\n",
      "durations 8.0 3675.0\n",
      "Concordance Index 0.530664395229983\n",
      "Integrated Brier Score: 0.2280782147296879\n",
      "Concordance Index 0.5531807754713814\n",
      "Integrated Brier Score: 0.20620970790130258\n",
      "durations 6.0 3478.0\n",
      "Concordance Index 0.6574427480916031\n",
      "Integrated Brier Score: 0.208375723503377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5593409826419535\n",
      "Integrated Brier Score: 0.1995470853656357\n",
      "durations 6.0 2728.0\n",
      "Concordance Index 0.4513491414554375\n",
      "Integrated Brier Score: 0.23073728962897\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n",
      "Concordance Index 0.5226191616384127\n",
      "Integrated Brier Score: 0.18450846905340393\n",
      "durations 4.0 3635.0\n",
      "Concordance Index 0.4332993890020367\n",
      "Integrated Brier Score: 0.20524213871088098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.517420778811288\n",
      "Integrated Brier Score: 0.1903121968414787\n",
      "durations 18.0 4765.0\n",
      "Concordance Index 0.532870122928915\n",
      "Integrated Brier Score: 0.19647577916986905\n",
      "Concordance Index 0.48144427001569856\n",
      "Integrated Brier Score: 0.19582237039805123\n",
      "durations 11.0 7248.0\n",
      "Concordance Index 0.49725274725274726\n",
      "Integrated Brier Score: 0.202862123775123\n",
      "Concordance Index 0.7173777792331117\n",
      "Integrated Brier Score: 0.1745931945875225\n",
      "durations 28.0 3940.0\n",
      "Concordance Index 0.5324074074074074\n",
      "Integrated Brier Score: 0.3120608922064661\n",
      "Concordance Index 0.5071540603693864\n",
      "Integrated Brier Score: 0.18072169254179427\n",
      "durations 19.0 6732.0\n",
      "Concordance Index 0.37321792260692466\n",
      "Integrated Brier Score: 0.20951826183401617\n",
      "split gex_?|100130426      float32\n",
      "gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 20531, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5500802975234553\n",
      "Integrated Brier Score: 0.1891094179723483\n",
      "durations 1.0 3838.0\n",
      "Concordance Index 0.42496793501496366\n",
      "Integrated Brier Score: 0.2107241211709256\n",
      "Concordance Index 0.5259777528765476\n",
      "Integrated Brier Score: 0.19278964525333633\n",
      "durations 4.0 4026.0\n",
      "Concordance Index 0.5361179361179361\n",
      "Integrated Brier Score: 0.1907237564563564\n",
      "Concordance Index 0.524290238660785\n",
      "Integrated Brier Score: 0.19128313965834026\n",
      "durations 12.0 5287.0\n",
      "Concordance Index 0.5350236355822948\n",
      "Integrated Brier Score: 0.20777328631062786\n",
      "Concordance Index 0.5345884413309983\n",
      "Integrated Brier Score: 0.18689111849991893\n",
      "durations 3.0 4765.0\n",
      "Concordance Index 0.4909887968826108\n",
      "Integrated Brier Score: 0.19276061017691287\n",
      "Concordance Index 0.5122448401800629\n",
      "Integrated Brier Score: 0.18319901004024172\n",
      "durations 2.0 4694.0\n",
      "Concordance Index 0.5686357841053974\n",
      "Integrated Brier Score: 0.22088940859535142\n",
      "split gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "gex_?|155060         float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 19076, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.50398636723267\n",
      "Integrated Brier Score: 0.1255951876104938\n",
      "durations 8.0 4424.0\n",
      "Concordance Index 0.4167468719923003\n",
      "Integrated Brier Score: 0.1372662974038205\n",
      "Concordance Index 0.5110780226325193\n",
      "Integrated Brier Score: 0.14115753444426504\n",
      "durations 9.0 5481.0\n",
      "Concordance Index 0.45454545454545453\n",
      "Integrated Brier Score: 0.11973710993513564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5568898592916061\n",
      "Integrated Brier Score: 0.12560496381114752\n",
      "durations 53.0 4624.0\n",
      "Concordance Index 0.5131195335276968\n",
      "Integrated Brier Score: 0.14867737841925624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.536114795610756\n",
      "Integrated Brier Score: 0.12393962095199665\n",
      "durations 24.0 3871.0\n",
      "Concordance Index 0.5099403578528827\n",
      "Integrated Brier Score: 0.14738343861386174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n",
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/skorch/callbacks/training.py:455: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  new_threshold = score - abs_threshold_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.531405721316518\n",
      "Integrated Brier Score: 0.12053763421344445\n",
      "durations 11.0 3525.0\n",
      "Concordance Index 0.5112359550561798\n",
      "Integrated Brier Score: 0.16691852019968492\n",
      "split gex_?|100133144      float32\n",
      "gex_?|100134869      float32\n",
      "gex_?|10357          float32\n",
      "gex_?|10431          float32\n",
      "gex_?|155060         float32\n",
      "                      ...   \n",
      "gex_ZYG11A|440590    float32\n",
      "gex_ZYG11B|79699     float32\n",
      "gex_ZYX|7791         float32\n",
      "gex_ZZEF1|23140      float32\n",
      "gex_ZZZ3|26009       float32\n",
      "Length: 19076, dtype: object\n",
      "Concordance Index 0.592316173352557\n",
      "Integrated Brier Score: 0.20382519501371732\n",
      "durations 7.0 3540.0\n",
      "Concordance Index 0.5735797399041752\n",
      "Integrated Brier Score: 0.2236037344148463\n",
      "Concordance Index 0.583249791144528\n",
      "Integrated Brier Score: 0.21030430825108473\n",
      "durations 14.0 2267.0\n",
      "Concordance Index 0.6364306784660767\n",
      "Integrated Brier Score: 0.18671620490057064\n",
      "Concordance Index 0.5777292014915777\n",
      "Integrated Brier Score: 0.2155463001582481\n",
      "durations 8.0 3720.0\n",
      "Concordance Index 0.6534653465346535\n",
      "Integrated Brier Score: 0.20850130830332828\n",
      "Concordance Index 0.6037399065023374\n",
      "Integrated Brier Score: 0.21786606701734693\n",
      "durations 3.0 2197.0\n",
      "Concordance Index 0.4800275482093664\n",
      "Integrated Brier Score: 0.19830468493418724\n",
      "Concordance Index 0.5929328319945308\n",
      "Integrated Brier Score: 0.20377177271824307\n",
      "durations 8.0 3519.0\n",
      "Concordance Index 0.5788079470198676\n",
      "Integrated Brier Score: 0.23498257075462947\n"
     ]
    }
   ],
   "source": [
    "cancer_types = ['BLCA',\n",
    "    'BRCA',\n",
    "    'HNSC',\n",
    "    'KIRC',\n",
    "    'LGG',\n",
    "    'LIHC',\n",
    "    'LUAD',\n",
    "    'LUSC',\n",
    "    'OV',\n",
    "    'STAD']\n",
    "\n",
    "\n",
    "class InputShapeSetter(skorch.callbacks.Callback):\n",
    "    def on_train_begin(self, net, X, y):\n",
    "        net.set_params(module__input_units=X.shape[-1])\n",
    "\n",
    "agg_metrics_cindex = []\n",
    "agg_metrics_ibs = []\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types):\n",
    "    # get name of current dataset\n",
    "    data = load_tcga(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", cancer_type=cancer_type, as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "\n",
    "    net = NeuralNet(\n",
    "        SurvivalModel, \n",
    "        module__n_layers = 1,\n",
    "        module__input_units = X.shape[1],\n",
    "        #module__num_nodes = 32,\n",
    "        #module__dropout = 0.1, # these could also be removed\n",
    "        module__out_features = 1,\n",
    "        # for split sizes when result size = 1\n",
    "        iterator_train__drop_last=True,\n",
    "        #iterator_valid__drop_last=True,\n",
    "        criterion=BreslowLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer__weight_decay = 0.4,\n",
    "        batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "        callbacks=[\n",
    "            (\n",
    "                \"sched\",\n",
    "                LRScheduler(\n",
    "                    torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=5,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"es\",\n",
    "                EarlyStopping(\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=10,\n",
    "                    load_best=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"seed\", FixSeed(seed=42)),\n",
    "            #(\"Inpout Shape Setter\",InputShapeSetter())\n",
    "        ],\n",
    "        train_split = CustomValidSplit(0.2, stratified=True, random_state=rand_state),  \n",
    "        verbose=0\n",
    "    )\n",
    "    df_agg_metrics_cindex, df_agg_metrics_ibs, best_model,params, outer_scores, best_preds_train, best_preds_test = train_eval(X, y, net, n_iter, data.filename)\n",
    "    agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "    agg_metrics_ibs.append(df_agg_metrics_ibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cindex_train_mean</th>\n",
       "      <th>cindex_train_std</th>\n",
       "      <th>cindex_test_mean</th>\n",
       "      <th>cindex_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.5827</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIRC</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.0657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGG</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIHC</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.4738</td>\n",
       "      <td>0.0693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUSC</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.0555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OV</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.0436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAD</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  cindex_train_mean  cindex_train_std  cindex_test_mean  \\\n",
       "0    BLCA             0.6995            0.0202            0.5827   \n",
       "0    BRCA             0.5298            0.0142            0.4997   \n",
       "0    HNSC             0.6054            0.0647            0.5776   \n",
       "0    KIRC             0.6626            0.0775            0.6251   \n",
       "0     LGG             0.8197            0.0207            0.7498   \n",
       "0    LIHC             0.5485            0.0251            0.5073   \n",
       "0    LUAD             0.5492            0.0953            0.4738   \n",
       "0    LUSC             0.5294            0.0140            0.5111   \n",
       "0      OV             0.5279            0.0211            0.4811   \n",
       "0    STAD             0.5900            0.0100            0.5845   \n",
       "\n",
       "   cindex_test_std  \n",
       "0           0.0217  \n",
       "0           0.0704  \n",
       "0           0.0093  \n",
       "0           0.0657  \n",
       "0           0.0558  \n",
       "0           0.1002  \n",
       "0           0.0693  \n",
       "0           0.0555  \n",
       "0           0.0436  \n",
       "0           0.0680  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_breslow_1_cindex = pd.concat([df for df in agg_metrics_cindex]).round(4)\n",
    "df_final_breslow_1_cindex.to_csv('metrics/final_deep_learning_tcga_breslow_1_cindex.csv', index=False)\n",
    "df_final_breslow_1_cindex.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_deep_learning_tcga_breslow_1_cindex.csv', index=False)  #\n",
    "df_final_breslow_1_cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ibs_train_mean</th>\n",
       "      <th>ibs_train_std</th>\n",
       "      <th>ibs_test_mean</th>\n",
       "      <th>ibs_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIRC</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGG</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIHC</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.0488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUSC</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OV</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAD</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  ibs_train_mean  ibs_train_std  ibs_test_mean  ibs_test_std\n",
       "0    BLCA          0.2053         0.0239         0.2624        0.0320\n",
       "0    BRCA          0.1937         0.0121         0.2003        0.0108\n",
       "0    HNSC          0.2233         0.0942         0.2759        0.1592\n",
       "0    KIRC          0.1771         0.0204         0.1870        0.0132\n",
       "0     LGG          0.1646         0.0116         0.2177        0.0982\n",
       "0    LIHC          0.2065         0.0062         0.2181        0.0120\n",
       "0    LUAD          0.1852         0.0082         0.2252        0.0488\n",
       "0    LUSC          0.1887         0.0038         0.2046        0.0127\n",
       "0      OV          0.1274         0.0080         0.1440        0.0173\n",
       "0    STAD          0.2103         0.0065         0.2104        0.0193"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_breslow_1_ibs = pd.concat([df for df in agg_metrics_ibs]).round(4)\n",
    "df_final_breslow_1_ibs.to_csv('metrics/final_deep_learning_tcga_breslow_1_ibs.csv', index=False)\n",
    "df_final_breslow_1_ibs.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_deep_learning_tcga_breslow_1_ibs.csv', index=False) \n",
    "df_final_breslow_1_ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
