{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBsurv benchmark\n",
    "from xgbsurv.datasets import load_metabric, load_flchain, load_rgbsg, load_support\n",
    "#from xgbsurv.datasets import (load_flchain, load_rgbsg, load_support,\n",
    "#load_tcga)\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "from xgbsurv.models.utils import sort_X_y\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,LabelBinarizer\n",
    "# import models\n",
    "from pycox.evaluation import EvalSurv\n",
    "from xgbsurv.models.utils import transform_back, transform\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df\n",
    "import sys\n",
    "#sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import EHLoss, eh_likelihood_torch_2, AFTLoss\n",
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.dataset import CVSplit, ValidSplit\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "deep learning hyperparameter spaces follow pycox paper\n",
    "Time-to-Event Prediction with Neural Networks and Cox Regression\n",
    "page 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 10 # set to 50\n",
    "#n_iter_cind = 200\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "\n",
    "param_grid_breslow = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    'estimator__lr': scloguniform(0.001,0.01),\n",
    "    #'max_epochs':  scrandint(10,20), # corresponds to num_rounds\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, n_layers, in_features, num_nodes, dropout, out_features):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.in_features = in_features\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dropout = dropout\n",
    "        self.out_features = out_features\n",
    "        model = []\n",
    "        # first layer\n",
    "        model.append(torch.nn.Linear(in_features, num_nodes))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout))\n",
    "        model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            model.append(torch.nn.Linear(num_nodes, num_nodes))\n",
    "            #init.kaiming_normal_(model[-1].weight, nonlinearity='relu')\n",
    "            model.append(torch.nn.ReLU())\n",
    "            model.append(torch.nn.Dropout(dropout))\n",
    "            model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        # output layer\n",
    "        model.append(torch.nn.Linear(num_nodes, out_features))\n",
    "    \n",
    "        self.layers = nn.Sequential(*model)\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     if isinstance(layer, nn.Linear):\n",
    "        #         #nn.init.uniform_(layer.weight, a=-0.5, b=0.5)\n",
    "        #         nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.layers(x)\n",
    "        print('res',res)\n",
    "        return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stratified inner k-fold cross-validation\n",
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        if isinstance(y,pd.DataFrame):\n",
    "            y = y.to_numpy()\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        print(super().split(X, bins, groups=groups))\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Scorer\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "\n",
    "        #y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, np.ndarray):\n",
    "            y_pred = torch.from_numpy(y_pred)\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, pd.Series):\n",
    "            y_pred = torch.tensor(y_pred.values)\n",
    "        if isinstance(y_true, pd.Series):\n",
    "            y_true = torch.tensor(y_true.values)\n",
    "        score = eh_likelihood_torch_2(y_true, y_pred)\n",
    "        print('score',score)\n",
    "        return score.numpy()\n",
    "\n",
    "scoring_function = make_scorer(custom_scoring_function, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7871, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapt this for bool case\n",
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        \n",
    "        #to_add = X[X.columns[X.columns.isin(['sex','D'])]]\n",
    "        #X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        #df.columns.get_loc('age')\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        #to_add = to_add.values.reshape(-1, 1)\n",
    "\n",
    "        # Horizontally stack the two arrays\n",
    "        #result = np.hstack((X_transformed, to_add))\n",
    "        \n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "\n",
    "class CustomStandardScaler2(StandardScaler):\n",
    "    \"\"\"Just to change the datatype of bool variables.\"\"\"\n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        \n",
    "        to_return = X\n",
    "        #X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        #df.columns.get_loc('age')\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        #to_add = to_add.values.reshape(-1, 1)\n",
    "\n",
    "        # Horizontally stack the two arrays\n",
    "        #result = np.hstack((X_transformed, to_add))\n",
    "        \n",
    "        # Add your own code here\n",
    "        return to_return.astype(np.float32)\n",
    "    \n",
    "class CustomLabelBinarizer(LabelBinarizer):\n",
    "    def __init__(self, neg_label=0, pos_label=1, sparse_output=False):\n",
    "        super().__init__(neg_label=0, pos_label=1, sparse_output=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Add custom fit logic here\n",
    "        # Call the parent class's fit method\n",
    "        print('fit',X)\n",
    "        super().fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Add custom transform logic here\n",
    "\n",
    "        # Call the parent class's transform method\n",
    "        print('transform',X)\n",
    "        transformed_X = super().transform(X)\n",
    "\n",
    "        return transformed_X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add custom transform logic here\n",
    "\n",
    "        # Call the parent class's transform method\n",
    "        print(y)\n",
    "        print('fit_transform',X.values)\n",
    "        to_add = X[X.columns[X.columns.isin(['sex','D'])]]\n",
    "        X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        transformed_X = super().fit_transform(X.values)\n",
    "    \n",
    "        return transformed_X.astype(np.float32)\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        # Add custom inverse_transform logic here\n",
    "\n",
    "        # Call the parent class's inverse_transform method\n",
    "        inverse_X = super().inverse_transform(X)\n",
    "\n",
    "        return inverse_X.astype(np.float32)\n",
    "    \n",
    "# ct = make_column_transformer(\n",
    "#         (CustomStandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "#         #(CustomLabelBinarizer(), make_column_selector(dtype_include=['bool'])), remainder='passthrough')\n",
    "\n",
    "ct = CustomStandardScaler()\n",
    "data = load_flchain(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X = ct.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 1 # # set to 50\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "\n",
    "        dataset_name = filename.split('_')[0]\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        # ct = make_column_transformer(\n",
    "        #  (StandardScaler(),\n",
    "        #  make_column_selector(dtype_include=float,dtype_exclude=bool)),)\n",
    "        # (LabelBinarizer(),\n",
    "        # make_column_selector(dtype_include=bool, dtype_exclude=float)))\n",
    "        ct = make_column_transformer(\n",
    "        (CustomStandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "        (CustomStandardScaler2(), make_column_selector(dtype_include=['category'])), remainder='passthrough')\n",
    "        #columns_to_transform = [col for col in X.columns if col != 'sex']\n",
    "        #ct = make_column_transformer(\n",
    "        #(StandardScaler(), columns_to_transform), \n",
    "        #(LabelBinarizer(), make_column_selector(dtype_include='bool')),\n",
    "        #remainder='passthrough'\n",
    "        #)\n",
    "        pipe = Pipeline(\n",
    "        [('scaler', ct),\n",
    "        ('estimator', net)]\n",
    "        )\n",
    "        # pipe = Pipeline([\n",
    "        # ('scale', StandardScaler()),\n",
    "        # ('estimator', net),\n",
    "        # ])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_breslow, scoring = scoring_function, n_jobs=-1, \n",
    "                            cv=inner_custom_cv, n_iter=n_iter, refit=True)\n",
    "        \n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                print(X_train.shape, type(X_train))\n",
    "                print(y_train.shape, type(y_train))\n",
    "                print(X_test.shape, X_test.shape)\n",
    "                print(y_test.shape, y_test.shape)\n",
    "                # save splits and data\n",
    "                savetxt('splits/train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                savetxt('splits/X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                savetxt('splits/X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                savetxt('splits/y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                savetxt('splits/y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "                \n",
    "                #savetxt('splits/test_index_'+str(i)+'.csv', test_index, delimiter=',')\n",
    "                \n",
    "                # create validation dataset for early stopping\n",
    "                #strat = np.sign(y_train)\n",
    "                #valid_split = ValidSplit(cv=0.1, stratified=strat, random_state=42)\n",
    "\n",
    "                # train\n",
    "                rs.fit(X_train, y_train)\n",
    "                \n",
    "                # predict\n",
    "                #scaler = StandardScaler()\n",
    "                #X_train = scaler.fit_transform(X_train)\n",
    "                #X_test = scaler.transform(X_test)\n",
    "                print(rs.best_estimator_.predict(X_train))\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "\n",
    "                #print(best_preds_test, type(best_preds_train))\n",
    "                #print(best_preds_test, type(best_preds_test))\n",
    "                # predict survival function\n",
    "                # d = predict_survival_function(X_test, dataframe=True)\n",
    "\n",
    "                # save predictions, get dataset name\n",
    "                savetxt('predictions/train_preds_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "                savetxt('predictions/test_preds_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "                \n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "                #print(rs.best_params_)\n",
    "                # save c-index values\n",
    "                try:\n",
    "                        score_train = cindex_censored(y_train, best_preds_train.reshape(-1))\n",
    "                        score_test = cindex_censored(y_test, best_preds_test.reshape(-1))\n",
    "                        outer_scores['cindex_train_'+dataset_name] += [score_train]\n",
    "                        outer_scores['cindex_test_'+dataset_name] += [score_test]\n",
    "                except:\n",
    "                        outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "                        outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "        df_metrics.to_csv('metrics/metric_summary_'+str(i)+'_'+filename, index=False)\n",
    "        return best_model, best_params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8873,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8868</th>\n",
       "      <td>-2029.0</td>\n",
       "      <td>-2029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8869</th>\n",
       "      <td>-2029.0</td>\n",
       "      <td>-2029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870</th>\n",
       "      <td>-2029.0</td>\n",
       "      <td>-2029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8871</th>\n",
       "      <td>-2029.0</td>\n",
       "      <td>-2029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8872</th>\n",
       "      <td>-2029.0</td>\n",
       "      <td>-2029.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  target\n",
       "0        3.0     3.0\n",
       "1        3.0     3.0\n",
       "2        3.0     3.0\n",
       "3        3.0     3.0\n",
       "4        3.0     3.0\n",
       "...      ...     ...\n",
       "8868 -2029.0 -2029.0\n",
       "8869 -2029.0 -2029.0\n",
       "8870 -2029.0 -2029.0\n",
       "8871 -2029.0 -2029.0\n",
       "8872 -2029.0 -2029.0\n",
       "\n",
       "[8873 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_support(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X.dtypes\n",
    "print(data.target.shape)\n",
    "# d = data.target.shape[0]\n",
    "# #y = np.hstack((data.target.reshape(d,1),data.target.reshape(d,1)))\n",
    "# #y.shape\n",
    "# type(data.target)\n",
    "pd.concat([data.target, data.target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: METABRIC_adapted.csv\n",
      "MKI67                float32\n",
      "EGFR                 float32\n",
      "PGR                  float32\n",
      "ERBB2                float32\n",
      "hormone_treatment    float32\n",
      "radiotherapy         float32\n",
      "chemotherapy         float32\n",
      "ER_positive          float32\n",
      "age                  float32\n",
      "dtype: object\n",
      "float32\n",
      "<generator object _BaseKFold.split at 0x7feec235d230>\n",
      "(1522, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(1522,) <class 'pandas.core.series.Series'>\n",
      "(381, 9) (381, 9)\n",
      "(381,) (381,)\n",
      "<generator object _BaseKFold.split at 0x7fee70b45150>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'lr' for estimator Pipeline(steps=[('scaler',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('customstandardscaler',\n                                                  CustomStandardScaler(),\n                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f81f887e590>),\n                                                 ('customstandardscaler2',\n                                                  CustomStandardScaler2(),\n                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f81f887ed40>)])),\n                ('estimator',\n                 <class 'skorch.net.NeuralNet'>[uninitialized](\n  module=<class '__main__.SurvivalModel'>,\n  module__in_features=9,\n  module__n_layers=1,\n  module__out_features=(1903,),\n))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/parallel.py\", line 263, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 211, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/utils/metaestimators.py\", line 70, in _set_params\n    super().set_params(**params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/base.py\", line 205, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'lr' for estimator Pipeline(steps=[('scaler',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('customstandardscaler',\n                                                  CustomStandardScaler(),\n                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f81f887e590>),\n                                                 ('customstandardscaler2',\n                                                  CustomStandardScaler2(),\n                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f81f887ed40>)])),\n                ('estimator',\n                 <class 'skorch.net.NeuralNet'>[uninitialized](\n  module=<class '__main__.SurvivalModel'>,\n  module__in_features=9,\n  module__n_layers=1,\n  module__out_features=(1903,),\n))]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 35\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mdtypes)\n\u001b[1;32m     13\u001b[0m     net \u001b[39m=\u001b[39m NeuralNet(\n\u001b[1;32m     14\u001b[0m     SurvivalModel, \n\u001b[1;32m     15\u001b[0m     module__n_layers \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[0;32m---> 35\u001b[0m     best_model,params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_eval(X, y, net, n_iter, data\u001b[39m.\u001b[39;49mfilename)\n\u001b[1;32m     37\u001b[0m \u001b[39m#train eval function here\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 67\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(X, y, net, n_iter, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m savetxt(\u001b[39m'\u001b[39m\u001b[39msplits/y_test_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfilename, y_test, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39m#savetxt('splits/test_index_'+str(i)+'.csv', test_index, delimiter=',')\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m# create validation dataset for early stopping\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m rs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     69\u001b[0m \u001b[39m# predict\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m#scaler = StandardScaler()\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m#X_train = scaler.fit_transform(X_train)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m#X_test = scaler.transform(X_test)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mprint\u001b[39m(rs\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_train))\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'lr' for estimator Pipeline(steps=[('scaler',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('customstandardscaler',\n                                                  CustomStandardScaler(),\n                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f81f887e590>),\n                                                 ('customstandardscaler2',\n                                                  CustomStandardScaler2(),\n                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f81f887ed40>)])),\n                ('estimator',\n                 <class 'skorch.net.NeuralNet'>[uninitialized](\n  module=<class '__main__.SurvivalModel'>,\n  module__in_features=9,\n  module__n_layers=1,\n  module__out_features=(1903,),\n))]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "for dataset in data_set_fns:\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target\n",
    "    #y = pd.concat([data.target, data.target],axis=1)\n",
    "    #y.columns = ['target_1','target_2']\n",
    "    print('Dataset:',data.filename)\n",
    "    print(X.dtypes)\n",
    "    print(y.dtypes)\n",
    "    \n",
    "    net = NeuralNet(\n",
    "    SurvivalModel, \n",
    "    module__n_layers = 1,\n",
    "    module__in_features = X.shape[1],\n",
    "    #module__num_nodes = 32,\n",
    "    #module__dropout = 0.1, # these could also be removed\n",
    "    module__out_features = y.shape,\n",
    "    # for split sizes when result size = 1\n",
    "    iterator_train__drop_last=True,\n",
    "    #iterator_valid__drop_last=True,\n",
    "    criterion=AFTLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__weight_decay = 0.4,\n",
    "    batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "    #callbacks=[EarlyStopping(patience=10)],\n",
    "    #TODO: enable stratification, verify\n",
    "    #train_split=ValidSplit(0.1), \n",
    "    #lr=0.001,\n",
    "    #max_epochs=1, #0,#100\n",
    "    #train_split=None,\n",
    "    verbose=1\n",
    "    )\n",
    "    best_model,params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test = train_eval(X, y, net, n_iter, data.filename)\n",
    "    \n",
    "#train eval function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: METABRIC_adapted.csv\n",
      "MKI67                float32\n",
      "EGFR                 float32\n",
      "PGR                  float32\n",
      "ERBB2                float32\n",
      "hormone_treatment    float32\n",
      "radiotherapy         float32\n",
      "chemotherapy         float32\n",
      "ER_positive          float32\n",
      "age                  float32\n",
      "dtype: object\n",
      "target_1    float32\n",
      "target_2    float32\n",
      "dtype: object\n",
      "y shape (1903, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1135, in run_single_epoch\n    for batch in iterator:\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n    data = self._next_data()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 721, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 175, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 175, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 183, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas.core.series.Series'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m rs \u001b[39m=\u001b[39m RandomizedSearchCV(pipe, param_grid_breslow, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, scoring \u001b[39m=\u001b[39m  \u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, n_iter\u001b[39m=\u001b[39mn_iter, refit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m rs\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     51\u001b[0m \u001b[39m# predict\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m#scaler = StandardScaler()\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m#X_train = scaler.fit_transform(X_train)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m#X_test = scaler.transform(X_test)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39mprint\u001b[39m(rs\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_train))\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1135, in run_single_epoch\n    for batch in iterator:\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n    data = self._next_data()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 721, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 175, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 175, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 183, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "for dataset in data_set_fns:\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target\n",
    "    y = pd.concat([data.target, data.target],axis=1)\n",
    "    y.columns = ['target_1','target_2']\n",
    "    print('Dataset:',data.filename)\n",
    "    print(X.dtypes)\n",
    "    print(y.dtypes)\n",
    "    print('y shape', y.shape)\n",
    "    \n",
    "    net = NeuralNet(\n",
    "    SurvivalModel, \n",
    "    module__n_layers = 1,\n",
    "    module__in_features = X.shape[1],\n",
    "    #module__num_nodes = 32,\n",
    "    #module__dropout = 0.1, # these could also be removed\n",
    "    module__out_features = y.shape[1],\n",
    "    # for split sizes when result size = 1\n",
    "    iterator_train__drop_last=True,\n",
    "    #iterator_valid__drop_last=True,\n",
    "    criterion=EHLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__weight_decay = 0.4,\n",
    "    batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "    #callbacks=[EarlyStopping(patience=10)],\n",
    "    #TODO: enable stratification, verify\n",
    "    #train_split=ValidSplit(0.1), \n",
    "    #lr=0.001,\n",
    "    #max_epochs=1, #0,#100\n",
    "    #train_split=None,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "    [\n",
    "    ('estimator', net)]\n",
    "    )\n",
    "    # pipe = Pipeline([\n",
    "    # ('scale', StandardScaler()),\n",
    "    # ('estimator', net),\n",
    "    # ])\n",
    "    rs = RandomizedSearchCV(pipe, param_grid_breslow, n_jobs=-1, scoring =  'neg_mean_squared_error', n_iter=n_iter, refit=True)\n",
    "    \n",
    "\n",
    "    # train\n",
    "    rs.fit(X, y)\n",
    "    \n",
    "    # predict\n",
    "    #scaler = StandardScaler()\n",
    "    #X_train = scaler.fit_transform(X_train)\n",
    "    #X_test = scaler.transform(X_test)\n",
    "    print(rs.best_estimator_.predict(X_train))\n",
    "    best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "    best_preds_test = rs.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_negative_likelihood_ratio',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'positive_likelihood_ratio',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.get_scorer_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Scorer\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "\n",
    "        #y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, np.ndarray):\n",
    "            y_pred = torch.from_numpy(y_pred)\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, pd.Series):\n",
    "            y_pred = torch.tensor(y_pred.values)\n",
    "        if isinstance(y_true, pd.Series):\n",
    "            y_true = torch.tensor(y_true.values)\n",
    "        score = eh_likelihood_torch_2(y_true, y_pred)\n",
    "        print('score',score)\n",
    "        return score.numpy()\n",
    "\n",
    "scoring_function = make_scorer(custom_scoring_function, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res tensor([[ 1.3605e-01, -4.0536e-02],\n",
      "        [-2.6749e-01, -4.3811e-01],\n",
      "        [ 1.6736e-01, -1.9756e-01],\n",
      "        [ 2.5982e-01,  1.9835e-01],\n",
      "        [ 2.3864e-01, -3.8675e-01],\n",
      "        [ 8.8213e-02,  1.0269e-01],\n",
      "        [-1.2194e-01,  2.0251e-01],\n",
      "        [ 9.0117e-02,  4.6018e-02],\n",
      "        [-2.5874e-01, -7.0655e-02],\n",
      "        [ 1.7664e-01, -2.2835e-02],\n",
      "        [-5.2692e-03, -6.0187e-02],\n",
      "        [ 4.5565e-02, -7.2283e-02],\n",
      "        [ 1.3050e-01, -2.2808e-01],\n",
      "        [ 1.4961e-01,  3.1284e-02],\n",
      "        [ 2.0955e-01, -2.4668e-01],\n",
      "        [ 3.5213e-01,  1.6539e-01],\n",
      "        [ 1.3855e-01, -2.5153e-02],\n",
      "        [-2.1017e-02,  6.5905e-02],\n",
      "        [ 7.2905e-01,  6.8269e-02],\n",
      "        [ 1.3487e-01, -1.9563e-01],\n",
      "        [ 1.7411e-01,  1.3675e-02],\n",
      "        [ 2.0898e-01,  7.6645e-02],\n",
      "        [ 1.6142e-01, -9.6822e-03],\n",
      "        [ 2.5252e-02, -7.1118e-02],\n",
      "        [ 7.2353e-01, -4.9765e-01],\n",
      "        [ 1.7573e-01, -4.6562e-04],\n",
      "        [-1.4910e-01,  8.4651e-01],\n",
      "        [ 1.6982e-01,  2.4087e-02],\n",
      "        [-1.7516e-01, -3.5267e-02],\n",
      "        [-2.6060e-01,  3.9022e-01],\n",
      "        [ 2.3276e-01,  7.6889e-02],\n",
      "        [ 1.0341e-01, -6.3508e-03],\n",
      "        [-3.1081e-01, -3.1914e-01],\n",
      "        [ 1.2980e-01, -1.6318e-01],\n",
      "        [ 5.9037e-01, -5.6984e-01],\n",
      "        [ 1.9007e-01, -2.3716e-01],\n",
      "        [-2.6010e-01, -2.3909e-01],\n",
      "        [ 6.8184e-01, -3.1371e-01],\n",
      "        [ 2.9448e-01,  1.5840e-01],\n",
      "        [ 1.3527e-01, -3.8703e-03],\n",
      "        [ 1.1757e-01, -1.5172e-01],\n",
      "        [ 2.9869e-01,  1.0651e-02],\n",
      "        [ 6.8904e-01, -2.6711e-01],\n",
      "        [ 1.6447e-01, -4.4042e-02],\n",
      "        [ 1.7264e-01,  2.5518e-02],\n",
      "        [-2.0629e-01,  1.2852e-01],\n",
      "        [-4.4119e-01,  3.9054e-01],\n",
      "        [ 4.2007e-01, -5.7805e-01],\n",
      "        [ 2.2940e-01,  5.1671e-01],\n",
      "        [ 1.4235e-01, -8.9991e-03],\n",
      "        [-2.5594e-01, -1.1060e+00],\n",
      "        [ 1.5867e-01, -7.2050e-02],\n",
      "        [ 1.9927e-01, -1.4701e-01],\n",
      "        [-6.3849e-01, -1.9709e-01],\n",
      "        [ 3.9205e-01,  9.0505e-02],\n",
      "        [ 1.7744e-01, -7.0017e-03],\n",
      "        [ 1.6763e-01, -2.0922e-01],\n",
      "        [ 7.8807e-01, -3.3401e-01],\n",
      "        [ 1.9731e-01, -6.1059e-02],\n",
      "        [-2.0598e-01,  1.3649e-01],\n",
      "        [ 3.1792e-01, -6.1710e-01],\n",
      "        [ 1.4715e-01,  2.9094e-02],\n",
      "        [-2.6384e-01, -3.2730e-01],\n",
      "        [ 1.1487e-01,  7.1174e-02],\n",
      "        [ 1.8328e-01, -3.6186e-01],\n",
      "        [ 7.7082e-01, -4.4306e-01],\n",
      "        [ 9.9162e-01, -1.0975e+00],\n",
      "        [ 2.5546e-01, -1.6464e-01],\n",
      "        [ 6.9946e-02,  2.8198e-02],\n",
      "        [-3.8470e-01,  3.1413e-01],\n",
      "        [ 2.9303e-01,  3.4502e-01],\n",
      "        [ 1.6401e-01,  9.8023e-03],\n",
      "        [ 3.1003e-01, -6.5109e-01],\n",
      "        [ 7.9954e-02, -9.9167e-02],\n",
      "        [ 2.1087e-01,  5.2126e-02],\n",
      "        [-2.2890e-01, -2.8541e-01],\n",
      "        [ 1.6602e-01, -1.0681e-01],\n",
      "        [ 6.7802e-02, -7.6926e-02],\n",
      "        [ 1.4755e-01, -1.6077e-01],\n",
      "        [ 4.0079e-01,  1.1159e-01],\n",
      "        [ 3.8548e-02, -4.5246e-01],\n",
      "        [ 2.9137e-01, -3.9021e-01],\n",
      "        [ 1.7277e-01,  1.3541e-01],\n",
      "        [-4.8214e-01,  4.2114e-01],\n",
      "        [ 6.4228e-01,  1.7225e-01],\n",
      "        [-3.4767e-01, -3.2268e-01],\n",
      "        [ 1.4046e-01,  7.0389e-02],\n",
      "        [ 2.0452e-01, -1.2033e-01],\n",
      "        [ 1.6284e-01,  8.9732e-02],\n",
      "        [ 3.6530e-02,  1.0831e-01],\n",
      "        [ 1.0306e-02, -1.1449e-03],\n",
      "        [ 7.9414e-02, -2.1492e-01],\n",
      "        [-2.7127e-01, -8.6106e-01],\n",
      "        [ 1.7757e-01, -7.9946e-02],\n",
      "        [ 1.1454e-01, -1.0463e-01],\n",
      "        [ 6.7146e-02, -1.4409e-01],\n",
      "        [ 2.5933e-01,  3.0373e-01],\n",
      "        [-3.4092e-02,  3.5666e-01],\n",
      "        [ 1.8244e-01, -2.5699e-01],\n",
      "        [-3.5495e-01,  1.2278e-01],\n",
      "        [ 1.3810e-01, -7.1280e-02],\n",
      "        [ 4.8507e-01, -2.3772e-01],\n",
      "        [ 3.3655e-01, -2.7482e-02],\n",
      "        [-4.8019e-02, -1.6571e-01],\n",
      "        [ 3.1604e-01, -5.3141e-02],\n",
      "        [ 2.2363e-01,  2.0434e-01],\n",
      "        [ 8.8881e-02, -3.4620e-01],\n",
      "        [ 1.5542e-01, -4.4554e-01],\n",
      "        [ 1.2721e-01,  6.8726e-02],\n",
      "        [ 7.5667e-02, -1.7011e-01],\n",
      "        [ 3.6727e-01, -8.7576e-03],\n",
      "        [-2.3004e-01,  1.4590e-02],\n",
      "        [ 2.0980e-01, -4.5997e-02],\n",
      "        [ 1.1948e-01, -3.5649e-02],\n",
      "        [-3.8445e-01, -2.1395e-01],\n",
      "        [-8.4004e-02,  6.2928e-02],\n",
      "        [-6.7729e-02, -3.3529e-02],\n",
      "        [ 1.4682e-01,  8.0774e-02],\n",
      "        [ 1.4989e-01, -1.0429e-01],\n",
      "        [ 2.1135e-02,  2.1970e-01],\n",
      "        [ 1.2618e-02, -8.9933e-02],\n",
      "        [ 1.7175e-01,  2.4921e-02],\n",
      "        [ 1.8397e-01, -2.2345e-02],\n",
      "        [-2.6634e-01, -2.9212e-01],\n",
      "        [-3.5388e-01, -1.8566e-01],\n",
      "        [-1.9562e-02,  7.0192e-01],\n",
      "        [ 2.4322e-01, -2.0421e-01],\n",
      "        [ 3.0570e-01, -6.2068e-01]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "res res tensor([[-3.5550e-01, -1.1829e-01],\n",
      "        [ 2.2765e-01,  6.4685e-01],\n",
      "        [ 5.9831e-01, -2.9054e-01],\n",
      "        [ 3.9735e-03, -4.8935e-01],\n",
      "        [ 1.7492e-01, -2.3974e-01],\n",
      "        [-6.9709e-04, -4.7209e-01],\n",
      "        [ 1.7044e-01, -2.4887e-01],\n",
      "        [-2.5279e-01,  1.0343e-01],\n",
      "        [ 6.6101e-01, -1.4556e-01],\n",
      "        [ 3.6319e-01, -2.4145e-03],\n",
      "        [ 6.5440e-01, -9.5719e-02],\n",
      "        [-2.5575e-01, -1.3901e-01],\n",
      "        [-5.6296e-01, -1.9448e-01],\n",
      "        [ 5.5510e-01, -2.9063e-01],\n",
      "        [-9.5570e-02, -2.2495e-01],\n",
      "        [-5.3897e-02, -2.8127e-01],\n",
      "        [-4.4535e-01, -1.2279e-02],\n",
      "        [-3.9015e-01,  5.6436e-02],\n",
      "        [ 6.1803e-01, -2.2394e-01],\n",
      "        [ 4.8034e-01, -6.0229e-01],\n",
      "        [-2.3407e-02, -4.1683e-01],\n",
      "        [ 3.2564e-01, -4.0587e-01],\n",
      "        [-3.1348e-01,  1.4784e-02],\n",
      "        [-1.4721e-01, -1.2082e+00],\n",
      "        [-1.0736e-01, -1.3688e-01],\n",
      "        [ 5.5363e-01, -6.8461e-02],\n",
      "        [ 1.4548e-02, -2.6625e-01],\n",
      "        [ 5.1260e-01, -1.2547e-01],\n",
      "        [ 8.9692e-02, -6.2838e-01],\n",
      "        [ 5.0925e-01, -1.2284e-02],\n",
      "        [-6.7222e-01, -4.7171e-01],\n",
      "        [ 1.5091e-01, -2.9737e-01],\n",
      "        [ 7.1881e-01, -8.0394e-02],\n",
      "        [ 4.8289e-01,  2.8869e-01],\n",
      "        [-2.4624e-01, -3.7079e-01],\n",
      "        [ 3.6709e-01, -5.2624e-02],\n",
      "        [ 1.0313e+00, -1.4248e-01],\n",
      "        [ 5.9701e-01,  7.2791e-02],\n",
      "        [ 3.7038e-01, -2.5105e-01],\n",
      "        [-1.9783e-01, -1.8055e-02],\n",
      "        [ 5.5723e-01, -7.7984e-02],\n",
      "        [-3.1997e-01, -8.3548e-02],\n",
      "        [ 2.5060e-01,  1.3398e-01],\n",
      "        [-1.2296e+00,  5.5733e-01],\n",
      "        [ 5.5047e-02, -1.9639e-01],\n",
      "        [-5.3851e-01,  1.5988e-01],\n",
      "        [-4.6261e-01,  8.9359e-02],\n",
      "        [ 3.0491e-01,  2.8882e-01],\n",
      "        [ 3.4999e-01, -2.0775e-01],\n",
      "        [ 4.2755e-01, -1.0277e-01],\n",
      "        [ 4.2275e-01, -6.4749e-02],\n",
      "        [ 3.9065e-01, -5.5464e-02],\n",
      "        [ 6.3653e-01, -1.1407e-01],\n",
      "        [ 9.7113e-02, -5.6265e-01],\n",
      "        [ 3.7017e-01, -1.2807e-01],\n",
      "        [ 3.6441e-02, -2.8944e-02],\n",
      "        [-1.5804e-01, -1.1526e-01],\n",
      "        [-2.9664e-01, -2.1834e-01],\n",
      "        [-1.7158e+00,  3.0634e-01],\n",
      "        [ 4.1406e-02,  1.1267e-01],\n",
      "        [-3.4564e-01,  3.8740e-02],\n",
      "        [-1.4426e+00,  2.3295e-01],\n",
      "        [ 5.0379e-01, -1.8916e-01],\n",
      "        [ 4.9153e-01, -2.3215e-01],\n",
      "        [ 3.8873e-01, -2.9076e-01],\n",
      "        [ 5.3009e-01, -7.7128e-04],\n",
      "        [ 7.1663e-01, -2.0703e-01],\n",
      "        [ 2.2385e-01, -6.6669e-01],\n",
      "        [-3.0907e-01, -5.7234e-01],\n",
      "        [ 2.5043e-01, -1.1113e-01],\n",
      "        [-4.6089e-01, -1.1809e-01],\n",
      "        [ 2.8781e-01, -2.7840e-01],\n",
      "        [ 3.5550e-01, -4.0492e-01],\n",
      "        [-4.8927e-01,  1.3684e-01],\n",
      "        [ 1.4947e-01, -2.4908e-01],\n",
      "        [ 1.7000e-01, -5.8831e-02],\n",
      "        [ 3.0620e-01,  1.0698e-01],\n",
      "        [ 5.8182e-01,  8.2863e-02],\n",
      "        [ 2.7491e-01, -6.2698e-02],\n",
      "        [-9.5841e-02, -2.3015e-01],\n",
      "        [-1.9684e-01, -9.3254e-02],\n",
      "        [ 6.7623e-01, -1.9529e-01],\n",
      "        [-1.3617e+00,  7.2280e-01],\n",
      "        [ 9.2280e-02, -1.2719e-01],\n",
      "        [ 8.0239e-02, -1.3338e-01],\n",
      "        [-6.9079e-01, -5.0040e-01],\n",
      "        [ 9.3090e-02, -6.3327e-01],\n",
      "        [-3.4282e-01, -1.4736e-01],\n",
      "        [ 1.4202e-01, -1.8513e-01],\n",
      "        [ 4.4232e-01,  2.8846e-02],\n",
      "        [-1.6048e-01,  1.9458e-01],\n",
      "        [ 4.1900e-01,  2.2797e-01],\n",
      "        [-4.0673e-01,  1.2972e-01],\n",
      "        [-4.6355e-02,  2.5687e-01],\n",
      "        [ 6.4833e-01, -1.2574e-01],\n",
      "        [ 6.9905e-01, -3.3601e-01],\n",
      "        [ 3.8075e-02,  4.4329e-01],\n",
      "        [-2.3528e-01, -7.5432e-02],\n",
      "        [ 5.4406e-01,  7.2223e-03],\n",
      "        [ 2.6898e-01,  1.3599e-01],\n",
      "        [ 2.6385e-01, -3.2976e-01],\n",
      "        [ 2.9383e-01, -4.2876e-01],\n",
      "        [-2.6616e-01,  1.8818e-01],\n",
      "        [ 4.9581e-01, -3.8040e-01],\n",
      "        [ 3.6242e-01, -3.7135e-01],\n",
      "        [ 8.9714e-01, -2.3289e-01],\n",
      "        [ 5.1381e-01, -4.3342e-02],\n",
      "        [ 5.2820e-01, -1.0400e-01],\n",
      "        [ 2.7795e-01,  6.8381e-01],\n",
      "        [ 5.1429e-02, -1.8210e-01],\n",
      "        [ 5.2077e-02,  1.8230e-02],\n",
      "        [ 7.9984e-01,  1.0119e-01],\n",
      "        [-1.4428e-01,  4.5093e-02],\n",
      "        [ 1.0362e-01, -2.2613e-01],\n",
      "        [ 4.6416e-01, -1.6396e-01],\n",
      "        [ 7.5017e-01,  1.0247e-01],\n",
      "        [ 5.6138e-02, -1.9928e-01],\n",
      "        [-1.0074e+00, -1.9982e-02],\n",
      "        [-1.1565e+00,  9.8837e-01],\n",
      "        [-9.9569e-01,  5.3966e-01],\n",
      "        [ 2.0576e-01, -6.5145e-02],\n",
      "        [-2.0460e-01, -2.4156e-01],\n",
      "        [ 1.5060e-01,  9.0856e-02],\n",
      "        [ 6.0271e-01,  7.8784e-03],\n",
      "        [-3.3814e-01,  2.1262e-02],\n",
      "        [-8.1857e-02,  3.2574e-01],\n",
      "        [ 1.1904e-01, -4.6137e-01],\n",
      "        [ 9.4175e-02, -5.5981e-01]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor([[-1.7376e-01, -5.8192e-01],\n",
      "        [-3.7459e-01, -1.0391e+00],\n",
      "        [ 7.7448e-02,  1.9154e-01],\n",
      "        [ 5.0001e-01,  1.8826e-01],\n",
      "        [-7.3328e-02, -5.9165e-02],\n",
      "        [-2.2426e-01, -1.5773e-01],\n",
      "        [-3.8421e-01, -6.0796e-01],\n",
      "        [-1.0058e+00, -3.2376e-01],\n",
      "        [ 1.6167e-02,  2.3605e-01],\n",
      "        [ 4.2392e-01,  3.3373e-01],\n",
      "        [-1.4015e-01, -5.0360e-01],\n",
      "        [-1.2085e+00, -7.9997e-01],\n",
      "        [-4.1454e-01, -3.6090e-01],\n",
      "        [ 2.6512e-01,  5.4514e-01],\n",
      "        [-1.3017e-01, -8.9487e-01],\n",
      "        [-2.9195e-01, -4.9902e-01],\n",
      "        [-9.0673e-02, -2.5207e-02],\n",
      "        [ 5.7625e-03,  6.5831e-03],\n",
      "        [-3.1444e-02,  8.3446e-03],\n",
      "        [ 1.2488e-01,  4.6291e-01],\n",
      "        [-4.3291e-01, -2.8956e-02],\n",
      "        [ 1.6818e-01,  4.1973e-01],\n",
      "        [-5.6429e-01, -5.2717e-01],\n",
      "        [-8.2133e-02,  1.8991e-01],\n",
      "        [ 2.1347e-01,  3.9810e-01],\n",
      "        [ 5.1526e-01,  7.8164e-01],\n",
      "        [ 7.6732e-01,  3.5113e-01],\n",
      "        [ 3.6076e-01,  2.4787e-01],\n",
      "        [ 2.4580e-01,  4.1740e-01],\n",
      "        [-7.1130e-02, -2.2228e-02],\n",
      "        [ 6.4672e-01,  5.4059e-01],\n",
      "        [-9.1471e-02, -6.1711e-02],\n",
      "        [ 1.4659e-01,  2.5865e-01],\n",
      "        [-1.3732e-01, -1.4238e-01],\n",
      "        [-5.3776e-01,  5.2795e-03],\n",
      "        [ 3.2050e-01,  9.8597e-02],\n",
      "        [ 3.6894e-01,  1.2180e-01],\n",
      "        [ 5.7652e-01,  6.1431e-01],\n",
      "        [-5.5446e-01, -2.8797e-01],\n",
      "        [-1.8125e-01, -1.7522e-01],\n",
      "        [ 7.0046e-02,  1.2703e-01],\n",
      "        [ 2.8184e-01, -1.6268e-01],\n",
      "        [ 5.8075e-01,  8.5792e-01],\n",
      "        [ 2.7165e-01, -1.7139e-01],\n",
      "        [ 1.4908e-01,  9.0732e-02],\n",
      "        [-5.2084e-01,  1.2855e-02],\n",
      "        [-1.7209e-01, -1.8202e-01],\n",
      "        [ 6.1640e-01,  5.5206e-01],\n",
      "        [-1.9933e-02,  1.9419e-01],\n",
      "        [ 6.3867e-02,  2.2911e-01],\n",
      "        [-4.0146e-01, -1.7754e-01],\n",
      "        [-7.5869e-02, -4.2139e-02],\n",
      "        [ 2.3778e-01,  1.8505e-01],\n",
      "        [ 1.0685e-01, -3.1384e-01],\n",
      "        [-4.0570e-02,  8.5142e-04],\n",
      "        [-1.0705e-01, -8.4030e-02],\n",
      "        [ 3.4006e-01,  3.7421e-02],\n",
      "        [-1.2191e-01, -1.4530e-01],\n",
      "        [-2.5683e-01, -1.6914e-01],\n",
      "        [ 1.5345e-01,  1.7344e-01],\n",
      "        [-2.4217e-01, -2.8338e-01],\n",
      "        [-5.7687e-01, -3.5227e-01],\n",
      "        [-3.0358e-02,  5.2371e-02],\n",
      "        [-9.7173e-03,  2.2038e-02],\n",
      "        [ 1.1249e-01,  2.8250e-01],\n",
      "        [-3.8191e-02,  2.9093e-02],\n",
      "        [-1.8148e-01, -2.4539e-01],\n",
      "        [ 1.0013e-01,  2.5963e-01],\n",
      "        [-2.2844e-01, -2.6469e-01],\n",
      "        [ 1.4846e-01, -2.4112e-01],\n",
      "        [ 4.0097e-02, -3.8063e-03],\n",
      "        [ 4.8955e-01,  3.5767e-01],\n",
      "        [ 4.0382e-02,  1.7642e-01],\n",
      "        [ 5.7447e-02, -4.5344e-01],\n",
      "        [ 1.1363e-02, -4.3427e-01],\n",
      "        [ 1.1549e-01,  4.2986e-02],\n",
      "        [ 5.1526e-01, -3.7952e-01],\n",
      "        [ 2.9963e-01,  3.2221e-01],\n",
      "        [ 1.0830e-02,  2.0803e-01],\n",
      "        [ 1.7025e-01,  3.7360e-01],\n",
      "        [ 2.5414e-01,  1.0292e+00],\n",
      "        [-2.1535e-02,  5.6327e-02],\n",
      "        [-7.2005e-02, -1.7960e-02],\n",
      "        [ 8.8339e-01,  1.8031e+00],\n",
      "        [-3.7058e-01, -3.1750e-01],\n",
      "        [-2.3430e-01, -1.7227e-01],\n",
      "        [ 7.7629e-02, -1.9134e-01],\n",
      "        [ 2.9533e-01, -4.6279e-02],\n",
      "        [ 2.8430e-01,  6.1532e-01],\n",
      "        [-3.4455e-01,  1.2309e-01],\n",
      "        [-5.1173e-02,  2.1499e-02],\n",
      "        [ 8.8172e-01,  3.1566e-01],\n",
      "        [-5.2679e-02,  7.1877e-02],\n",
      "        [ 3.5680e-01,  3.4319e-02],\n",
      "        [ 1.9753e-01,  2.7595e-01],\n",
      "        [ 5.3527e-02,  2.4307e-01],\n",
      "        [-3.0451e-01, -5.3063e-01],\n",
      "        [ 2.7737e-01,  1.5280e-01],\n",
      "        [-1.5638e-01, -1.3559e-01],\n",
      "        [ 2.0708e-01,  3.6869e-01],\n",
      "        [ 5.8630e-01,  2.9075e-01],\n",
      "        [ 7.7719e-02,  3.7536e-01],\n",
      "        [-2.9988e-01, -1.8581e-01],\n",
      "        [-9.6620e-02,  4.7783e-02],\n",
      "        [ 3.6899e-01,  2.9133e-02],\n",
      "        [-5.6928e-01, -4.5949e-01],\n",
      "        [-9.7225e-02, -6.7248e-02],\n",
      "        [-1.1463e+00, -6.5700e-01],\n",
      "        [-6.8411e-02,  7.2246e-02],\n",
      "        [-1.7411e-01, -1.8668e-01],\n",
      "        [ 2.3840e-01, -2.1968e-01],\n",
      "        [ 5.0737e-01,  8.1579e-01],\n",
      "        [-3.9557e-02,  3.2686e-02],\n",
      "        [ 3.7390e-01,  5.6647e-01],\n",
      "        [ 1.5480e-01,  3.0968e-01],\n",
      "        [ 1.2181e-01,  4.1552e-01],\n",
      "        [-1.7270e-02,  4.6517e-02],\n",
      "        [ 9.2583e-02,  7.3049e-02],\n",
      "        [-3.7715e-01, -2.8673e-01],\n",
      "        [ 4.2986e-01,  5.8807e-02],\n",
      "        [-5.3713e-01, -6.1779e-01],\n",
      "        [-6.1661e-01, -6.7813e-01],\n",
      "        [ 2.2529e-01,  4.7175e-01],\n",
      "        [ 6.1493e-02, -4.0411e-01],\n",
      "        [ 7.8201e-02,  4.4469e-01],\n",
      "        [ 2.3524e-01, -3.8178e-01],\n",
      "        [-5.6719e-01, -6.8365e-02],\n",
      "        [-3.0469e-01, -2.3409e-01]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(21.6349) tensor(20.7366, grad_fn=<DivBackward0>) tensor(-1.8151, grad_fn=<DivBackward0>) tensor(-0.5467, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
      "res res tensor([[-6.6440e-01, -2.3785e-01],\n",
      "        [ 2.0063e-01,  5.1967e-03],\n",
      "        [ 4.8406e-04,  1.1840e-01],\n",
      "        [-4.7812e-01,  8.0655e-01],\n",
      "        [ 3.4732e-01, -5.2798e-01],\n",
      "        [-1.5781e+00,  4.1930e-01],\n",
      "        [-6.8470e-01, -3.8763e-01],\n",
      "        [-5.7506e-01,  4.7907e-01],\n",
      "        [ 3.0523e-01, -1.2039e-01],\n",
      "        [ 3.3761e-01, -1.3718e-01],\n",
      "        [ 4.9938e-01, -4.2681e-01],\n",
      "        [-1.3481e-01,  3.2943e-01],\n",
      "        [ 5.8580e-01, -2.9728e-01],\n",
      "        [ 6.0608e-01,  8.7472e-02],\n",
      "        [-7.9837e-01,  3.8652e-01],\n",
      "        [-2.3687e-01,  4.4465e-01],\n",
      "        [-1.5854e+00,  5.3913e-01],\n",
      "        [-1.0442e-01,  9.4069e-02],\n",
      "        [ 3.9579e-01,  2.3475e-01],\n",
      "        [ 3.7723e-01, -2.4166e-01],\n",
      "        [ 2.4936e-01, -4.2494e-01],\n",
      "        [-4.7545e-01,  1.9020e-01],\n",
      "        [-7.6084e-01,  5.6638e-01],\n",
      "        [-1.7951e-04,  9.5585e-01],\n",
      "        [-2.8746e-01,  2.6325e-01],\n",
      "        [ 5.6926e-01, -1.2681e-01],\n",
      "        [-1.3558e+00,  6.4936e-01],\n",
      "        [ 5.3648e-01, -3.9220e-02],\n",
      "        [-2.0479e-01, -1.5454e+00],\n",
      "        [-1.1707e-01,  9.5637e-01],\n",
      "        [-9.5115e-01,  6.1414e-01],\n",
      "        [ 1.1563e-01,  1.6811e-01],\n",
      "        [ 7.8238e-01, -2.6977e-01],\n",
      "        [ 4.2744e-02, -5.8158e-01],\n",
      "        [ 2.0065e-02, -4.1399e-01],\n",
      "        [ 3.1378e-01, -2.3948e-01],\n",
      "        [-2.6914e-01,  7.1212e-02],\n",
      "        [ 2.8674e-01, -2.7001e-01],\n",
      "        [-2.4227e-01, -2.3839e-01],\n",
      "        [-4.9209e-01,  4.6579e-02],\n",
      "        [ 6.4623e-01, -7.5048e-02],\n",
      "        [-8.8366e-01,  7.9796e-02],\n",
      "        [ 1.2888e-01,  1.1585e-01],\n",
      "        [-3.6842e-01,  1.3766e-01],\n",
      "        [-1.0106e-01,  7.1201e-02],\n",
      "        [-1.1612e+00,  8.9066e-01],\n",
      "        [-3.1619e-01,  1.1464e+00],\n",
      "        [-4.0782e-01,  6.7258e-01],\n",
      "        [-1.6086e-01, -3.3567e-02],\n",
      "        [ 6.0361e-01,  2.6288e-01],\n",
      "        [-5.1153e-01, -2.1347e-01],\n",
      "        [ 3.6738e-01, -3.9802e-01],\n",
      "        [ 5.7024e-01, -2.7621e-01],\n",
      "        [-7.5505e-01,  3.7299e-01],\n",
      "        [ 3.9004e-01, -5.6567e-01],\n",
      "        [ 4.1010e-01, -4.0480e-02],\n",
      "        [-3.5960e-01, -1.4952e-01],\n",
      "        [ 1.2590e-01, -1.0308e-01],\n",
      "        [-4.6021e-01, -4.4252e-01],\n",
      "        [ 1.7285e-01,  1.8531e-02],\n",
      "        [-8.6372e-01,  2.5838e-01],\n",
      "        [-1.1788e+00,  1.8991e-01],\n",
      "        [-3.9723e-01, -2.3301e-01],\n",
      "        [ 4.4651e-01, -1.1526e-01],\n",
      "        [ 3.2055e-01, -1.4191e+00],\n",
      "        [ 2.4203e-01, -1.7829e-01],\n",
      "        [ 2.8718e-01, -4.5719e-01],\n",
      "        [-3.3651e-01,  1.8548e-01],\n",
      "        [-1.0513e+00,  3.7255e-01],\n",
      "        [ 3.2110e-01, -2.8889e-01],\n",
      "        [-7.8630e-01,  3.1401e-01],\n",
      "        [ 5.2208e-01, -7.5465e-03],\n",
      "        [ 1.3362e-01, -3.8898e-01],\n",
      "        [ 2.8815e-01, -7.0293e-01],\n",
      "        [ 9.0531e-01,  3.6654e-01],\n",
      "        [ 7.5210e-01,  1.4665e-02],\n",
      "        [ 6.5864e-01,  4.7658e-01],\n",
      "        [-3.7892e-01, -6.0182e-01],\n",
      "        [-7.7586e-01, -4.8768e-01],\n",
      "        [ 2.8848e-01, -7.8730e-01],\n",
      "        [-2.5602e-01, -8.0314e-01],\n",
      "        [ 5.2431e-04, -2.2245e-02],\n",
      "        [-2.6381e-01, -1.9989e-01],\n",
      "        [-8.9761e-01,  2.9675e-01],\n",
      "        [-9.1227e-01, -1.7719e-01],\n",
      "        [-1.0243e+00,  6.6809e-01],\n",
      "        [ 2.3327e-01,  8.7775e-02],\n",
      "        [-2.3046e-01, -2.9159e-02],\n",
      "        [ 6.8365e-01, -1.6832e-01],\n",
      "        [-9.0538e-01,  1.1702e-01],\n",
      "        [ 3.8605e-02,  1.5249e-01],\n",
      "        [ 6.3033e-01, -5.4095e-01],\n",
      "        [ 4.7104e-01, -4.0559e-01],\n",
      "        [-1.2940e+00,  6.6042e-01],\n",
      "        [ 1.6354e-01, -1.3089e-01],\n",
      "        [-9.1427e-01, -4.1344e-01],\n",
      "        [ 5.4616e-01,  1.0272e-01],\n",
      "        [ 1.0131e+00,  7.1120e-01],\n",
      "        [ 6.3755e-01, -1.2021e-01],\n",
      "        [-5.5380e-01,  3.1045e-01],\n",
      "        [-5.3811e-01,  2.5201e-01],\n",
      "        [-2.2955e-01,  3.8849e-01],\n",
      "        [-6.3413e-02, -2.0474e-01],\n",
      "        [-5.1153e-01, -4.9570e-01],\n",
      "        [-7.3267e-01,  5.2455e-01],\n",
      "        [-1.1216e-01, -2.5608e-01],\n",
      "        [-1.1079e+00,  3.9052e-02],\n",
      "        [-6.3274e-02,  2.8271e-01],\n",
      "        [ 6.1717e-01, -1.2585e-01],\n",
      "        [ 5.5364e-01, -5.1913e-01],\n",
      "        [ 4.8364e-01,  4.4615e-02],\n",
      "        [-3.0420e-01,  4.4366e-01],\n",
      "        [ 2.4995e-01, -1.9956e-01],\n",
      "        [ 8.7966e-01, -1.4295e-01],\n",
      "        [-5.8545e-01,  5.5080e-01],\n",
      "        [-6.6907e-01,  5.4090e-01],\n",
      "        [ 7.5344e-01,  5.5206e-01],\n",
      "        [-1.1005e-01, -6.6544e-01],\n",
      "        [-9.5378e-01,  2.6726e-01],\n",
      "        [-3.8655e-02, -1.1568e+00],\n",
      "        [-3.4166e-01,  2.2746e-01],\n",
      "        [ 4.3778e-02,  7.0772e-01],\n",
      "        [-1.9905e-01,  1.3140e-01],\n",
      "        [-3.1979e-01, -1.3440e-01],\n",
      "        [ 3.1850e-02, -4.1193e-01],\n",
      "        [-4.7467e-02, -4.1062e-01],\n",
      "        [-2.4885e-01, -4.6025e-01],\n",
      "        [-3.6827e-01,  8.8662e-02]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor([[-0.1341, -0.1150],\n",
      "        [-0.1707,  0.0470],\n",
      "        [-0.1578, -0.0070],\n",
      "        [-0.3738, -0.3449],\n",
      "        [ 0.4555, -0.0751],\n",
      "        [-0.2142, -0.4368],\n",
      "        [-0.4412, -0.1985],\n",
      "        [-0.1654, -0.0436],\n",
      "        [-0.4283, -0.0185],\n",
      "        [-0.2170, -0.3021],\n",
      "        [ 0.4559,  0.3246],\n",
      "        [-0.1588, -0.0736],\n",
      "        [ 0.2639,  0.0247],\n",
      "        [-0.1873,  0.1720],\n",
      "        [-0.0661,  0.1569],\n",
      "        [-0.0703,  0.1179],\n",
      "        [-0.6442, -0.1333],\n",
      "        [ 0.2484,  0.0433],\n",
      "        [ 0.4213,  0.5578],\n",
      "        [-0.2352, -0.1336],\n",
      "        [-0.1087,  0.0252],\n",
      "        [-0.5172, -0.4121],\n",
      "        [ 0.0568,  0.0126],\n",
      "        [-0.1918, -0.0891],\n",
      "        [-0.2035,  0.1856],\n",
      "        [ 0.0938,  0.3487],\n",
      "        [ 0.6680,  0.3451],\n",
      "        [ 0.6754,  1.0153],\n",
      "        [-0.4537, -0.5703],\n",
      "        [-0.1498, -0.4094],\n",
      "        [ 0.0481,  0.2421],\n",
      "        [-0.2595, -0.0428],\n",
      "        [-0.2023, -0.0652],\n",
      "        [ 0.5757,  1.2123],\n",
      "        [-0.6246, -0.5028],\n",
      "        [-0.0922,  0.0316],\n",
      "        [ 0.1018,  0.1140],\n",
      "        [-0.1724, -0.1584],\n",
      "        [-0.2731,  0.1973],\n",
      "        [ 0.4993,  0.4584],\n",
      "        [ 0.0972,  0.0212],\n",
      "        [-0.1923, -0.0877],\n",
      "        [-0.2217, -0.2648],\n",
      "        [-0.9708, -1.3966],\n",
      "        [-0.1869, -0.0571],\n",
      "        [-0.2261, -0.0480],\n",
      "        [-0.6103, -0.1023],\n",
      "        [ 0.4213,  0.4980],\n",
      "        [-0.1658, -0.1369],\n",
      "        [-0.2388, -0.1050],\n",
      "        [-0.1615, -0.0866],\n",
      "        [-0.2384, -0.2501],\n",
      "        [ 0.3659, -0.3557],\n",
      "        [ 0.2546,  0.1288],\n",
      "        [ 0.1424,  0.3888],\n",
      "        [ 0.1121,  0.3596],\n",
      "        [-0.2054, -0.0668],\n",
      "        [-0.5831,  0.0046],\n",
      "        [ 0.0484,  0.2448],\n",
      "        [ 0.2368,  0.4593],\n",
      "        [ 0.4743,  0.0534],\n",
      "        [-0.6999, -0.6849],\n",
      "        [-0.1806, -0.4284],\n",
      "        [ 0.1976,  0.3875],\n",
      "        [-0.2843, -0.5865],\n",
      "        [-0.1547,  0.0971],\n",
      "        [-0.2738,  0.6469],\n",
      "        [-0.6448, -0.2190],\n",
      "        [-0.2144, -0.0697],\n",
      "        [ 0.1689,  0.2727],\n",
      "        [ 0.1169,  0.3367],\n",
      "        [ 0.1394, -0.1365],\n",
      "        [ 0.0686,  0.2351],\n",
      "        [-0.2091, -0.5822],\n",
      "        [ 0.3823,  0.1317],\n",
      "        [ 0.1737,  0.4891],\n",
      "        [ 0.3059, -0.0389],\n",
      "        [-0.1331, -0.0606],\n",
      "        [ 0.1685, -0.1193],\n",
      "        [ 0.6152,  0.0714],\n",
      "        [-0.0960,  0.8382],\n",
      "        [-0.0781, -0.0211],\n",
      "        [-0.4877, -0.2417],\n",
      "        [-0.1731, -0.1211],\n",
      "        [ 0.0161, -0.1218],\n",
      "        [-0.2570,  0.0917],\n",
      "        [-0.3540, -0.5341],\n",
      "        [-0.1588,  0.1942],\n",
      "        [-0.2531, -0.6194],\n",
      "        [ 0.1790, -0.4774],\n",
      "        [ 0.8870,  0.6031],\n",
      "        [-0.0851,  0.0377],\n",
      "        [-0.3022, -0.3335],\n",
      "        [-0.2302,  0.2583],\n",
      "        [ 0.0070,  0.5794],\n",
      "        [ 0.2153,  0.4039],\n",
      "        [-0.2341, -0.1480],\n",
      "        [-0.0898, -0.1372],\n",
      "        [ 0.7859, -0.1347],\n",
      "        [-0.2951, -0.0797],\n",
      "        [-0.1634, -0.0853],\n",
      "        [ 0.1741,  0.3183],\n",
      "        [-0.1412, -0.4378],\n",
      "        [ 0.1073,  0.1247],\n",
      "        [ 0.2702, -0.0079],\n",
      "        [ 0.2009, -0.0961],\n",
      "        [-0.1050, -0.0340],\n",
      "        [ 0.0636,  0.1401],\n",
      "        [ 0.4720,  1.1224],\n",
      "        [-0.3731,  0.1973],\n",
      "        [ 0.1623,  0.7457],\n",
      "        [-0.1237, -0.4386],\n",
      "        [-0.3482, -0.2498],\n",
      "        [-0.3423, -0.1219],\n",
      "        [ 0.3462,  0.5005],\n",
      "        [-0.1534,  0.2801],\n",
      "        [-0.1331,  0.2117],\n",
      "        [-0.2115, -0.0766],\n",
      "        [-0.3683, -0.3283],\n",
      "        [ 0.0951,  0.2528],\n",
      "        [-0.1083, -0.0636],\n",
      "        [ 0.6678, -0.3801],\n",
      "        [ 0.6489,  0.7728],\n",
      "        [-0.9438, -0.5356],\n",
      "        [-0.3668, -0.3262],\n",
      "        [-0.1430,  0.0973],\n",
      "        [ 0.5578,  0.6054],\n",
      "        [ 0.0520,  0.1514]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(18.0195) tensor(17.3989, grad_fn=<DivBackward0>) res tensor(-1.5948, grad_fn=<DivBackward0>) tensor(-0.3856, grad_fn=<DivBackward0>)\n",
      "tensor(9.7867) tensor(9.1480, grad_fn=<DivBackward0>) loss tensor(-1.5787, grad_fn=<DivBackward0>) tensor(0.5885, grad_fn=<NegBackward0>)\n",
      "tensor(-0.4678, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
      "tensor([[-1.5807e+00, -7.3772e-01],\n",
      "        [-8.0279e-01, -2.8024e-01],\n",
      "        [ 7.9217e-01, -2.3413e-01],\n",
      "        [-5.3650e-01, -3.7151e-01],\n",
      "        [ 3.9184e-01, -4.5801e-01],\n",
      "        [-3.8582e-01,  6.6477e-02],\n",
      "        [ 2.9490e-01, -2.1342e-02],\n",
      "        [-5.9174e-02,  1.7497e-01],\n",
      "        [ 3.5848e-01,  2.9376e-01],\n",
      "        [ 4.3483e-01, -1.1075e-01],\n",
      "        [ 1.0519e+00,  2.6865e-01],\n",
      "        [-1.0811e+00, -2.0073e-01],\n",
      "        [ 4.4329e-01,  2.1717e-01],\n",
      "        [ 1.4146e-01, -3.9418e-01],\n",
      "        [-7.9610e-01, -2.1466e-01],\n",
      "        [-7.9431e-01, -7.2102e-01],\n",
      "        [-1.0738e+00, -2.3570e-01],\n",
      "        [-1.7484e-01, -1.2561e-01],\n",
      "        [ 7.5785e-01, -2.3296e-02],\n",
      "        [ 5.2969e-01,  4.8132e-01],\n",
      "        [ 5.5731e-02, -1.4143e-01],\n",
      "        [ 4.4607e-01,  5.5584e-01],\n",
      "        [-1.0070e-01, -6.9719e-02],\n",
      "        [-4.5560e-01,  1.8529e-01],\n",
      "        [-2.2481e-01,  2.3095e-01],\n",
      "        [ 9.1418e-01, -4.4405e-01],\n",
      "        [-4.9765e-01, -2.0053e-01],\n",
      "        [ 5.1111e-01,  2.2708e-01],\n",
      "        [-3.6030e-01, -6.7918e-01],\n",
      "        [ 9.6166e-01,  6.9784e-02],\n",
      "        [-4.6977e-01, -5.9836e-01],\n",
      "        [-3.0149e-01, -2.1614e-01],\n",
      "        [ 9.3323e-01,  2.3937e-01],\n",
      "        [-3.2857e-01, -1.7776e-01],\n",
      "        [-8.7161e-01,  2.0633e-02],\n",
      "        [ 7.9404e-01, -2.2417e-01],\n",
      "        [ 4.1669e-01, -3.1185e-01],\n",
      "        [ 4.2250e-01, -5.7186e-02],\n",
      "        [ 1.9941e-01, -9.3731e-02],\n",
      "        [-2.4092e-01,  4.4748e-05],\n",
      "        [ 1.1689e+00, -2.3673e-01],\n",
      "        [-9.7754e-01,  5.4334e-01],\n",
      "        [-5.6424e-01, -6.7990e-01],\n",
      "        [-1.3608e+00, -2.4779e-01],\n",
      "        [-5.0289e-01, -7.2752e-01],\n",
      "        [-1.2321e+00, -7.0887e-01],\n",
      "        [-6.0526e-01, -8.5554e-01],\n",
      "        [ 4.1141e-02, -4.3391e-01],\n",
      "        [ 2.0763e-01, -4.2952e-01],\n",
      "        [ 2.5303e-01, -3.3027e-01],\n",
      "        [ 3.5371e-01, -2.2784e-02],\n",
      "        [ 3.2715e-01, -6.4206e-01],\n",
      "        [ 4.0901e-01, -1.5619e-01],\n",
      "        [ 3.8687e-02, -1.4228e-01],\n",
      "        [ 5.6679e-01,  1.3832e-01],\n",
      "        [ 2.5600e+00,  1.7196e+00],\n",
      "        [-5.5870e-01,  1.4159e-01],\n",
      "        [-2.0918e-01, -1.7875e-03],\n",
      "        [-1.2464e+00,  3.5646e-02],\n",
      "        [ 5.9575e-01, -6.5299e-01],\n",
      "        [-7.8540e-01, -2.4440e-01],\n",
      "        [-6.4454e-01,  1.0314e-01],\n",
      "        [-1.5997e-01, -2.0395e-03],\n",
      "        [ 1.9067e-01,  1.2284e-01],\n",
      "        [-4.5521e-02,  6.4708e-02],\n",
      "        [ 1.1814e+00, -2.0211e-01],\n",
      "        [ 9.6556e-01,  2.4615e-01],\n",
      "        [-8.4398e-01, -2.2655e-01],\n",
      "        [-1.1495e-01, -3.4382e-01],\n",
      "        [ 1.8039e-01, -1.2834e-01],\n",
      "        [ 6.1293e-02, -8.5731e-01],\n",
      "        [ 9.5849e-01, -2.8857e-01],\n",
      "        [ 2.7578e-01, -5.0638e-01],\n",
      "        [-5.9366e-01,  2.1776e-02],\n",
      "        [-6.0517e-02,  5.8519e-02],\n",
      "        [ 7.8851e-02, -5.3519e-01],\n",
      "        [-1.0720e+00, -2.2984e-01],\n",
      "        [-5.8416e-01, -9.9027e-01],\n",
      "        [ 3.0101e-01,  2.5916e-02],\n",
      "        [ 2.6839e-01, -9.5919e-02],\n",
      "        [-1.1152e+00, -2.1210e-01],\n",
      "        [ 3.2489e-01, -2.8483e-01],\n",
      "        [-5.7475e-01, -2.4231e-01],\n",
      "        [-3.0614e-02, -4.0198e-02],\n",
      "        [ 2.9429e-01,  4.0949e-01],\n",
      "        [-9.3028e-01, -1.5155e-01],\n",
      "        [ 5.1319e-01, -3.1015e-01],\n",
      "        [ 1.8707e-01, -3.1332e-02],\n",
      "        [ 5.6063e-01,  5.8827e-02],\n",
      "        [-3.5817e-01, -1.0572e+00],\n",
      "        [-1.1790e+00, -2.7701e-01],\n",
      "        [ 3.3974e-01,  6.2164e-02],\n",
      "        [ 5.3086e-01, -5.0118e-02],\n",
      "        [-5.2041e-01, -1.6053e-01],\n",
      "        [ 4.2682e-01,  2.7335e-01],\n",
      "        [ 3.0015e-01, -5.8763e-01],\n",
      "        [ 5.9159e-01, -1.5999e-01],\n",
      "        [ 7.5583e-01,  5.1196e-03],\n",
      "        [-1.1076e-01, -9.1275e-01],\n",
      "        [-5.0723e-01, -3.8841e-02],\n",
      "        [-7.1160e-01, -3.0329e-02],\n",
      "        [-1.0514e+00, -6.6821e-01],\n",
      "        [ 1.6616e-01, -5.4437e-01],\n",
      "        [-2.8329e-02,  1.6711e-01],\n",
      "        [-4.6380e-01, -7.3101e-01],\n",
      "        [-3.7765e-01,  2.2693e-01],\n",
      "        [ 9.7790e-02,  2.8567e-01],\n",
      "        [-3.1065e-01,  7.6820e-02],\n",
      "        [ 4.2311e-01, -3.1342e-03],\n",
      "        [ 2.8502e-02,  2.7234e-02],\n",
      "        [ 6.9470e-01,  1.0106e-01],\n",
      "        [-1.7150e-01, -1.6326e-01],\n",
      "        [ 4.4200e-01, -1.3167e-01],\n",
      "        [ 7.1007e-01, -8.5059e-02],\n",
      "        [-4.0376e-01, -5.9066e-01],\n",
      "        [-3.7518e-01, -5.3612e-01],\n",
      "        [-2.9522e-01, -3.1364e-01],\n",
      "        [-8.9842e-01, -1.9189e-01],\n",
      "        [-2.8716e-01,  2.7937e-01],\n",
      "        [-9.8656e-01, -3.9179e-01],\n",
      "        [ 7.1995e-01,  5.1228e-01],\n",
      "        [-1.0818e+00, -6.8321e-01],\n",
      "        [ 6.6748e-01,  2.5106e-01],\n",
      "        [-6.8573e-02, -4.4177e-01],\n",
      "        [ 2.4774e-01, -3.5080e-01],\n",
      "        [-7.1835e-02, -1.6033e-01],\n",
      "        [ 9.3486e-02, -4.9402e-02],\n",
      "        [-2.2808e-01, -7.5984e-03]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "res res tensor(18.3120) tensor(17.8020, grad_fn=<DivBackward0>) tensor(-1.7451, grad_fn=<DivBackward0>) tensor(-0.4301, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.8051, grad_fn=<NegBackward0>)\n",
      "tensor([[-0.3566, -0.2639],\n",
      "        [ 0.2654,  0.1609],\n",
      "        [-0.2652, -0.0292],\n",
      "        [ 0.0872,  0.4410],\n",
      "        [ 0.0641, -0.0272],\n",
      "        [ 0.0729, -0.1395],\n",
      "        [-0.2521, -0.0798],\n",
      "        [ 0.0311, -0.1433],\n",
      "        [-0.9346, -0.7670],\n",
      "        [ 0.2336,  0.1338],\n",
      "        [-0.0698, -0.0788],\n",
      "        [ 0.2896, -0.0301],\n",
      "        [ 0.2007,  0.0801],\n",
      "        [ 0.3440,  0.3897],\n",
      "        [ 0.1295, -0.3209],\n",
      "        [-0.1756, -0.0729],\n",
      "        [ 0.1018,  0.2748],\n",
      "        [-0.2456, -0.1567],\n",
      "        [ 0.1852,  0.3443],\n",
      "        [-0.0878,  0.0144],\n",
      "        [-0.1453, -0.0718],\n",
      "        [ 0.0502, -0.0874],\n",
      "        [-0.3736, -0.5057],\n",
      "        [-0.2915, -0.2734],\n",
      "        [-0.3617, -0.2599],\n",
      "        [-0.1091, -0.1663],\n",
      "        [ 0.0516,  0.6722],\n",
      "        [-0.3298, -0.5666],\n",
      "        [-0.2067, -0.0790],\n",
      "        [ 0.6371,  0.5232],\n",
      "        [ 0.4114,  0.6310],\n",
      "        [-0.0277, -0.4105],\n",
      "        [-0.1604, -0.1915],\n",
      "        [-0.2463, -0.1673],\n",
      "        [ 0.3399,  0.6286],\n",
      "        [-0.0677,  0.2589],\n",
      "        [-0.1029,  0.1293],\n",
      "        [-0.1181, -0.0020],\n",
      "        [ 0.2672,  0.7698],\n",
      "        [-0.0562,  0.0395],\n",
      "        [-0.3291, -0.2248],\n",
      "        [-0.1240,  0.0064],\n",
      "        [-0.9933, -0.3900],\n",
      "        [ 0.1218,  0.3117],\n",
      "        [ 0.3728,  0.7070],\n",
      "        [-0.1439, -0.0152],\n",
      "        [ 0.2998,  0.0458],\n",
      "        [-0.4576, -0.7544],\n",
      "        [-0.1240,  0.0969],\n",
      "        [ 0.2802,  0.4160],\n",
      "        [ 0.4823,  0.8860],\n",
      "        [-0.2383, -0.2389],\n",
      "        [-0.1724, -0.0570],\n",
      "        [-0.4539, -0.5315],\n",
      "        [-0.4189, -0.6609],\n",
      "        [-0.7808, -0.3415],\n",
      "        [ 0.3722,  0.7622],\n",
      "        [-0.0566,  0.1835],\n",
      "        [ 0.1202,  0.4591],\n",
      "        [-0.4007, -0.1527],\n",
      "        [ 0.6018,  0.1082],\n",
      "        [ 0.1731,  0.1170],\n",
      "        [ 0.0502,  0.1957],\n",
      "        [-0.2202, -0.1973],\n",
      "        [-0.2857, -0.1499],\n",
      "        [ 0.1729,  0.1408],\n",
      "        [-0.7303,  0.1324],\n",
      "        [-0.5074,  0.1315],\n",
      "        [-0.5012,  0.3379],\n",
      "        [ 0.1012,  0.8300],\n",
      "        [ 0.3570,  0.3805],\n",
      "        [ 0.3334,  0.6351],\n",
      "        [-0.5823, -0.8013],\n",
      "        [-0.0926, -0.3902],\n",
      "        [ 0.1119,  0.0945],\n",
      "        [ 0.2464,  0.4868],\n",
      "        [-0.2579, -0.3967],\n",
      "        [-0.2240,  0.2582],\n",
      "        [-0.1773, -0.0598],\n",
      "        [-0.2883, -0.1559],\n",
      "        [-0.0819, -0.3306],\n",
      "        [-0.2592, -0.2470],\n",
      "        [ 0.0729,  0.3099],\n",
      "        [ 0.7130,  0.7658],\n",
      "        [ 0.1783,  0.3434],\n",
      "        [-0.1417,  0.2443],\n",
      "        [ 0.2502, -0.0291],\n",
      "        [-0.5642,  0.0520],\n",
      "        [ 0.0202,  0.1728],\n",
      "        [ 0.4397,  0.3801],\n",
      "        [ 0.0670,  0.5849],\n",
      "        [-0.2970, -0.0733],\n",
      "        [-0.4607, -0.3060],\n",
      "        [-0.1784, -0.0130],\n",
      "        [-0.5236,  0.3081],\n",
      "        [ 0.1596,  0.0811],\n",
      "        [-0.1075,  0.0850],\n",
      "        [-0.2139, -0.0684],\n",
      "        [-0.2867, -0.1916],\n",
      "        [-0.1488,  0.0756],\n",
      "        [-0.1348, -0.3668],\n",
      "        [-0.4218, -0.0986],\n",
      "        [-0.3547, -0.1976],\n",
      "        [-0.0847,  0.0390],\n",
      "        [-0.2311, -0.3710],\n",
      "        [-0.1049,  0.2228],\n",
      "        [-0.1966,  0.2099],\n",
      "        [-0.2391,  0.1373],\n",
      "        [ 0.1003,  0.4360],\n",
      "        [ 0.3301,  0.1849],\n",
      "        [-0.0122, -0.2437],\n",
      "        [-0.4463, -0.6257],\n",
      "        [-0.1443,  0.0130],\n",
      "        [ 0.3954, -0.0615],\n",
      "        [ 0.2781,  0.6987],\n",
      "        [-0.7892, -1.0779],\n",
      "        [-0.3084, -0.0483],\n",
      "        [-0.0946, -0.4638],\n",
      "        [-0.2454, -0.0762],\n",
      "        [-0.2944, -0.0527],\n",
      "        [-0.1615, -0.2095],\n",
      "        [-0.0964, -0.2690],\n",
      "        [-0.1296,  0.0190],\n",
      "        [-0.2184, -0.0566],\n",
      "        [-0.3247, -0.3005],\n",
      "        [ 0.0461,  0.2389],\n",
      "        [ 0.2156,  0.0166],\n",
      "        [ 0.0848, -0.0050]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor([[-8.8183e-01, -4.3027e-01],\n",
      "        [-4.3582e+00, -7.7277e-01],\n",
      "        [ 7.7181e-01, -1.6252e-01],\n",
      "        [-1.7511e+00, -7.6922e-01],\n",
      "        [-4.0947e-01,  1.8788e-01],\n",
      "        [-2.7199e+00,  5.2845e-01],\n",
      "        [ 4.0788e-01,  2.3750e-03],\n",
      "        [-6.7522e+00, -1.1351e-01],\n",
      "        [-1.9967e+00, -4.5184e-01],\n",
      "        [-3.6499e-01, -4.1151e-01],\n",
      "        [-9.0517e-01, -8.4135e-02],\n",
      "        [-1.4479e+00, -2.1214e-01],\n",
      "        [ 1.9100e-01, -2.3032e-01],\n",
      "        [-4.3093e-01,  2.3723e-01],\n",
      "        [-4.5768e-01, -2.8454e-01],\n",
      "        [-1.9641e+00, -1.8708e-01],\n",
      "        [ 5.5508e-02,  1.5144e-01],\n",
      "        [-3.4014e+00,  2.3811e-01],\n",
      "        [-5.0890e-01,  3.6429e-02],\n",
      "        [ 2.7697e-01, -8.6570e-01],\n",
      "        [-1.5890e+00,  4.7545e-01],\n",
      "        [ 9.4436e-01, -3.8493e-01],\n",
      "        [-2.0517e+00, -1.8253e-01],\n",
      "        [-3.1561e-01,  5.4474e-01],\n",
      "        [-1.7848e+00,  6.1561e-01],\n",
      "        [-4.2796e-01,  8.1212e-02],\n",
      "        [-9.6059e-01, -5.3952e-03],\n",
      "        [-6.5201e-01, -1.3318e-01],\n",
      "        [ 6.0295e-01,  3.0353e-01],\n",
      "        [ 2.9720e-02,  8.1899e-01],\n",
      "        [-1.3254e+00, -1.2446e+00],\n",
      "        [-1.5898e+00,  6.0714e-01],\n",
      "        [ 9.0019e-02, -2.2839e-01],\n",
      "        [-8.1317e-01, -4.6417e-02],\n",
      "        [-4.1654e-01,  7.8357e-01],\n",
      "        [ 5.6910e-02, -1.0335e-01],\n",
      "        [-1.0219e-01,  6.0006e-01],\n",
      "        [-4.2028e-01, -3.3800e-01],\n",
      "        [-1.1009e+00, -1.2115e-01],\n",
      "        [ 3.3536e-01,  4.2162e-01],\n",
      "        [-8.0866e-01,  6.1203e-02],\n",
      "        [-5.8970e-01, -4.6350e-01],\n",
      "        [-2.6803e-01,  9.1110e-02],\n",
      "        [ 9.2520e-01,  2.4442e-01],\n",
      "        [ 6.9581e-01, -2.1347e-01],\n",
      "        [ 4.2793e-01, -6.8081e-01],\n",
      "        [-3.6086e-01,  9.6815e-02],\n",
      "        [-1.9474e-01, -4.9253e-01],\n",
      "        [-4.8452e-01, -5.1403e-01],\n",
      "        [-6.0159e-01, -5.0869e-02],\n",
      "        [ 5.3714e-01,  1.9869e-01],\n",
      "        [ 5.3281e-01,  1.7202e-01],\n",
      "        [ 5.0500e-01,  4.9000e-01],\n",
      "        [-1.8417e+00,  7.7547e-02],\n",
      "        [-3.6386e-01, -2.5060e-01],\n",
      "        [ 1.7421e-01, -1.6246e-01],\n",
      "        [-7.3736e-01,  1.2126e-01],\n",
      "        [-8.8615e-01,  1.6721e-02],\n",
      "        [ 6.1866e-01, -2.1664e-01],\n",
      "        [-1.7341e+00, -1.9609e-01],\n",
      "        [-1.9868e+00, -3.8766e-01],\n",
      "        [-1.3509e-01,  1.8964e-01],\n",
      "        [-6.5721e-01,  2.7464e-02],\n",
      "        [-9.5646e-01,  2.5933e-01],\n",
      "        [-4.6661e-01,  4.2105e-02],\n",
      "        [-6.7187e-01,  4.4004e-02],\n",
      "        [ 3.7946e+00,  1.8056e+00],\n",
      "        [-2.2188e-01,  4.5006e-02],\n",
      "        [-1.9331e-01,  2.5769e-01],\n",
      "        [ 1.3232e-01,  1.0747e-01],\n",
      "        [ 1.3991e+00,  3.7893e-01],\n",
      "        [-1.4925e+00,  2.3803e-01],\n",
      "        [-7.9999e-01, -5.1219e-01],\n",
      "        [-6.0531e-01,  4.0226e-01],\n",
      "        [ 4.6420e-01, -6.0489e-02],\n",
      "        [ 3.5022e-01, -2.0674e-01],\n",
      "        [-3.5639e-01,  3.7402e-01],\n",
      "        [-9.0202e-01,  2.6023e-01],\n",
      "        [-6.1195e-01, -5.6442e-02],\n",
      "        [-1.5492e+00,  1.6500e-01],\n",
      "        [ 1.2014e+00, -2.6536e-01],\n",
      "        [-6.0451e-01, -3.6191e-01],\n",
      "        [ 7.1204e-01,  2.8268e-01],\n",
      "        [-2.9355e+00,  9.9457e-02],\n",
      "        [-1.7114e+00, -1.7854e-01],\n",
      "        [-1.6717e+00, -3.6412e-01],\n",
      "        [-1.7941e-01,  3.5023e-01],\n",
      "        [-3.9060e-01, -3.4562e-01],\n",
      "        [-2.1328e+00,  8.7904e-01],\n",
      "        [ 4.0125e-01,  3.1099e-01],\n",
      "        [-1.4052e+00,  1.8543e-01],\n",
      "        [-1.0406e+00, -6.1446e-02],\n",
      "        [ 3.8181e-01,  1.9384e-01],\n",
      "        [ 7.7920e-01,  3.5406e-01],\n",
      "        [-2.3367e-01,  6.0944e-01],\n",
      "        [-1.0257e+00,  2.1415e-02],\n",
      "        [-1.5734e+00,  7.6798e-01],\n",
      "        [-1.8154e+00, -3.9731e-01],\n",
      "        [ 1.2074e-01,  7.4204e-01],\n",
      "        [-2.0526e+00, -9.9074e-02],\n",
      "        [-1.4585e-01,  1.1526e-01],\n",
      "        [-3.3092e-01,  6.1657e-02],\n",
      "        [-4.3099e-01,  2.6313e-01],\n",
      "        [ 3.8667e-01,  3.4515e-01],\n",
      "        [-1.7418e+00, -7.1041e-01],\n",
      "        [-1.5936e+00,  5.3059e-05],\n",
      "        [-9.7710e-02, -4.7740e-01],\n",
      "        [ 6.4367e-01,  1.5228e-01],\n",
      "        [-1.0120e+00, -2.8411e-01],\n",
      "        [ 1.5161e-01,  8.2981e-01],\n",
      "        [ 1.4389e-01,  1.6744e-01],\n",
      "        [ 6.8620e-01,  3.5005e-01],\n",
      "        [ 8.6020e-01, -6.5274e-01],\n",
      "        [-9.5651e-01, -1.8426e-02],\n",
      "        [-1.1338e+00, -3.2826e-01],\n",
      "        [-3.3770e-01,  6.5990e-01],\n",
      "        [ 3.4111e-02,  6.3666e-01],\n",
      "        [ 1.0380e+00, -7.8594e-01],\n",
      "        [-6.8501e-01, -1.0652e-01],\n",
      "        [ 2.9693e-01,  2.0344e-01],\n",
      "        [-1.4631e+00, -4.8234e-01],\n",
      "        [-6.1740e-01,  9.6606e-01],\n",
      "        [-2.0192e+00, -2.7722e-01],\n",
      "        [-9.8406e-01, -4.4509e-02],\n",
      "        [ 5.2186e-01,  2.6699e-01],\n",
      "        [-9.4597e-01,  8.4358e-02],\n",
      "        [-8.8455e-01,  2.3560e-02],\n",
      "        [ 2.0004e-01, -1.0885e-01]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_pred"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 97)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[   0.0000, -350.2591, -351.1521,  ...,      -inf,      -inf,\n              -inf],\n        [   1.3047, -348.9544, -349.8474,  ...,      -inf,      -inf,\n              -inf],\n        [ 350.2591,    0.0000,   -0.8930,  ...,      -inf,      -inf,\n              -inf],\n        ...,\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan],\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan],\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan]], grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 83)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[ 0.8371, -1.2598,  8.7843,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000, -2.0969,  7.9472,  ...,    -inf,    -inf,    -inf],\n        [ 2.0969,  0.0000, 10.0441,  ...,    -inf,    -inf,    -inf],\n        ...,\n        [    inf,     inf,     inf,  ...,     nan,     nan,     nan],\n        [    inf,     inf,     inf,  ...,     nan,     nan,     nan],\n        [    inf,     inf,     inf,  ...,     nan,     nan,     nan]],\n       grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 38)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[ 5.1619e-01, -1.0572e-01,  3.4996e+02,  ...,        -inf,\n                 inf,         inf],\n        [ 0.0000e+00, -6.2191e-01,  3.4945e+02,  ...,        -inf,\n                 inf,         inf],\n        [-3.5195e+02, -3.5257e+02, -2.5078e+00,  ...,        -inf,\n                 inf,         inf],\n        ...,\n        [       -inf,        -inf,        -inf,  ...,        -inf,\n                 nan,         nan],\n        [       -inf,        -inf,        -inf,  ...,        -inf,\n                 nan,         nan],\n        [        inf,         inf,         inf,  ...,         nan,\n                 inf,         inf]], grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 29)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[   0.0000,  348.9722,   -4.9261,  ...,      -inf,      -inf,\n              -inf],\n        [   6.1051,  355.0772,    1.1790,  ...,      -inf,      -inf,\n              -inf],\n        [-345.9179,    3.0542, -350.8440,  ...,      -inf,      -inf,\n              -inf],\n        ...,\n        [-372.5119,  -23.5398, -377.4380,  ...,      -inf,      -inf,\n              -inf],\n        [-376.4622,  -27.4900, -381.3882,  ...,      -inf,      -inf,\n              -inf],\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan]], grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 51)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[  -0.8326,  351.8084,  353.2236,  ...,  374.8965,      -inf,\n          381.3479],\n        [   0.0000,  352.6410,  354.0562,  ...,  375.7291,      -inf,\n          382.1806],\n        [-350.7828,    1.8582,    3.2735,  ...,   24.9463,      -inf,\n           31.3978],\n        ...,\n        [-382.1806,  -29.5396,  -28.1243,  ...,   -6.4515,      -inf,\n            0.0000],\n        [     -inf,      -inf,      -inf,  ...,      -inf,      -inf,\n              -inf],\n        [      inf,       inf,       inf,  ...,       inf,       nan,\n               inf]], grad_fn=<DivBackward0>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 79\u001b[0m\n\u001b[1;32m     75\u001b[0m rs \u001b[39m=\u001b[39m RandomizedSearchCV(net, param_grid_breslow, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mneg_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m, n_iter\u001b[39m=\u001b[39mn_iter, refit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m \u001b[39m#scoring_function\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m rs\u001b[39m.\u001b[39;49mfit(X\u001b[39m.\u001b[39;49mvalues, y\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m     81\u001b[0m \u001b[39m# Training the network\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m#net.fit(X, y)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 97)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[   0.0000, -350.2591, -351.1521,  ...,      -inf,      -inf,\n              -inf],\n        [   1.3047, -348.9544, -349.8474,  ...,      -inf,      -inf,\n              -inf],\n        [ 350.2591,    0.0000,   -0.8930,  ...,      -inf,      -inf,\n              -inf],\n        ...,\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan],\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan],\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan]], grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 83)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[ 0.8371, -1.2598,  8.7843,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000, -2.0969,  7.9472,  ...,    -inf,    -inf,    -inf],\n        [ 2.0969,  0.0000, 10.0441,  ...,    -inf,    -inf,    -inf],\n        ...,\n        [    inf,     inf,     inf,  ...,     nan,     nan,     nan],\n        [    inf,     inf,     inf,  ...,     nan,     nan,     nan],\n        [    inf,     inf,     inf,  ...,     nan,     nan,     nan]],\n       grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 38)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[ 5.1619e-01, -1.0572e-01,  3.4996e+02,  ...,        -inf,\n                 inf,         inf],\n        [ 0.0000e+00, -6.2191e-01,  3.4945e+02,  ...,        -inf,\n                 inf,         inf],\n        [-3.5195e+02, -3.5257e+02, -2.5078e+00,  ...,        -inf,\n                 inf,         inf],\n        ...,\n        [       -inf,        -inf,        -inf,  ...,        -inf,\n                 nan,         nan],\n        [       -inf,        -inf,        -inf,  ...,        -inf,\n                 nan,         nan],\n        [        inf,         inf,         inf,  ...,         nan,\n                 inf,         inf]], grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 29)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[   0.0000,  348.9722,   -4.9261,  ...,      -inf,      -inf,\n              -inf],\n        [   6.1051,  355.0772,    1.1790,  ...,      -inf,      -inf,\n              -inf],\n        [-345.9179,    3.0542, -350.8440,  ...,      -inf,      -inf,\n              -inf],\n        ...,\n        [-372.5119,  -23.5398, -377.4380,  ...,      -inf,      -inf,\n              -inf],\n        [-376.4622,  -27.4900, -381.3882,  ...,      -inf,      -inf,\n              -inf],\n        [      inf,       inf,       inf,  ...,       nan,       nan,\n               nan]], grad_fn=<DivBackward0>)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/regressor.py\", line 91, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1230, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1189, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1101, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1137, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1016, in train_step\n    self._step_optimizer(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 972, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 113, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/optim/sgd.py\", line 125, in step\n    loss = closure()\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1006, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 906, in train_step_single\n    loss = self.get_loss(y_pred, yi, X=Xi, training=True)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/skorch/net.py\", line 1571, in get_loss\n    return self.criterion_(y_pred, y_true)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 397, in forward\n    loss = eh_likelihood_torch_2(input, prediction, bandwidth=self.bandwidth)\n  File \"/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/loss_functions_pytorch.py\", line 369, in eh_likelihood_torch_2\n    integrated_kernel_matrix = rv.cdf(diff)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/normal.py\", line 85, in cdf\n    self._validate_sample(value)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 293, in _validate_sample\n    raise ValueError(\nValueError: Expected value argument (Tensor of shape (128, 51)) to be within the support (Real()) of the distribution Normal(loc: 0.0, scale: 1.0), but found invalid values:\ntensor([[  -0.8326,  351.8084,  353.2236,  ...,  374.8965,      -inf,\n          381.3479],\n        [   0.0000,  352.6410,  354.0562,  ...,  375.7291,      -inf,\n          382.1806],\n        [-350.7828,    1.8582,    3.2735,  ...,   24.9463,      -inf,\n           31.3978],\n        ...,\n        [-382.1806,  -29.5396,  -28.1243,  ...,   -6.4515,      -inf,\n            0.0000],\n        [     -inf,      -inf,      -inf,  ...,      -inf,      -inf,\n              -inf],\n        [      inf,       inf,       inf,  ...,       inf,       nan,\n               inf]], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ictor type <class 'torch.Tensor'>\n",
      "tensor(9.2232) tensor(8.5503, grad_fn=<DivBackward0>) res tensor(-1.5981, grad_fn=<DivBackward0>) tensor(9.4372) tensor(-0.2968, grad_fn=<DivBackward0>)\n",
      "tensor(9.1091, grad_fn=<DivBackward0>) loss tensor(-1.3090, grad_fn=<DivBackward0>) tensor(0.6284, grad_fn=<NegBackward0>)\n",
      "tensor(-0.3301, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.6507, grad_fn=<NegBackward0>)\n",
      "tensor([[ 1.1177e-01, -1.0263e-01],\n",
      "        [ 6.6378e-01,  1.2264e-01],\n",
      "        [ 2.0045e-01,  4.4903e-01],\n",
      "        [ 9.9885e-01,  4.2749e-01],\n",
      "        [-2.6593e-01, -3.9031e-01],\n",
      "        [-5.8369e-02,  2.5767e-01],\n",
      "        [-1.9582e+00,  4.9075e-01],\n",
      "        [ 9.1617e-01,  1.1869e-01],\n",
      "        [ 5.7928e-01, -2.6876e-01],\n",
      "        [-2.8740e-01,  1.8818e-02],\n",
      "        [ 7.6196e-02, -1.2846e-01],\n",
      "        [ 7.3036e-01,  1.1969e-01],\n",
      "        [-4.8280e-01, -2.5260e-01],\n",
      "        [ 2.2954e-02, -2.1771e-01],\n",
      "        [-5.5487e-01, -2.4247e-01],\n",
      "        [ 5.6256e-01,  7.9699e-02],\n",
      "        [-5.2144e-01, -1.7109e-01],\n",
      "        [-1.9876e-01, -1.4839e+00],\n",
      "        [ 2.6668e-01, -6.5670e-02],\n",
      "        [-4.7053e-01,  2.9146e-02],\n",
      "        [-7.9781e-01, -1.8466e-01],\n",
      "        [ 7.5370e-02, -6.8271e-03],\n",
      "        [ 7.7486e-01,  5.5916e-02],\n",
      "        [-4.2779e-01, -7.8623e-01],\n",
      "        [-1.6701e-01, -1.8544e-01],\n",
      "        [ 6.6932e-01,  4.4451e-02],\n",
      "        [ 5.0292e-01,  2.8853e-01],\n",
      "        [-2.6587e-02, -3.8935e-02],\n",
      "        [-1.1121e+00, -5.1570e-01],\n",
      "        [-1.3971e-01,  2.5466e-01],\n",
      "        [ 9.7083e-01, -1.3998e-01],\n",
      "        [-2.5813e-01,  4.1791e-01],\n",
      "        [-5.1910e-01, -1.2995e-01],\n",
      "        [-1.1240e-01, -3.5440e-01],\n",
      "        [-2.9369e-01, -2.1707e-01],\n",
      "        [-9.4818e-01, -3.0484e-01],\n",
      "        [-3.8496e-01,  1.3466e-02],\n",
      "        [-5.7255e-01, -2.6758e-01],\n",
      "        [ 2.8828e-01,  4.5381e-02],\n",
      "        [-4.1530e-01, -2.5949e-01],\n",
      "        [ 6.1698e-01,  2.8449e-01],\n",
      "        [-3.8790e-02, -4.2195e-02],\n",
      "        [ 8.8649e-02,  1.1830e-01],\n",
      "        [ 5.1143e-02, -7.8141e-01],\n",
      "        [-5.1516e-01,  1.3487e-01],\n",
      "        [-5.5665e-01, -5.5771e-01],\n",
      "        [-3.9935e-01, -4.2489e-01],\n",
      "        [-1.2458e-01, -6.2054e-01],\n",
      "        [-1.8219e-01, -4.7259e-01],\n",
      "        [ 7.0486e-02,  2.5931e-01],\n",
      "        [-3.6152e-01,  7.8793e-02],\n",
      "        [-2.1579e-01,  4.7620e-01],\n",
      "        [-8.2972e-01, -2.5105e-01],\n",
      "        [ 2.3857e-01,  4.2827e-02],\n",
      "        [-2.1978e-01, -2.5980e-01],\n",
      "        [-3.5945e-01, -2.1519e-01],\n",
      "        [ 5.0067e-01, -3.8407e-01],\n",
      "        [-1.3324e-01, -7.7600e-01],\n",
      "        [-4.9821e-01, -9.3859e-01],\n",
      "        [ 5.0505e-01,  6.6913e-02],\n",
      "        [ 1.0390e-01,  3.0181e-03],\n",
      "        [-2.0050e-01,  9.4957e-02],\n",
      "        [ 1.5961e-01, -9.8711e-01],\n",
      "        [ 2.6395e-01,  4.6173e-02],\n",
      "        [-5.0174e-02, -1.4293e-01],\n",
      "        [-1.6663e-01,  7.1286e-02],\n",
      "        [-1.0849e-01,  9.2174e-01],\n",
      "        [-3.8453e-02, -8.5961e-01],\n",
      "        [ 9.3651e-02, -5.5450e-01],\n",
      "        [-8.9547e-01, -9.1787e-02],\n",
      "        [-1.4480e+00, -8.4459e-01],\n",
      "        [ 2.3994e-02, -2.9083e-01],\n",
      "        [ 8.4075e-02, -1.5223e-01],\n",
      "        [-3.6009e-01, -1.4762e-01],\n",
      "        [ 4.5889e-01,  2.0047e-01],\n",
      "        [-2.3220e-01, -1.0227e+00],\n",
      "        [-5.4820e-01, -5.8183e-01],\n",
      "        [-3.5641e-01, -1.7151e-01],\n",
      "        [-4.7709e-02, -8.3274e-02],\n",
      "        [ 1.7470e-01, -1.3033e-02],\n",
      "        [-2.9905e-01, -6.5753e-01],\n",
      "        [ 3.5799e-01,  1.0679e-01],\n",
      "        [-1.6902e+00, -5.1242e-02],\n",
      "        [ 5.2215e-01,  4.1579e-02],\n",
      "        [ 6.9067e-01,  9.2662e-02],\n",
      "        [ 4.0436e-01,  3.0345e-02],\n",
      "        [ 5.9457e-01,  2.1205e-01],\n",
      "        [-1.7404e-01, -2.2527e-01],\n",
      "        [-6.4056e-01, -2.9844e-01],\n",
      "        [-5.7460e-01, -1.2155e-01],\n",
      "        [ 1.0216e-01,  1.3618e-01],\n",
      "        [ 3.4258e-01, -4.2780e-01],\n",
      "        [-1.1329e-01, -5.4331e-01],\n",
      "        [-2.8499e-01, -1.4354e+00],\n",
      "        [-7.7616e-01, -2.2719e-01],\n",
      "        [ 6.7114e-01, -2.9016e-02],\n",
      "        [-5.1789e-02, -4.6300e-01],\n",
      "        [ 4.0707e-01,  1.1892e-02],\n",
      "        [ 2.7094e-03,  8.7031e-02],\n",
      "        [ 5.8245e-01,  1.3594e-01],\n",
      "        [-9.4212e-02,  1.1319e-01],\n",
      "        [-1.1485e-01, -1.4273e-01],\n",
      "        [-1.4893e-01, -1.7900e-01],\n",
      "        [-4.9271e-01, -1.6992e-01],\n",
      "        [ 1.3907e-01,  1.4032e-01],\n",
      "        [ 2.2486e-01,  1.4049e-01],\n",
      "        [-1.3992e-01, -1.4676e-01],\n",
      "        [-5.7395e-01, -4.8650e-03],\n",
      "        [ 8.4018e-02, -5.7027e-01],\n",
      "        [ 1.4864e-01, -3.3886e-01],\n",
      "        [-1.4529e-02,  9.1278e-02],\n",
      "        [-4.6641e-01, -7.1280e-01],\n",
      "        [-1.2540e+00, -7.6267e-01],\n",
      "        [ 1.0293e-01,  1.2665e-02],\n",
      "        [ 2.5805e-01, -3.3257e-02],\n",
      "        [-7.6504e-01, -5.9151e-01],\n",
      "        [-4.1636e-01,  1.0986e-03],\n",
      "        [-4.3776e-01, -2.8103e-01],\n",
      "        [ 1.1196e-01, -1.5943e-02],\n",
      "        [ 6.4301e-01, -2.6236e-01],\n",
      "        [ 4.9771e-01, -3.1244e-01],\n",
      "        [-1.1857e+00,  3.9032e-01],\n",
      "        [ 8.6136e-01,  7.6904e-02],\n",
      "        [ 4.0518e-01,  8.2936e-02],\n",
      "        [ 2.9787e-01, -3.7885e-01],\n",
      "        [ 6.1596e-01,  2.0682e-01],\n",
      "        [ 2.4553e-01, -1.0348e-01],\n",
      "        [ 2.5706e-01, -3.9774e-01]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "res res tensor(4.9750) tensor(4.3393, grad_fn=<DivBackward0>) tensor(-1.8068, grad_fn=<DivBackward0>) tensor(-0.4529, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.7182, grad_fn=<NegBackward0>)\n",
      "tensor([[-2.1465e-01, -7.6860e-02],\n",
      "        [ 1.4568e-01, -1.0585e-02],\n",
      "        [-7.9301e-02, -7.3381e-01],\n",
      "        [ 1.6752e-01,  3.1101e-01],\n",
      "        [ 3.3315e-01, -3.0181e-01],\n",
      "        [-3.4528e-01, -3.0238e-01],\n",
      "        [ 3.6042e-01,  2.8708e-01],\n",
      "        [ 1.4679e-01,  2.4069e-01],\n",
      "        [-1.2551e-01, -4.4389e-02],\n",
      "        [-1.3458e-01,  3.6398e-02],\n",
      "        [-3.9372e-01,  3.5169e-01],\n",
      "        [ 1.4577e-01,  2.2744e-01],\n",
      "        [-2.0749e-01, -1.7981e-02],\n",
      "        [ 1.6393e-01,  2.3007e-01],\n",
      "        [-1.4531e-01,  2.8679e-01],\n",
      "        [-2.2003e-01,  3.4885e-01],\n",
      "        [-1.1418e-01,  1.0890e-01],\n",
      "        [-6.5077e-01,  1.7186e-01],\n",
      "        [-4.2912e-01, -2.3535e-02],\n",
      "        [-2.1904e-01,  3.0808e-01],\n",
      "        [-2.7250e-01, -6.4152e-01],\n",
      "        [-4.9068e-01, -2.8489e-02],\n",
      "        [-1.9258e-01,  6.0507e-01],\n",
      "        [ 2.3837e-01,  1.4191e-01],\n",
      "        [-6.1533e-02,  2.4231e-01],\n",
      "        [-1.4094e-01,  1.7364e-01],\n",
      "        [-1.1199e-01,  5.0603e-01],\n",
      "        [-1.1405e-01,  2.7683e-02],\n",
      "        [ 2.0766e-01,  4.2045e-01],\n",
      "        [-7.2757e-01, -5.6704e-01],\n",
      "        [ 3.3967e-02, -4.6755e-02],\n",
      "        [ 3.0075e-01,  3.6668e-01],\n",
      "        [-2.5546e-01, -2.7801e-01],\n",
      "        [-6.8566e-01, -8.3926e-03],\n",
      "        [-1.0007e+00, -2.2145e-01],\n",
      "        [-3.1042e-01, -1.5121e-01],\n",
      "        [-2.4463e-01,  5.2105e-02],\n",
      "        [ 3.8668e-01,  3.2866e-01],\n",
      "        [-4.7214e-01, -3.5316e-01],\n",
      "        [-4.2340e-01, -4.5554e-02],\n",
      "        [ 2.5312e-01,  1.4642e-01],\n",
      "        [-1.9042e-01, -2.3350e-02],\n",
      "        [ 2.9894e-02,  3.1332e-01],\n",
      "        [-5.6082e-01, -3.4480e-01],\n",
      "        [-3.0128e-02, -5.4688e-01],\n",
      "        [ 2.6074e-01,  9.6540e-02],\n",
      "        [-4.2059e-01,  2.3286e-01],\n",
      "        [-5.1334e-03,  1.4752e-02],\n",
      "        [ 2.7678e-01,  8.4555e-01],\n",
      "        [ 1.8954e-01,  4.5580e-01],\n",
      "        [-3.5214e-01, -2.8544e-01],\n",
      "        [-1.5132e-01,  6.1995e-03],\n",
      "        [-1.5343e-01, -1.9856e-02],\n",
      "        [-2.2711e-02, -2.0742e-01],\n",
      "        [-1.5081e-01, -1.6014e-01],\n",
      "        [ 2.9322e-03, -1.2074e-01],\n",
      "        [ 1.7137e-01,  2.0279e-01],\n",
      "        [ 1.7192e-01,  2.4626e-01],\n",
      "        [-3.1305e-01, -1.0029e-01],\n",
      "        [-1.0126e-01,  8.6154e-02],\n",
      "        [-2.1316e-01,  4.6918e-04],\n",
      "        [-1.0595e-01,  5.7600e-02],\n",
      "        [-1.8380e-01, -1.3214e-02],\n",
      "        [-4.8509e-01, -5.0822e-01],\n",
      "        [-6.1739e-02,  6.3620e-03],\n",
      "        [-2.7981e-01, -3.1762e-01],\n",
      "        [-5.8525e-01, -5.2137e-01],\n",
      "        [-2.3280e-01, -1.6132e-02],\n",
      "        [-3.0825e-01, -6.5980e-02],\n",
      "        [ 4.5045e-01,  4.1951e-01],\n",
      "        [-1.3790e-01,  3.8357e-02],\n",
      "        [-9.1956e-02,  5.9212e-02],\n",
      "        [ 1.4038e-02,  3.4975e-01],\n",
      "        [ 5.4186e-02,  3.9639e-01],\n",
      "        [-3.2002e-01,  3.5795e-01],\n",
      "        [ 6.0121e-02, -3.9990e-01],\n",
      "        [-1.6947e-01, -3.5195e-01],\n",
      "        [-6.5140e-01, -6.8934e-01],\n",
      "        [-2.0625e-01,  9.1264e-02],\n",
      "        [-4.1193e-01, -5.6953e-02],\n",
      "        [-4.8596e-01, -7.4048e-02],\n",
      "        [-1.4866e-01, -6.5816e-03],\n",
      "        [ 2.3048e-01,  1.6086e-01],\n",
      "        [-2.8505e-01, -5.6427e-02],\n",
      "        [-2.2601e-01,  5.4142e-02],\n",
      "        [-6.2708e-01, -7.1120e-01],\n",
      "        [ 1.9664e-01,  3.0852e-01],\n",
      "        [-5.5524e-01, -2.0957e-01],\n",
      "        [ 1.4961e-01,  1.2499e-01],\n",
      "        [ 2.4295e-01,  6.2990e-02],\n",
      "        [-1.2299e-01,  2.4320e-01],\n",
      "        [-3.7247e-01, -1.5241e-01],\n",
      "        [-6.4465e-02,  1.1912e-01],\n",
      "        [-2.0778e-01, -8.0057e-02],\n",
      "        [-2.9737e-01, -1.2415e-01],\n",
      "        [-1.3068e-01, -3.3312e-01],\n",
      "        [-7.4590e-02,  7.5366e-01],\n",
      "        [ 4.8337e-01, -3.9440e-01],\n",
      "        [-2.1866e-01,  1.1532e-01],\n",
      "        [-2.2391e-03, -6.2844e-01],\n",
      "        [-4.0907e-02,  4.3891e-01],\n",
      "        [-5.7022e-01, -1.2692e-01],\n",
      "        [ 2.8531e-01,  1.0667e-01],\n",
      "        [-1.6270e-01,  2.6648e-02],\n",
      "        [ 4.7871e-01,  5.2966e-01],\n",
      "        [-1.2973e-01,  8.3385e-02],\n",
      "        [-1.7678e-01,  3.4342e-02],\n",
      "        [-4.9214e-01, -6.8425e-02],\n",
      "        [-8.1281e-02,  2.6145e-02],\n",
      "        [ 1.8164e-01, -1.9469e-01],\n",
      "        [-5.2316e-02,  3.8552e-01],\n",
      "        [-5.0003e-01, -1.7629e-01],\n",
      "        [-1.3916e-01,  1.8908e-02],\n",
      "        [ 1.7671e-01,  4.2559e-01],\n",
      "        [ 1.0958e-01,  3.0033e-01],\n",
      "        [-1.8179e-01, -4.9559e-01],\n",
      "        [-4.3445e-01, -8.3374e-01],\n",
      "        [ 3.4159e-01,  6.0408e-01],\n",
      "        [-1.7133e-01,  1.6455e-04],\n",
      "        [-1.1018e-01, -1.4833e-02],\n",
      "        [-3.2215e-02,  3.1628e-01],\n",
      "        [ 1.6418e-01,  1.7312e-01],\n",
      "        [ 1.2055e-01, -1.1474e-01],\n",
      "        [-1.1459e-01,  1.1174e-01],\n",
      "        [-2.3882e-01, -2.8165e-02],\n",
      "        [-1.1572e-01, -4.1909e-02],\n",
      "        [ 2.1948e-01,  9.4903e-02],\n",
      "        [-1.2118e-01,  1.3604e-01]], grad_fn=<AddmmBackward0>)tensor([[-1.2461e+00,  4.1367e-01],\n",
      "        [-9.9708e-01, -1.0445e-01],\n",
      "        [-1.0060e+00, -6.8698e-02],\n",
      "        [-3.5310e-01,  4.6234e-01],\n",
      "        [-1.3034e+00, -9.6623e-01],\n",
      "        [-1.0770e+00,  3.2567e-02],\n",
      "        [-1.4894e+00,  7.7448e-01],\n",
      "        [-8.9874e-01,  3.4340e-01],\n",
      "        [ 8.0554e-01, -1.2975e-01],\n",
      "        [-1.6017e+00, -5.9544e-02],\n",
      "        [-1.5962e+00, -8.4568e-01],\n",
      "        [ 1.3078e-01,  1.3888e-01],\n",
      "        [-2.9905e-01,  1.7266e-01],\n",
      "        [-4.0238e-01,  1.0098e-01],\n",
      "        [ 7.0227e-01, -1.9611e-01],\n",
      "        [-1.2342e+00, -4.1637e-02],\n",
      "        [-1.9657e+00,  1.9857e-01],\n",
      "        [ 1.4257e-01,  2.9894e-01],\n",
      "        [-7.1398e-01,  1.1059e-01],\n",
      "        [-1.2353e+00, -2.7584e-01],\n",
      "        [-1.4977e+00, -6.9436e-02],\n",
      "        [-6.8418e-01,  2.2965e-01],\n",
      "        [-7.4248e-01,  3.4530e-01],\n",
      "        [ 4.2679e-01, -9.2569e-02],\n",
      "        [ 9.5471e-01,  6.8060e-01],\n",
      "        [-9.5524e-01, -6.1906e-02],\n",
      "        [ 5.8650e-01, -4.0363e-01],\n",
      "        [-1.8263e+00,  9.5653e-02],\n",
      "        [-6.8158e-01,  3.5317e-01],\n",
      "        [ 1.0177e-01,  2.0090e-02],\n",
      "        [-2.0880e+00,  8.5845e-02],\n",
      "        [-8.0521e-01,  3.0892e-01],\n",
      "        [-1.1356e+00, -2.4191e-01],\n",
      "        [-6.3688e+00,  9.2702e-01],\n",
      "        [-1.6036e+00,  2.7808e-01],\n",
      "        [ 9.6219e-01, -3.8000e-01],\n",
      "        [-5.9649e-01,  1.6579e-01],\n",
      "        [ 7.6804e-01,  5.1652e-02],\n",
      "        [ 1.7184e-01, -6.3020e-02],\n",
      "        [ 1.0811e+00,  5.2540e-01],\n",
      "        [-9.2375e-01,  1.2252e-01],\n",
      "        [ 2.8581e-01,  2.2493e-01],\n",
      "        [-1.1001e-01, -3.8682e-01],\n",
      "        [ 2.4635e-01,  3.1765e-01],\n",
      "        [-1.8095e+00, -9.7367e-03],\n",
      "        [-1.3036e+00,  5.6028e-02],\n",
      "        [-1.1324e+00,  1.0526e-01],\n",
      "        [-1.1217e+00,  3.0318e-01],\n",
      "        [-1.7763e+00, -1.3403e-01],\n",
      "        [-2.8062e-01,  1.5200e-01],\n",
      "        [-7.7211e-01, -4.3103e-02],\n",
      "        [-1.0019e+00,  4.1190e-01],\n",
      "        [-1.1219e+00, -3.2722e-01],\n",
      "        [-3.3413e-02, -2.3574e-01],\n",
      "        [-2.1613e+00,  3.0801e-01],\n",
      "        [-3.2396e-01,  6.4798e-01],\n",
      "        [-3.8806e-01, -3.2087e-01],\n",
      "        [-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8065e-01,  1.4453e-01],\n",
      "        [-1.1345e+00,  6.0600e-02],\n",
      "        [ 1.0419e+00, -4.9611e-02],\n",
      "        [-1.3106e-01,  2.1022e-01],\n",
      "        [-3.8234e-01,  2.3816e-01],\n",
      "        [-2.1864e+00,  5.8654e-02],\n",
      "        [ 2.5890e-01,  2.3628e-01],\n",
      "        [-1.7154e+00, -2.0312e-01],\n",
      "        [-2.7808e+00,  1.0340e-01],\n",
      "        [ 1.0903e-01,  3.1776e-01],\n",
      "        [-9.6534e-01, -2.6735e-01],\n",
      "        [-8.6385e-01, -6.7720e-02],\n",
      "        [ 6.7001e-01, -9.1338e-02],\n",
      "        [ 2.4555e-01, -4.9717e-02],\n",
      "        [-1.2007e+00,  7.3372e-02],\n",
      "        [-1.6577e-01,  2.6373e-01],\n",
      "        [ 3.2777e-01,  2.5255e-01],\n",
      "        [ 1.9776e-01, -2.0660e-01],\n",
      "        [-5.5177e-01,  4.5996e-02],\n",
      "        [-1.1964e+00, -3.5423e-01],\n",
      "        [-4.2305e-01, -1.4762e-01],\n",
      "        [ 3.9070e-02,  3.9144e-01],\n",
      "        [ 3.4601e-01,  2.4604e-01],\n",
      "        [-9.2957e-02,  1.9043e-01],\n",
      "        [-1.5754e+00, -1.0251e-01],\n",
      "        [ 1.1326e+00, -1.6381e-01],\n",
      "        [-9.6148e-01, -9.7884e-05],\n",
      "        [-1.2273e+00, -1.2824e-01],\n",
      "        [ 1.5595e-01, -4.6797e-01],\n",
      "        [ 1.8470e-01,  1.7699e-01],\n",
      "        [-7.8245e-01, -3.1011e-01],\n",
      "        [-3.9739e-01, -4.6232e-01],\n",
      "        [-3.2287e-01,  7.3862e-02],\n",
      "        [-2.4557e+00,  5.4975e-01],\n",
      "        [-1.8581e+00, -2.8945e-01],\n",
      "        [-2.7551e-01, -4.5248e-01],\n",
      "        [ 1.7068e-01,  2.1074e-01],\n",
      "        [ 7.1032e-01, -1.4837e-01],\n",
      "        [-4.8462e-02,  2.6251e-01],\n",
      "        [-1.6329e+00,  3.1838e-01],\n",
      "        [-7.6302e-01,  1.2758e-01],\n",
      "        [ 6.2041e-01, -1.9345e-01],\n",
      "        [-4.0945e-01,  8.4530e-02],\n",
      "        [-1.1666e+00,  1.8143e-01],\n",
      "        [ 4.1177e-01,  3.0299e-01],\n",
      "        [-1.9272e+00, -3.1056e-01],\n",
      "        [-1.1432e-01,  1.6571e-01],\n",
      "        [-1.5798e+00, -3.3549e-01],\n",
      "        [-1.8139e+00, -1.1827e+00],\n",
      "        [-8.0291e-01,  3.4178e-01],\n",
      "        [-1.5648e+00,  4.6677e-01],\n",
      "        [ 1.8078e-01,  1.8581e-01],\n",
      "        [ 2.0844e-01,  1.9805e-01],\n",
      "        [-9.0363e-01,  7.3792e-02],\n",
      "        [ 2.9417e-01,  2.1802e-01],\n",
      "        [-8.5836e-01, -5.8332e-01],\n",
      "        [-7.5440e-02, -2.2912e-01],\n",
      "        [ 4.7997e-02, -2.4023e-02],\n",
      "        [ 1.3653e-01,  2.2008e-01],\n",
      "        [ 1.0387e+00, -6.8855e-01],\n",
      "        [ 7.5631e-02,  1.9053e-01],\n",
      "        [-7.9988e-01,  5.2881e-01],\n",
      "        [-1.8214e+00,  3.7890e-01],\n",
      "        [-3.3223e-01,  1.3590e-01],\n",
      "        [-1.1357e-01, -1.2594e-01],\n",
      "        [ 3.1833e-01,  1.1494e+00],\n",
      "        [-1.5468e-01, -1.0522e-01],\n",
      "        [-2.3016e-01, -7.1515e-01],\n",
      "        [-3.1263e-01, -7.5261e-02],\n",
      "        [-2.3479e-02, -9.5571e-01],\n",
      "        [-1.0667e+00,  1.5483e-01]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(12.8000) res tensor(12.4454, grad_fn=<DivBackward0>) tensor(-1.2369, grad_fn=<DivBackward0>) tensor(-0.3138, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.5685, grad_fn=<NegBackward0>)\n",
      "tensor([[-0.5862, -0.3300],\n",
      "        [ 0.1367, -0.0047],\n",
      "        [ 0.0619, -0.2062],\n",
      "        [-1.4437, -0.5113],\n",
      "        [ 0.4172,  0.1951],\n",
      "        [ 0.1896, -0.0936],\n",
      "        [-0.5177, -0.1823],\n",
      "        [ 0.7561,  0.0028],\n",
      "        [-0.4701, -0.1546],\n",
      "        [-0.0596,  0.0295],\n",
      "        [-0.3559, -0.4847],\n",
      "        [-0.3529, -0.2695],\n",
      "        [-1.0117, -0.9853],\n",
      "        [-0.0703, -0.5372],\n",
      "        [-1.3115, -0.5085],\n",
      "        [ 0.1979,  0.1673],\n",
      "        [ 0.2730,  0.0279],\n",
      "        [ 0.2301, -0.6252],\n",
      "        [ 0.6596,  0.1421],\n",
      "        [ 0.9996, -0.0301],\n",
      "        [ 0.3006,  0.0082],\n",
      "        [-0.1606, -0.0364],\n",
      "        [-0.2098, -0.4405],\n",
      "        [ 0.0869, -0.9593],\n",
      "        [-0.6662, -0.3283],\n",
      "        [-0.0297, -0.2072],\n",
      "        [ 0.0652, -0.4584],\n",
      "        [-0.3188, -0.0557],\n",
      "        [ 0.0071,  0.0436],\n",
      "        [-0.6347, -0.3181],\n",
      "        [ 0.2643, -0.0856],\n",
      "        [ 0.5220,  0.3004],\n",
      "        [ 0.6403,  0.1945],\n",
      "        [ 1.3901,  0.8250],\n",
      "        [-0.0716, -0.1630],\n",
      "        [-0.6185,  0.0901],\n",
      "        [-0.1506,  0.0149],\n",
      "        [ 0.5414, -0.5735],\n",
      "        [-0.0314,  0.0354],\n",
      "        [-0.7613, -0.4017],\n",
      "        [ 0.1510,  0.0667],\n",
      "        [-0.6822, -0.3334],\n",
      "        [-0.4908, -0.1235],\n",
      "        [ 0.7745, -0.9060],\n",
      "        [ 0.1790,  0.1753],\n",
      "        [ 0.2654,  0.0870],\n",
      "        [ 0.3349,  0.0453],\n",
      "        [-0.8392,  0.0852],\n",
      "        [ 0.6711,  0.1955],\n",
      "        [-0.5990,  0.0208],\n",
      "        [-0.7034,  0.0089],\n",
      "        [ 0.1979, -0.3231],\n",
      "        [ 0.8827,  0.3056],\n",
      "        [-0.2503, -0.0753],\n",
      "        [ 0.1523,  0.0460],\n",
      "        [-0.3659, -0.1808],\n",
      "        [ 0.4425,  0.3862],\n",
      "        [-0.2257, -0.4136],\n",
      "        [-0.5843, -0.3251],\n",
      "        [-0.3313, -0.4179],\n",
      "        [-0.4625, -0.5046],\n",
      "        [-0.1034, -0.0339],\n",
      "        [-0.1752, -0.2872],\n",
      "        [-0.5673,  0.1945],\n",
      "        [ 0.2527,  0.1743],\n",
      "        [ 0.7596, -0.4362],\n",
      "        [ 0.2584, -0.2180],\n",
      "        [ 0.0246,  0.1415],\n",
      "        [ 0.2755, -0.7168],\n",
      "        [-0.6606, -0.2943],\n",
      "        [-0.0423, -0.6241],\n",
      "        [ 0.3390,  0.1336],\n",
      "        [-0.3073, -0.0440],\n",
      "        [-1.1013, -0.0687],\n",
      "        [ 0.1986,  0.1011],\n",
      "        [-0.7309,  0.0848],\n",
      "        [ 0.8590, -0.1037],\n",
      "        [-0.1408,  0.0142],\n",
      "        [ 0.0315, -0.3462],\n",
      "        [-0.0573,  0.0082],\n",
      "        [-0.5745, -0.5822],\n",
      "        [-0.0980,  0.1061],\n",
      "        [-0.5052,  0.0029],\n",
      "        [ 0.1897, -0.8132],\n",
      "        [-0.3825, -0.2027],\n",
      "        [-0.3188, -0.1084],\n",
      "        [-0.3783, -0.2514],\n",
      "        [-0.0358,  0.2535],\n",
      "        [-0.1764, -0.1593],\n",
      "        [-0.2445, -0.6188],\n",
      "        [-0.1218, -0.0919],\n",
      "        [ 0.4656, -0.2472],\n",
      "        [ 0.0062, -0.6803],\n",
      "        [-0.6077, -0.2826],\n",
      "        [-0.0031, -0.4349],\n",
      "        [-0.9817, -0.3818],\n",
      "        [ 0.1873,  0.1050],\n",
      "        [ 0.2506, -0.6845],\n",
      "        [ 0.1321, -0.5182],\n",
      "        [-0.6209, -0.4427],\n",
      "        [ 0.5496, -0.0816],\n",
      "        [-0.4748, -0.7265],\n",
      "        [-0.1949, -0.0843],\n",
      "        [-0.3247, -0.1911],\n",
      "        [ 0.3543, -0.3038],\n",
      "        [ 0.6328,  0.2150],\n",
      "        [-0.1870, -0.1045],\n",
      "        [ 0.5189,  0.2856],\n",
      "        [-0.3914, -0.2201],\n",
      "        [-0.2331,  0.0132],\n",
      "        [-0.3156, -0.1856],\n",
      "        [ 0.3835,  0.0778],\n",
      "        [ 0.6182,  0.1143],\n",
      "        [-0.1678, -0.0021],\n",
      "        [-0.6877,  0.2093],\n",
      "        [ 0.0674,  0.4085],\n",
      "        [-0.7822,  0.2735],\n",
      "        [ 0.0104,  0.0679],\n",
      "        [-0.3735, -0.7412],\n",
      "        [-0.1483, -0.0929],\n",
      "        [ 0.8778,  0.0288],\n",
      "        [-0.4202, -0.1258],\n",
      "        [-0.6309, -0.3024],\n",
      "        [-0.4531, -0.2204],\n",
      "        [-0.2665, -0.5614],\n",
      "        [-0.2759,  0.2766],\n",
      "        [-0.2349, -0.5225],\n",
      "        [ 0.2069, -0.3261]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "res tensor(10.0294) tensor(9.4231, grad_fn=<DivBackward0>) tensor(-1.7172, grad_fn=<DivBackward0>) tensor(-0.3691, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.7418, grad_fn=<NegBackward0>)\n",
      "tensor([[ 6.8717e-02, -3.6116e-02],\n",
      "        [-1.2169e+00,  5.4125e-02],\n",
      "        [-6.3999e-01, -7.7432e-02],\n",
      "        [-6.0371e-01,  7.9759e-01],\n",
      "        [-1.5512e+00,  5.2914e-01],\n",
      "        [-2.0167e+00, -5.7294e-02],\n",
      "        [ 2.1926e-01,  8.8560e-02],\n",
      "        [-6.6415e-01,  6.1759e-02],\n",
      "        [-9.2231e-01,  4.7895e-01],\n",
      "        [-1.6525e+00,  1.5604e-01],\n",
      "        [ 2.8618e-01, -5.1483e-01],\n",
      "        [-3.6989e-01,  2.7273e-01],\n",
      "        [ 6.6524e-01,  5.5648e-01],\n",
      "        [ 2.4414e-01, -1.6487e-01],\n",
      "        [-3.7530e-01,  2.4898e-01],\n",
      "        [-6.1033e-01, -1.1612e-01],\n",
      "        [-8.8522e-01, -1.8437e-01],\n",
      "        [ 3.5108e-01, -1.1233e-01],\n",
      "        [-3.4037e-01,  6.6217e-02],\n",
      "        [-9.9411e-02, -1.0915e-01],\n",
      "        [-1.4930e+00, -4.4105e-01],\n",
      "        [-4.5924e-01,  1.2384e-01],\n",
      "        [-1.6331e+00,  4.6302e-01],\n",
      "        [ 5.1417e-01, -1.7305e-01],\n",
      "        [-8.8326e-01, -3.6542e-01],\n",
      "        [-6.6378e-01, -5.9597e-01],\n",
      "        [-3.6373e-01, -2.2454e-01],\n",
      "        [-5.5352e-01,  4.7530e-01],\n",
      "        [-2.2315e-01, -4.8305e-01],\n",
      "        [ 7.4629e-01, -2.4542e-01],\n",
      "        [-3.3968e-01,  6.2697e-01],\n",
      "        [-9.8659e-01,  2.1612e-02],\n",
      "        [-1.2324e+00,  2.5095e-01],\n",
      "        [-1.5192e+00,  5.5688e-01],\n",
      "        [-1.7747e+00,  5.7600e-01],\n",
      "        [ 6.9044e-01, -9.3911e-01],\n",
      "        [-2.7140e+00,  3.8032e-01],\n",
      "        [-7.8132e-01, -3.1073e-01],\n",
      "        [-1.0364e+00, -4.8306e-01],\n",
      "        [ 6.0746e-03,  4.3374e-01],\n",
      "        [-1.7528e-02, -1.1963e+00],\n",
      "        [-7.6289e-01,  3.4439e-01],\n",
      "        [ 7.7072e-03,  1.4876e-01],\n",
      "        [-2.2947e-01, -1.4526e-01],\n",
      "        [-1.3567e+00, -1.2469e-01],\n",
      "        [ 3.4718e-01, -1.2562e-01],\n",
      "        [-1.0610e-01,  1.7270e-01],\n",
      "        [ 1.0773e+00, -6.3871e-01],\n",
      "        [-3.9593e-01, -5.0134e-01],\n",
      "        [-5.3785e-01,  6.4969e-02],\n",
      "        [-8.0571e-01,  1.7268e-01],\n",
      "        [ 1.3646e-01,  3.2247e-01],\n",
      "        [-4.9544e-01, -1.7688e-01],\n",
      "        [-3.8043e-01,  4.0168e-02],\n",
      "        [-8.4028e-01,  9.9297e-03],\n",
      "        [-6.9284e-02, -1.4117e-01],\n",
      "        [-1.1166e+00, -3.7791e-02],\n",
      "        [-2.1374e+00, -3.8095e-02],\n",
      "        [ 6.7511e-02,  2.2118e-01],\n",
      "        [-4.6621e-01,  1.4579e-01],\n",
      "        [ 3.7419e-01,  4.3586e-01],\n",
      "        [-2.6887e+00,  6.6962e-01],\n",
      "        [ 1.5892e-01,  1.9832e-01],\n",
      "        [-1.9794e+00, -1.6321e+00],\n",
      "        [-1.2636e+00,  2.7312e-01],\n",
      "        [-1.3172e-03,  3.8797e-01],\n",
      "        [ 5.3804e-02, -4.4966e-01],\n",
      "        [ 3.7633e-01, -2.7633e-01],\n",
      "        [-9.7644e-01, -2.6946e-01],\n",
      "        [ 9.7030e-01, -8.4643e-01],\n",
      "        [-9.1313e-01,  4.3125e-01],\n",
      "        [-7.0771e-01,  7.7964e-02],\n",
      "        [-1.0319e+00,  3.7442e-01],\n",
      "        [-1.0699e+00,  5.2232e-01],\n",
      "        [-2.4852e+00, -1.4052e-01],\n",
      "        [-2.2861e+00,  2.7919e-02],\n",
      "        [-1.3077e+00,  2.1892e-01],\n",
      "        [ 5.9597e-01, -4.6046e-01],\n",
      "        [-3.3070e-01, -1.3410e-01],\n",
      "        [ 1.1016e+00, -4.3794e-01],\n",
      "        [-2.0712e-01,  1.8942e-01],\n",
      "        [-3.6101e-01,  1.5845e-01],\n",
      "        [ 4.9932e-01,  2.8895e-01],\n",
      "        [-1.4408e+00, -2.8978e-01],\n",
      "        [-1.3411e+00,  7.3059e-01],\n",
      "        [-4.8345e-01,  9.5798e-02],\n",
      "        [-5.5306e-01,  5.1540e-01],\n",
      "        [-1.1549e-01,  2.0371e-01],\n",
      "        [-1.2099e+00,  2.8385e-04],\n",
      "        [-1.1958e-01,  8.0094e-02],\n",
      "        [-1.2850e+00,  6.3851e-02],\n",
      "        [-8.9495e-01, -1.6375e-01],\n",
      "        [-6.9075e-01, -1.5453e-01],\n",
      "        [-4.9221e-01,  2.3376e-01],\n",
      "        [-3.4273e-01,  7.5391e-01],\n",
      "        [-8.9120e-01, -4.4878e-01],\n",
      "        [-3.7541e-01,  2.5094e-01],\n",
      "        [-1.6473e-01,  2.0520e-01],\n",
      "        [-4.5890e-01, -1.4081e-01],\n",
      "        [ 6.4347e-01,  3.0082e-01],\n",
      "        [-1.4262e+00,  3.8410e-01],\n",
      "        [-4.3212e-01, -3.6754e-01],\n",
      "        [-9.7259e-01,  4.3326e-01],\n",
      "        [-2.8925e+00,  1.3708e-01],\n",
      "        [-1.8534e+00, -1.4479e+00],\n",
      "        [ 6.3113e-01, -2.4581e-01],\n",
      "        [-1.0132e+00,  2.0304e-01],\n",
      "        [-1.4802e-01, -1.9079e-01],\n",
      "        [-8.1884e-01,  1.4239e-01],\n",
      "        [-1.2815e+00,  4.8117e-01],\n",
      "        [-4.8749e-01, -9.9834e-02],\n",
      "        [-1.1403e+00,  4.3804e-01],\n",
      "        [-1.1581e+00,  1.2913e-01],\n",
      "        [-9.3326e-01, -1.5243e-01],\n",
      "        [ 4.0036e-01,  2.8694e-01],\n",
      "        [-1.2563e-01,  7.5974e-01],\n",
      "        [ 1.6940e-01, -2.0605e-01],\n",
      "        [-1.2574e+00, -3.6204e-02],\n",
      "        [-2.2707e-01,  4.9600e-01],\n",
      "        [ 6.4110e-03,  1.6996e-01],\n",
      "        [-1.1227e+00, -1.4575e-01],\n",
      "        [-1.4882e+00,  5.3446e-01],\n",
      "        [-1.9439e+00,  1.1519e-01],\n",
      "        [ 1.3797e-01,  2.2564e-01],\n",
      "        [-1.6737e-01, -4.9807e-01],\n",
      "        [-2.1480e+00,  6.6650e-01],\n",
      "        [-3.0101e-01,  8.0028e-02],\n",
      "        [-7.9168e-01,  2.5254e-01]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "res tensor([[-1.9066e-01, -1.5443e-01],\n",
      "        [ 2.5147e-01,  3.6856e-01],\n",
      "        [-2.4362e-01, -8.7558e-02],\n",
      "        [-8.2466e-01, -1.1137e+00],\n",
      "        [-1.4733e-01, -5.3028e-01],\n",
      "        [ 1.4551e-01, -9.6325e-03],\n",
      "        [ 7.4920e-02, -5.6592e-01],\n",
      "        [-7.9593e-02, -3.9119e-02],\n",
      "        [ 2.6590e-01, -6.7118e-01],\n",
      "        [ 2.6275e-01,  1.4772e-01],\n",
      "        [-3.4995e-01, -2.2373e-01],\n",
      "        [-2.4601e-01,  2.1625e-01],\n",
      "        [-1.0740e-01, -4.4988e-02],\n",
      "        [-4.3986e-01, -5.1597e-01],\n",
      "        [-3.2609e-01, -5.0261e-01],\n",
      "        [-3.1134e-01, -1.8755e-01],\n",
      "        [ 1.7029e-01, -3.0983e-02],\n",
      "        [-1.1613e-01, -4.5947e-02],\n",
      "        [-4.0333e-01, -2.9666e-01],\n",
      "        [-3.6505e-02,  5.7698e-02],\n",
      "        [ 2.5071e-01,  1.7585e-01],\n",
      "        [-1.7420e-01, -1.5866e-01],\n",
      "        [-2.8832e-02, -2.3924e-01],\n",
      "        [-4.4100e-01, -1.7764e-01],\n",
      "        [-1.7685e-01, -3.9979e-01],\n",
      "        [-4.3364e-01,  8.3094e-02],\n",
      "        [ 2.1822e-01, -2.3486e-01],\n",
      "        [ 1.3638e-01, -1.7897e-01],\n",
      "        [-1.3060e-01, -7.6332e-01],\n",
      "        [ 1.4092e-01,  2.2440e-02],\n",
      "        [-4.4511e-01, -4.4041e-01],\n",
      "        [ 3.3979e-01,  2.1189e-01],\n",
      "        [ 1.1438e-02, -1.0714e-01],\n",
      "        [-1.1269e-01,  1.6762e-01],\n",
      "        [-2.0094e-01,  4.8530e-02],\n",
      "        [-3.6801e-01, -4.3765e-01],\n",
      "        [-4.6225e-01, -7.2216e-01],\n",
      "        [-2.4276e-01,  1.9456e-01],\n",
      "        [ 3.2781e-01,  1.4947e-01],\n",
      "        [-8.9097e-01,  2.6402e-01],\n",
      "        [ 1.4689e-01,  1.3802e-01],\n",
      "        [-7.9260e-01, -7.5738e-01],\n",
      "        [-2.6336e-01, -2.6263e-01],\n",
      "        [ 5.2710e-01, -8.8154e-02],\n",
      "        [ 7.0424e-01,  1.4818e-01],\n",
      "        [-4.0808e-01, -4.4585e-01],\n",
      "        [ 2.4493e-01, -7.6578e-02],\n",
      "        [-3.3393e-01, -1.9753e-01],\n",
      "        [ 2.9797e-01,  2.0814e-01],\n",
      "        [-6.2547e-02, -1.7620e-01],\n",
      "        [-5.2972e-01, -2.5996e-01],\n",
      "        [ 1.7420e-01, -2.4654e-02],\n",
      "        [-1.0526e-02, -5.7730e-01],\n",
      "        [ 8.3120e-02, -6.5530e-01],\n",
      "        [-4.4331e-01, -2.3980e-01],\n",
      "        [ 1.1058e-02, -3.7734e-01],\n",
      "        [-5.1346e-02, -5.9959e-02],\n",
      "        [ 1.5142e-01,  7.2087e-02],\n",
      "        [-6.9821e-01, -6.4369e-01],\n",
      "        [ 1.5383e-01,  8.5604e-02],\n",
      "        [-3.6371e-01, -2.4745e-01],\n",
      "        [ 1.5624e-01, -3.6695e-01],\n",
      "        [-4.0129e-02, -1.2777e-02],\n",
      "        [ 5.6293e-01,  2.8337e-01],\n",
      "        [ 1.9074e-01, -5.8796e-01],\n",
      "        [-1.1661e+00, -1.6952e-01],\n",
      "        [-5.5988e-01, -1.3552e+00],\n",
      "        [-3.7586e-01,  1.9974e-01],\n",
      "        [-2.5719e-01, -4.5906e-01],\n",
      "        [-5.0367e-01, -3.0860e-01],\n",
      "        [-7.0723e-02,  8.4232e-02],\n",
      "        [-2.0354e-01,  1.2472e-01],\n",
      "        [ 1.2442e-01, -3.5536e-02],\n",
      "        [ 6.4810e-01, -7.2418e-02],\n",
      "        [ 9.5950e-01, -2.3800e-01],\n",
      "        [ 2.4135e-01, -9.2544e-02],\n",
      "        [ 6.4226e-01,  6.4838e-02],\n",
      "        [-1.1064e+00, -1.2894e-01],\n",
      "        [-2.6489e-01, -1.8781e-02],\n",
      "        [-1.4739e+00, -3.3110e-01],\n",
      "        [-1.3109e-01, -1.5671e-01],\n",
      "        [-2.3414e-01, -1.3516e-01],\n",
      "        [ 2.7166e-01, -5.4629e-01],\n",
      "        [-5.0276e-02, -1.8567e-02],\n",
      "        [-3.3739e-01, -1.7717e-01],\n",
      "        [-8.8678e-02, -4.0389e-01],\n",
      "        [-8.0952e-01, -2.3006e-02],\n",
      "        [-5.4055e-01, -4.9043e-01],\n",
      "        [ 1.3198e-01, -2.0320e-02],\n",
      "        [-4.8109e-02,  1.5952e-01],\n",
      "        [-2.1757e-02, -1.2361e-01],\n",
      "        [ 5.3272e-01, -1.4574e+00],\n",
      "        [-2.3443e-01,  2.6944e-01],\n",
      "        [-3.6543e-01, -2.8803e-01],\n",
      "        [ 4.3550e-01, -5.7155e-02],\n",
      "        [ 1.8577e-02, -3.8719e-01],\n",
      "        [ 5.4205e-01,  1.7622e-01],\n",
      "        [ 1.1273e-01,  5.5993e-02],\n",
      "        [-2.6568e-01, -5.1537e-01],\n",
      "        [-6.0707e-01, -2.4993e-01],\n",
      "        [ 2.0899e-01,  1.2600e-01],\n",
      "        [-7.1843e-02,  1.9208e-01],\n",
      "        [ 4.3960e-01, -2.9627e-01],\n",
      "        [ 2.3875e-01, -2.1988e-01],\n",
      "        [ 6.4283e-01,  4.9856e-01],\n",
      "        [ 5.8796e-01,  1.4380e-01],\n",
      "        [ 7.9395e-04, -1.5093e-01],\n",
      "        [ 1.2305e-01,  2.9970e-02],\n",
      "        [-6.6859e-02,  5.1104e-02],\n",
      "        [-2.8262e-01,  2.0837e-01],\n",
      "        [-1.2839e-01, -1.8104e-01],\n",
      "        [-7.5848e-01, -3.8660e-01],\n",
      "        [ 3.0365e-01,  2.7293e-01],\n",
      "        [ 7.4719e-03,  3.2970e-01],\n",
      "        [-6.4732e-01, -8.1502e-01],\n",
      "        [ 4.1162e-01,  1.1186e-01],\n",
      "        [-6.8968e-01,  2.4565e-02],\n",
      "        [ 6.7463e-01, -2.3477e-02],\n",
      "        [-5.8512e-01, -6.8967e-01],\n",
      "        [-3.9048e-03, -2.2067e-01],\n",
      "        [ 1.5821e-01,  1.3591e-03],\n",
      "        [-2.3119e-01,  1.2375e-01],\n",
      "        [-1.1422e+00, -1.4098e-01],\n",
      "        [-2.3857e-01,  9.5546e-02],\n",
      "        [-4.7787e-01, -2.6288e-01],\n",
      "        [ 9.7550e-02, -1.4488e-01],\n",
      "        [-1.6669e-02,  4.8992e-02],\n",
      "        [-7.4370e-02, -7.9004e-02]], grad_fn=<AddmmBackward0>)\n",
      "linear_predictor shape torch.Size([128, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# This is a toy dataset for binary classification, 1000 data points with 20 features each\n",
    "X, y = make_regression(1000, 20, n_informative=10, random_state=0, n_targets=2)\n",
    "X_old, y_old = X.astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "data = load_metabric(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data #.iloc[:1000]#.astype(np.float32)\n",
    "y = data.target\n",
    "y = pd.concat([data.target, data.target],axis=1) #.iloc[:1000]\n",
    "\n",
    "    \n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, n_layers, in_features, num_nodes, dropout, out_features):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.in_features = in_features\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dropout = dropout\n",
    "        self.out_features = out_features\n",
    "        model = []\n",
    "        # first layer\n",
    "        model.append(torch.nn.Linear(in_features, num_nodes))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout))\n",
    "        model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            model.append(torch.nn.Linear(num_nodes, num_nodes))\n",
    "            #init.kaiming_normal_(model[-1].weight, nonlinearity='relu')\n",
    "            model.append(torch.nn.ReLU())\n",
    "            model.append(torch.nn.Dropout(dropout))\n",
    "            model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        # output layer\n",
    "        model.append(torch.nn.Linear(num_nodes, out_features))\n",
    "    \n",
    "        self.layers = nn.Sequential(*model)\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     if isinstance(layer, nn.Linear):\n",
    "        #         #nn.init.uniform_(layer.weight, a=-0.5, b=0.5)\n",
    "        #         nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.layers(x)\n",
    "        print('res',res)\n",
    "        return res\n",
    "    \n",
    "\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    SurvivalModel,\n",
    "    max_epochs=20,\n",
    "    module__n_layers = 1,\n",
    "    module__in_features = X.shape[1],\n",
    "    module__num_nodes = 32,\n",
    "    module__dropout = 0.1, # these could also be removed\n",
    "    module__out_features = y.shape[1],\n",
    "    criterion=AFTLoss,\n",
    "    # for split sizes when result size = 1\n",
    "    iterator_train__drop_last=True,\n",
    "    lr=0.001,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")\n",
    "param_grid_breslow = {'lr':[0.01]}\n",
    "rs = RandomizedSearchCV(net, param_grid_breslow, n_jobs=-1, scoring = 'neg_mean_absolute_error', n_iter=n_iter, refit=True)\n",
    "    \n",
    "#scoring_function\n",
    "    # train\n",
    "rs.fit(X.values, y.values)\n",
    "\n",
    "# Training the network\n",
    "#net.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
