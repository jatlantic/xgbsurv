{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/JUSC/Documents/xgbsurv/experiments/deep_learning\n"
     ]
    }
   ],
   "source": [
    "# XGBsurv benchmark\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "from skorch import NeuralNet, NeuralNetRegressor\n",
    "from skorch.callbacks import Callback,EarlyStopping, LRScheduler\n",
    "from skorch.dataset import CVSplit, ValidSplit\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "#from pycox.evaluation import EvalSurv\n",
    "from xgbsurv.models.utils import transform_back, transform\n",
    "from xgbsurv.models.eh_final import baseline_hazard_estimator_eh\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df\n",
    "from xgbsurv.datasets import load_metabric, load_flchain, load_rgbsg, load_support\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "\n",
    "#sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import EHLoss, eh_likelihood_torch_2\n",
    "#torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "deep learning hyperparameter spaces follow pycox paper\n",
    "Time-to-Event Prediction with Neural Networks and Cox Regression\n",
    "page 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 10 # set to 50\n",
    "#n_iter_cind = 200\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "\n",
    "param_grid_breslow = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    #'estimator__lr': scloguniform(0.001,0.01), # scheduler unten einbauen\n",
    "    #'max_epochs':  scrandint(10,20), # corresponds to num_rounds\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, n_layers, in_features, num_nodes, dropout, out_features):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.in_features = in_features\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dropout = dropout\n",
    "        self.out_features = out_features\n",
    "        model = []\n",
    "        # first layer\n",
    "        model.append(torch.nn.Linear(in_features, num_nodes))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout))\n",
    "        model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            model.append(torch.nn.Linear(num_nodes, num_nodes))\n",
    "            #init.kaiming_normal_(model[-1].weight, nonlinearity='relu')\n",
    "            model.append(torch.nn.ReLU())\n",
    "            model.append(torch.nn.Dropout(dropout))\n",
    "            model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        # output layer\n",
    "        model.append(torch.nn.Linear(num_nodes, out_features))\n",
    "    \n",
    "        self.layers = nn.Sequential(*model)\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     if isinstance(layer, nn.Linear):\n",
    "        #         #nn.init.uniform_(layer.weight, a=-0.5, b=0.5)\n",
    "        #         nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.layers(x)\n",
    "        #print(res)\n",
    "        return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stratified inner k-fold cross-validation\n",
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Scorer\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "\n",
    "        #y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, np.ndarray):\n",
    "            y_pred = torch.from_numpy(y_pred)\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, pd.Series):\n",
    "            y_pred = torch.tensor(y_pred.values)\n",
    "        if isinstance(y_true, pd.Series):\n",
    "            y_true = torch.tensor(y_true.values)\n",
    "        score = eh_likelihood_torch_2(y_pred, y_true) \n",
    "        return score.numpy()\n",
    "\n",
    "scoring_function = make_scorer(custom_scoring_function, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set EH Estimator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# def baseline_hazard_estimator_eh(\n",
    "#     time,\n",
    "#     y_train,\n",
    "#     train_eta,\n",
    "# ):\n",
    "#     train_time, train_event = transform_back(y_train)\n",
    "#     n_samples: int = train_time.shape[0]\n",
    "#     bandwidth = 1.30 * math.pow(n_samples, -0.2)\n",
    "#     inverse_bandwidth: float = 1 / bandwidth\n",
    "#     inverse_sample_size: float = 1 / n_samples\n",
    "#     inverse_bandwidth_sample_size: float = (\n",
    "#         inverse_sample_size * (1 / (time + EPS)) * inverse_bandwidth\n",
    "#     )\n",
    "#     log_time: float = time\n",
    "#     train_eta_1 = train_eta[:,0]\n",
    "#     train_eta_2 = train_eta[:,1]\n",
    "#     h_prefactor = np.exp(train_eta_2-train_eta_1)\n",
    "#     R_lp: np.array = np.log(train_time * np.exp(train_eta))\n",
    "#     difference_lp_log_time: np.array = (R_lp - log_time) / bandwidth\n",
    "#     numerator: float = 0.0\n",
    "#     denominator: float = 0.0\n",
    "#     for _ in range(n_samples):\n",
    "#         difference: float = difference_lp_log_time[_]\n",
    "#         denominator += h_prefactor * gaussian_integrated_kernel(difference)\n",
    "#         if train_event[_]:\n",
    "#             numerator += gaussian_kernel(difference)\n",
    "#     numerator = inverse_bandwidth_sample_size * numerator\n",
    "#     denominator = inverse_sample_size * denominator\n",
    "\n",
    "#     return numerator / denominator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1903, 9)\n",
      "(1903, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# adapt this for bool case\n",
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        \n",
    "        #to_add = X[X.columns[X.columns.isin(['sex','D'])]]\n",
    "        #X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        #df.columns.get_loc('age')\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        #to_add = to_add.values.reshape(-1, 1)\n",
    "\n",
    "        # Horizontally stack the two arrays\n",
    "        #result = np.hstack((X_transformed, to_add))\n",
    "        \n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "\n",
    "class CustomStandardScaler2(StandardScaler):\n",
    "    \"\"\"Just to change the datatype of bool variables.\"\"\"\n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        \n",
    "        to_return = X\n",
    "        #X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        #df.columns.get_loc('age')\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        #to_add = to_add.values.reshape(-1, 1)\n",
    "\n",
    "        # Horizontally stack the two arrays\n",
    "        #result = np.hstack((X_transformed, to_add))\n",
    "        \n",
    "        # Add your own code here\n",
    "        return to_return.astype(np.float32)\n",
    "    \n",
    "#ct = CustomStandardScaler()\n",
    "ct = make_column_transformer(\n",
    "        (CustomStandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "        (OneHotEncoder(), make_column_selector(dtype_include=['category'])), remainder='passthrough')\n",
    "data = load_metabric(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "print(type(X.to_numpy()))\n",
    "print(X.shape)\n",
    "X = ct.fit_transform(X)\n",
    "print(X.shape)\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation D\n",
    "# Adapted from https://github.com/pytorch/pytorch/issues/7068.\n",
    "def seed_torch(seed=42):\n",
    "    \"\"\"Sets all seeds within torch and adjacent libraries.\n",
    "    Args:\n",
    "        seed: Random seed to be used by the seeding functions.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "class FixSeed(Callback):\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "    def initialize(self):\n",
    "        seed_torch(self.seed)\n",
    "        return super().initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 1 # # set to 50\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "\n",
    "        dataset_name = filename.split('_')[0]\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        # ct = make_column_transformer(\n",
    "        #  (StandardScaler(),\n",
    "        #  make_column_selector(dtype_include=float,dtype_exclude=bool)),)\n",
    "        # (LabelBinarizer(),\n",
    "        # make_column_selector(dtype_include=bool, dtype_exclude=float)))\n",
    "        ct = make_column_transformer(\n",
    "        (CustomStandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "        (CustomStandardScaler2(), make_column_selector(dtype_include=['category'])), remainder='passthrough')\n",
    "        #ct = make_column_transformer(\n",
    "        #(StandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "        #(OneHotEncoder(), make_column_selector(dtype_include=['category'])), remainder='passthrough')\n",
    "        #columns_to_transform = [col for col in X.columns if col != 'sex']\n",
    "        #ct = make_column_transformer(\n",
    "        #(StandardScaler(), columns_to_transform), \n",
    "        #(LabelBinarizer(), make_column_selector(dtype_include='bool')),\n",
    "        #remainder='passthrough'\n",
    "        #)\n",
    "        pipe = Pipeline(\n",
    "        [('scaler', ct),\n",
    "        ('estimator', net)]\n",
    "        )\n",
    "        # pipe = Pipeline([\n",
    "        # ('scale', StandardScaler()),\n",
    "        # ('estimator', net),\n",
    "        # ])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_breslow, scoring = scoring_function, n_jobs=-1, \n",
    "                            cv=inner_custom_cv, n_iter=n_iter, refit=True)\n",
    "        \n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                #print('train_index', train_index)\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                #print(X_train.shape, type(X_train))\n",
    "                #print(y_train.shape, type(y_train))\n",
    "                #print(X_test.shape, type(X_test))\n",
    "                #print(y_test.shape, type(y_test))\n",
    "                # save splits and data\n",
    "                savetxt('splits/eh_train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/eh_test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                savetxt('splits/eh_X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                savetxt('splits/eh_X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                savetxt('splits/eh_y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                savetxt('splits/eh_y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "                \n",
    "                #savetxt('splits/test_index_'+str(i)+'.csv', test_index, delimiter=',')\n",
    "                \n",
    "                # create validation dataset for early stopping\n",
    "                strat = np.sign(y_train)\n",
    "                valid_split = ValidSplit(cv=0.1, stratified=strat, random_state=42)\n",
    "\n",
    "                # train\n",
    "                rs.fit(X_train, y_train)\n",
    "                \n",
    "                # predict\n",
    "                #scaler = StandardScaler()\n",
    "                #X_train = scaler.fit_transform(X_train)\n",
    "                #X_test = scaler.transform(X_test)\n",
    "                print(rs.best_estimator_.predict(X_train))\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "\n",
    "                print('best_preds_test, best_preds_train',best_preds_test, best_preds_train)\n",
    "                #print(best_preds_test, type(best_preds_test))\n",
    "                # predict survival function\n",
    "                # d = predict_survival_function(X_test, dataframe=True)\n",
    "\n",
    "                # save predictions, get dataset name\n",
    "                savetxt('predictions/train_preds_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "                savetxt('predictions/test_preds_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "                \n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "                #print(rs.best_params_)\n",
    "                time_train, event_train = transform_back(y_train)\n",
    "                time_test, event_test = transform_back(y_test)\n",
    "                best_preds_train = baseline_hazard_estimator_eh(time_train, y_train, best_preds_train)\n",
    "                print('best_preds_train',best_preds_train)\n",
    "                # save c-index values\n",
    "                try:\n",
    "                        \n",
    "                        best_preds_test = baseline_hazard_estimator_eh(time_test, y_train, best_preds_test)\n",
    "                        score_train = cindex_censored(y_train, best_preds_train.reshape(-1))\n",
    "                        score_test = cindex_censored(y_test, best_preds_test.reshape(-1))\n",
    "                        outer_scores['cindex_train_'+dataset_name] += [score_train]\n",
    "                        outer_scores['cindex_test_'+dataset_name] += [score_test]\n",
    "                except:\n",
    "                        outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "                        outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "        df_metrics.to_csv('metrics/aft_metric_summary_'+str(i)+'_'+filename, index=False)\n",
    "        return best_model, best_params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  float32\n",
       "sex                 category\n",
       "race                 float32\n",
       "n_comorbidities      float32\n",
       "diabetes            category\n",
       "dementia            category\n",
       "cancer              category\n",
       "blood_pressure       float32\n",
       "heart_rate           float32\n",
       "respiration_rate     float32\n",
       "temperature          float32\n",
       "white_blood_cell     float32\n",
       "serum_sodium         float32\n",
       "serum_creatinine     float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_support(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: METABRIC_adapted.csv\n",
      "MKI67                float32\n",
      "EGFR                 float32\n",
      "PGR                  float32\n",
      "ERBB2                float32\n",
      "hormone_treatment    float32\n",
      "radiotherapy         float32\n",
      "chemotherapy         float32\n",
      "ER_positive          float32\n",
      "age                  float32\n",
      "dtype: object\n",
      "y [[ 1.0000000e-01  1.0000000e-01]\n",
      " [-7.6666665e-01 -7.6666665e-01]\n",
      " [-1.2333333e+00 -1.2333333e+00]\n",
      " ...\n",
      " [-3.3703333e+02 -3.3703333e+02]\n",
      " [ 3.5100000e+02  3.5100000e+02]\n",
      " [ 3.5520001e+02  3.5520001e+02]]\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])linear_predictor shape\n",
      "linear_predictor typelinear_predictor shape   torch.Size([244, 2])torch.Size([244, 2])<class 'torch.Tensor'>\n",
      "\n",
      "\n",
      "linear_predictor typelinear_predictor type  <class 'torch.Tensor'><class 'torch.Tensor'>\n",
      "\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0404) tensor(-0.0421)tensor(-0.0421)  tensor(-0.0424) tensor(-0.0403) tensor(2.4699) tensor(2.5270) tensor(2.5916)tensor(2.6143)  tensor(2.6300) tensor(-0.9755) tensor(-1.0219) tensor(-1.0071) tensor(-1.0300) tensor(-1.0227) tensor(-0.3973)\n",
      "tensor(-0.4495)\n",
      "tensor(-0.4379)\n",
      "tensor(-0.4440)\n",
      "tensor(-0.4544)\n",
      "loss loss lossloss  loss tensor(3.0885)\n",
      "tensor(3.1395)\n",
      "tensor(3.2256)tensor(3.2197)\n",
      "\n",
      "tensor(3.2406)\n",
      "  epoch    valid_loss     dur  epoch    valid_loss     dur\n",
      "\n",
      "-------  ------------  -------------  ------------  ------\n",
      "\n",
      "      1        \u001b[36m3.0885\u001b[0m  0.0096      1        \u001b[36m3.2256\u001b[0m  0.0096\n",
      "\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.2197\u001b[0m  0.0096\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.2406\u001b[0m  0.0098\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.1395\u001b[0m  0.0096\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0403) tensor(-0.0404) tensor(-0.0421) tensor(2.4699)tensor(2.5270)  tensor(-0.0421) tensor(2.5916) tensor(-0.0424) tensor(-0.9755) tensor(-1.0219) tensor(2.6143) tensor(-1.0300) tensor(2.6300) tensor(-0.3973)\n",
      "tensor(-0.4495)\n",
      "tensor(-1.0071) loss tensor(-0.4440)\n",
      "tensor(-1.0227) loss losstensor(-0.4379) \n",
      "tensor(3.0885)tensor(-0.4544)\n",
      "\n",
      "tensor(3.1395)\n",
      "loss loss tensor(3.2197)\n",
      "tensor(3.2406)tensor(3.2256)\n",
      "\n",
      "      2        3.0885  0.0069\n",
      "      2        3.1395  0.0067\n",
      "      2        3.2197  0.0068\n",
      "      2        3.2406  0.0069\n",
      "      2        3.2256  0.0070\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0403) tensor(-0.0404) tensor(2.5270) tensor(2.4699) tensor(-1.0219) tensor(-0.4495)\n",
      "tensor(-0.9755) loss tensor(-0.3973)\n",
      "tensor(3.1395)\n",
      "loss tensor(3.0885)\n",
      "tensor(-0.0421)       3        3.1395  0.0063\n",
      "tensor(-0.0424) tensor(2.5916) tensor(2.6300) tensor(-1.0300) tensor(-0.0421) tensor(-1.0227)tensor(-0.4440) \n",
      "      3        3.0885  0.0065\n",
      "tensor(2.6143) losstensor(-0.4544) \n",
      "tensor(-1.0071) loss tensor(3.2197)\n",
      "tensor(-0.4379)\n",
      "tensor(3.2406)\n",
      "loss tensor(3.2256)\n",
      "      3        3.2197  0.0069\n",
      "      3        3.2406  0.0068\n",
      "      3        3.2256  0.0069\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0404) tensor(2.4699) tensor(-0.9755) tensor(-0.3973)\n",
      "tensor(-0.0403) loss tensor(2.5270) tensor(3.0885)\n",
      "tensor(-1.0219) tensor(-0.0421) tensor(-0.4495)\n",
      "tensor(2.5916) loss tensor(-1.0300)       4        3.0885  0.0065\n",
      "tensor(3.1395)\n",
      "tensor(-0.4440)\n",
      "tensor(-0.0421) loss tensor(-0.0424) tensor(2.6143) tensor(3.2197)\n",
      "tensor(2.6300) tensor(-1.0071) tensor(-1.0227) tensor(-0.4379)\n",
      "      4        3.1395  0.0070\n",
      "tensor(-0.4544)\n",
      "loss loss       4        3.2197  0.0065\n",
      "tensor(3.2256)\n",
      "tensor(3.2406)\n",
      "      4        3.2256  0.0066\n",
      "      4        3.2406  0.0067\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shapelinear_predictor shape  torch.Size([244, 2])torch.Size([244, 2])\n",
      "\n",
      "linear_predictor typelinear_predictor type  <class 'torch.Tensor'><class 'torch.Tensor'>\n",
      "\n",
      "tensor(-0.0404) tensor(-0.0421) tensor(2.4699) tensor(-0.0403) tensor(2.5916) tensor(-0.9755) tensor(2.5270) tensor(-1.0300) tensor(-0.3973)\n",
      "tensor(-1.0219) tensor(-0.0421) tensor(-0.4440)\n",
      "tensor(-0.0424) loss loss tensor(2.6143) tensor(2.6300) tensor(-0.4495)\n",
      "tensor(3.0885)\n",
      "tensor(-1.0071)tensor(3.2197) \n",
      "losstensor(-1.0227)  tensor(-0.4379)\n",
      "tensor(-0.4544)\n",
      "tensor(3.1395)\n",
      "loss loss tensor(3.2256)\n",
      "tensor(3.2406)\n",
      "      5        3.2197  0.0065\n",
      "      5        3.0885  0.0069\n",
      "      5        3.1395  0.0067\n",
      "      5        3.2256  0.0064\n",
      "      5        3.2406  0.0064\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0421) tensor(-0.0403) tensor(-0.0421) tensor(2.6143) tensor(2.5270) tensor(-0.0404) tensor(2.5916) tensor(-1.0071) tensor(-1.0219) tensor(2.4699) tensor(-1.0300) tensor(-0.4379)\n",
      "tensor(-0.9755) tensor(-0.4495)\n",
      "tensor(-0.4440)\n",
      "loss loss tensor(-0.3973)\n",
      "loss loss tensor(3.2256)\n",
      "tensor(3.1395)\n",
      "tensor(3.2197)\n",
      "tensor(3.0885)\n",
      "tensor(-0.0424)       6        3.2256  0.0064\n",
      "      6        3.1395  0.0064\n",
      "tensor(2.6300)       6        3.2197  0.0066\n",
      "tensor(-1.0227)       6        3.0885  0.0066\n",
      "tensor(-0.4544)\n",
      "loss tensor(3.2406)\n",
      "      6        3.2406  0.0069\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0403) tensor(2.5270) tensor(-1.0219) tensor(-0.0421) tensor(-0.0404) tensor(-0.4495)\n",
      "tensor(2.5916) loss tensor(2.4699) tensor(-1.0300) tensor(3.1395)\n",
      "tensor(-0.9755) tensor(-0.4440)\n",
      "tensor(-0.0421) tensor(-0.3973)\n",
      "loss tensor(2.6143)loss  tensor(3.2197)\n",
      "tensor(3.0885)\n",
      "tensor(-1.0071)       7        3.1395  0.0065\n",
      "tensor(-0.4379)\n",
      "loss       7        3.2197  0.0066\n",
      "tensor(-0.0424) tensor(3.2256)\n",
      "      7        3.0885  0.0066\n",
      "tensor(2.6300) tensor(-1.0227) tensor(-0.4544)\n",
      "loss       7        3.2256  0.0069\n",
      "tensor(3.2406)\n",
      "      7        3.2406  0.0067\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0403) tensor(2.5270) tensor(-0.0421) tensor(-0.0404) tensor(-1.0219) tensor(2.5916) tensor(-0.4495)\n",
      "tensor(2.4699)tensor(-1.0300)  loss tensor(-0.4440)\n",
      "tensor(-0.9755) tensor(3.1395)\n",
      "loss tensor(-0.3973)\n",
      "tensor(3.2197)\n",
      "tensor(-0.0421)loss  tensor(2.6143)tensor(3.0885) \n",
      "      8        3.1395  0.0065\n",
      "tensor(-1.0071) tensor(-0.4379)\n",
      "      8        3.2197  0.0065\n",
      "loss tensor(3.2256)\n",
      "      8        3.0885  0.0065\n",
      "tensor(-0.0424) tensor(2.6300)       8        3.2256  0.0065\n",
      "tensor(-1.0227) tensor(-0.4544)\n",
      "loss tensor(3.2406)\n",
      "      8        3.2406  0.0067\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0421) tensor(2.5916) tensor(-1.0300) tensor(-0.4440)\n",
      "tensor(-0.0404) loss tensor(2.4699) tensor(-0.0403)tensor(3.2197)\n",
      "tensor(-0.0421)  tensor(-0.9755) tensor(2.6143) tensor(-0.3973)tensor(2.5270)\n",
      " loss tensor(-1.0219) tensor(-1.0071) tensor(3.0885)\n",
      "tensor(-0.4495)\n",
      "      9        3.2197  0.0064\n",
      "loss tensor(-0.4379)\n",
      "tensor(3.1395)\n",
      "loss       9        3.0885  0.0065\n",
      "tensor(3.2256)\n",
      "      9        3.1395  0.0068\n",
      "      9        3.2256  0.0065\n",
      "tensor(-0.0424) tensor(2.6300) tensor(-1.0227) tensor(-0.4544)\n",
      "loss tensor(3.2406)\n",
      "      9        3.2406  0.0067\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([244, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0421) tensor(2.5916) tensor(-1.0300) tensor(-0.4440)\n",
      "loss tensor(-0.0403) tensor(3.2197)\n",
      "tensor(2.5270) tensor(-1.0219) tensor(-0.4495)\n",
      "     10        3.2197  0.0064\n",
      "loss tensor(-0.0404) tensor(3.1395)\n",
      "tensor(2.4699) tensor(-0.9755)      10        3.1395  0.0063tensor(-0.3973)\n",
      "\n",
      "tensor(-0.0421) loss tensor(2.6143) tensor(3.0885)\n",
      "tensor(-1.0071) Restoring best model from epoch 1.\n",
      "tensor(-0.4379)\n",
      "loss tensor(3.2256)\n",
      "Restoring best model from epoch 1.\n",
      "     10        3.0885  0.0069\n",
      "     10        3.2256  0.0068\n",
      "tensor(-0.0424) tensor(2.6300) Restoring best model from epoch 1.\n",
      "tensor(-1.0227) tensor(-0.4544)Restoring best model from epoch 1.\n",
      "\n",
      "loss tensor(3.2406)\n",
      "     10        3.2406  0.0069\n",
      "Restoring best model from epoch 1.\n",
      "linear_predictor shape torch.Size([304, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([304, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "linear_predictor shape torch.Size([304, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0401)tensor(-0.0400)  tensor(2.5057)tensor(2.5424)  tensor(-0.9878)tensor(-0.9769)  tensor(-0.4017)tensor(-0.4407)\n",
      "\n",
      "tensor(-0.0400) tensor(2.4703) tensor(-1.0463) tensor(-0.4345)\n",
      "tensor(-0.0404) tensor(2.4542) tensor(-1.0632) tensor(-0.4252)\n",
      "tensor(-0.0401) tensor(2.4967) tensor(-1.0219) tensor(-0.4267)\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0244, grad_fn=<DivBackward0>) tensor(2.4853, grad_fn=<DivBackward0>) tensor(-1.1593, grad_fn=<DivBackward0>) tensor(-0.4742, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1948, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0383) tensor(2.6878) tensor(-1.0276) tensor(-0.4680)\n",
      "loss tensor(3.2857)\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1948\u001b[0m        \u001b[32m3.2857\u001b[0m  0.0685\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0209, grad_fn=<DivBackward0>) tensor(2.4752, grad_fn=<DivBackward0>) tensor(-1.1272, grad_fn=<DivBackward0>) tensor(-0.4307, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1927, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0323) tensor(2.6966) tensor(-1.0273) tensor(-0.4714)\n",
      "loss tensor(3.2848)\n",
      "      2        \u001b[36m3.1927\u001b[0m        \u001b[32m3.2848\u001b[0m  0.1242\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0226, grad_fn=<DivBackward0>) tensor(2.4673, grad_fn=<DivBackward0>) tensor(-1.1522, grad_fn=<DivBackward0>) tensor(-0.4652, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1768, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0257) tensor(2.7042) tensor(-1.0270) tensor(-0.4728)\n",
      "loss tensor(3.2841)\n",
      "      3        \u001b[36m3.1768\u001b[0m        \u001b[32m3.2841\u001b[0m  0.0528\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0195, grad_fn=<DivBackward0>) tensor(2.4750, grad_fn=<DivBackward0>) tensor(-1.1475, grad_fn=<DivBackward0>) tensor(-0.4754, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1665, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0181) tensor(2.7086) tensor(-1.0264) tensor(-0.4699)\n",
      "loss tensor(3.2832)\n",
      "      4        \u001b[36m3.1665\u001b[0m        \u001b[32m3.2832\u001b[0m  0.0537\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0102, grad_fn=<DivBackward0>) tensor(2.4722, grad_fn=<DivBackward0>) tensor(-1.1437, grad_fn=<DivBackward0>) tensor(-0.4633, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1629, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0127) tensor(2.7088) tensor(-1.0255) tensor(-0.4653)\n",
      "loss tensor(3.2818)\n",
      "      5        \u001b[36m3.1629\u001b[0m        \u001b[32m3.2818\u001b[0m  0.0520\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0117, grad_fn=<DivBackward0>) tensor(2.4648, grad_fn=<DivBackward0>) tensor(-1.1164, grad_fn=<DivBackward0>) tensor(-0.4534, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1396, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0086) tensor(2.7055) tensor(-1.0243) tensor(-0.4583)\n",
      "loss tensor(3.2801)\n",
      "      6        \u001b[36m3.1396\u001b[0m        \u001b[32m3.2801\u001b[0m  0.0475\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0220, grad_fn=<DivBackward0>) tensor(2.4613, grad_fn=<DivBackward0>) tensor(-1.1285, grad_fn=<DivBackward0>) tensor(-0.4494, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1624, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0060) tensor(2.6979) tensor(-1.0229) tensor(-0.4488)\n",
      "loss tensor(3.2780)\n",
      "      7        3.1624        \u001b[32m3.2780\u001b[0m  0.0493\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0021, grad_fn=<DivBackward0>) tensor(2.4581, grad_fn=<DivBackward0>) tensor(-1.1184, grad_fn=<DivBackward0>) tensor(-0.4450, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1335, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0031) tensor(2.6862) tensor(-1.0215) tensor(-0.4350)\n",
      "loss tensor(3.2757)\n",
      "      8        \u001b[36m3.1335\u001b[0m        \u001b[32m3.2757\u001b[0m  0.0510\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0161, grad_fn=<DivBackward0>) tensor(2.4634, grad_fn=<DivBackward0>) tensor(-1.1297, grad_fn=<DivBackward0>) tensor(-0.4653, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1438, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0021) tensor(2.6691) tensor(-1.0200) tensor(-0.4182)\n",
      "loss tensor(3.2730)\n",
      "      9        3.1438        \u001b[32m3.2730\u001b[0m  0.0540\n",
      "linear_predictor shape torch.Size([1024, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(-0.0143, grad_fn=<DivBackward0>) tensor(2.4690, grad_fn=<DivBackward0>) tensor(-1.1261, grad_fn=<DivBackward0>) tensor(-0.4507, grad_fn=<DivBackward0>)\n",
      "loss tensor(3.1586, grad_fn=<NegBackward0>)\n",
      "linear_predictor shape torch.Size([305, 2])\n",
      "linear_predictor type <class 'torch.Tensor'>\n",
      "tensor(0.0004) tensor(2.6495) tensor(-1.0185) tensor(-0.3975)\n",
      "loss tensor(3.2701)\n",
      "     10        3.1586        \u001b[32m3.2701\u001b[0m  0.0495\n",
      "[[-0.09237759  0.00469115]\n",
      " [-0.09931546  0.00557226]\n",
      " [-0.02337091  0.02892122]\n",
      " ...\n",
      " [-0.0891293  -0.01309121]\n",
      " [-0.10957815 -0.02971991]\n",
      " [-0.0797634  -0.0203575 ]]\n",
      "best_preds_test, best_preds_train [[-4.98183072e-04 -6.11734465e-02]\n",
      " [-3.97863388e-02 -3.53248790e-02]\n",
      " [-6.74187019e-02 -4.23976406e-02]\n",
      " [-6.98090866e-02 -2.16339175e-02]\n",
      " [ 1.36301201e-02 -3.43038887e-02]\n",
      " [-7.78866261e-02 -3.81986871e-02]\n",
      " [-8.60298574e-02 -5.43697402e-02]\n",
      " [-6.68302476e-02  3.61743234e-02]\n",
      " [ 2.84273550e-02 -1.33694425e-01]\n",
      " [-5.64387888e-02 -1.55646838e-02]\n",
      " [-3.27600725e-02 -3.87608856e-02]\n",
      " [-9.13769007e-03  1.56531371e-02]\n",
      " [-7.08180368e-02 -5.23317233e-02]\n",
      " [-1.06648996e-01 -1.02615774e-01]\n",
      " [-1.15766749e-02 -1.50821805e-02]\n",
      " [ 5.82308881e-03  4.29799296e-02]\n",
      " [-3.35456319e-02 -6.19858392e-02]\n",
      " [-1.00285202e-01 -1.36508107e-01]\n",
      " [-3.06120701e-02 -3.39365825e-02]\n",
      " [-5.89248762e-02  3.02457698e-02]\n",
      " [-3.33282053e-02 -6.85440227e-02]\n",
      " [-4.59836721e-02 -4.33300585e-02]\n",
      " [-1.22329444e-01 -7.87036866e-02]\n",
      " [ 7.50107877e-03  4.03820314e-02]\n",
      " [-7.28251189e-02 -2.91721672e-02]\n",
      " [-7.71136880e-02 -2.23718397e-02]\n",
      " [-7.91721493e-02 -1.50262192e-03]\n",
      " [-2.05741525e-02 -8.65897089e-02]\n",
      " [-3.37193348e-03  2.33131833e-02]\n",
      " [-6.96341097e-02  1.61835365e-02]\n",
      " [-1.07969195e-01 -3.47524658e-02]\n",
      " [-8.39302242e-02 -1.83654130e-02]\n",
      " [-5.02650887e-02  2.39628665e-02]\n",
      " [-5.78429997e-02 -1.00081675e-02]\n",
      " [-9.01307538e-03  1.45434178e-02]\n",
      " [ 5.22183813e-03 -4.87308577e-03]\n",
      " [-1.08439609e-01 -2.73657963e-02]\n",
      " [ 4.03245538e-03  4.48973291e-02]\n",
      " [ 5.73643781e-02 -1.67186279e-02]\n",
      " [-7.74518959e-03 -3.76784429e-02]\n",
      " [-6.56759292e-02  3.51673029e-02]\n",
      " [-3.96659598e-02  5.15500344e-02]\n",
      " [-1.36878997e-01 -1.42544016e-01]\n",
      " [-2.55891904e-02 -2.91281827e-02]\n",
      " [ 2.57232599e-02 -2.59141251e-03]\n",
      " [ 5.60577288e-02  5.24663068e-02]\n",
      " [-8.96277577e-02  4.26610187e-03]\n",
      " [ 1.31975822e-02 -8.45464617e-02]\n",
      " [-1.21351779e-02 -4.64051403e-02]\n",
      " [ 6.30728900e-05  9.64536145e-03]\n",
      " [ 7.94128031e-02 -6.31321371e-02]\n",
      " [-4.01444212e-02 -6.96131811e-02]\n",
      " [-5.22333197e-03  4.04683389e-02]\n",
      " [-9.77486372e-02 -4.72650304e-03]\n",
      " [-2.46914811e-02 -3.51113901e-02]\n",
      " [-6.62253052e-02 -8.16670433e-03]\n",
      " [-2.11842917e-02  1.47398449e-02]\n",
      " [ 1.32182166e-02 -5.75515106e-02]\n",
      " [-8.05312395e-03  8.78952816e-03]\n",
      " [-7.73181766e-02  3.78104672e-03]\n",
      " [-9.54468250e-02 -1.40706271e-01]\n",
      " [-1.31865442e-02  1.01121008e-01]\n",
      " [-9.13387984e-02 -1.80162117e-03]\n",
      " [-6.38814121e-02  1.54913850e-02]\n",
      " [ 1.30051663e-02  9.68661308e-02]\n",
      " [-4.60647792e-02  7.55722076e-02]\n",
      " [-7.94161037e-02 -2.99683940e-02]\n",
      " [-7.48348981e-02  2.88717039e-02]\n",
      " [ 5.67352325e-02  4.09471877e-02]\n",
      " [-5.08267991e-03  1.00258105e-02]\n",
      " [-6.62862808e-02  2.77346261e-02]\n",
      " [-7.72448480e-02 -3.67371067e-02]\n",
      " [-3.29450257e-02  9.05295312e-02]\n",
      " [-7.23492354e-02 -2.43971497e-03]\n",
      " [ 2.80071944e-02 -3.90109979e-02]\n",
      " [-8.41191411e-03 -2.80775260e-02]\n",
      " [-1.06649891e-01 -1.24637142e-01]\n",
      " [-4.10945043e-02  7.92560726e-02]\n",
      " [-3.62972021e-02  2.08100565e-02]\n",
      " [-4.03397717e-02  1.95756815e-02]\n",
      " [-2.14634016e-02  7.65182823e-02]\n",
      " [-5.13541698e-02 -3.89243104e-02]\n",
      " [-8.61006379e-02 -1.60082486e-02]\n",
      " [-1.24534741e-02 -1.01368561e-01]\n",
      " [-4.04294804e-02  3.30483876e-02]\n",
      " [ 1.01007475e-02 -7.34183788e-02]\n",
      " [-8.95352960e-02 -3.74544412e-02]\n",
      " [-6.81625456e-02  3.57750393e-02]\n",
      " [-2.55052336e-02 -4.70873043e-02]\n",
      " [ 8.14662687e-03  1.21836476e-02]\n",
      " [-3.42202708e-02 -1.13169074e-01]\n",
      " [ 5.84797189e-03  5.37139215e-02]\n",
      " [-6.11794889e-02  4.21520360e-02]\n",
      " [-8.99489373e-02 -4.31194976e-02]\n",
      " [-7.52564818e-02  3.69740240e-02]\n",
      " [-5.31587824e-02 -3.90553400e-02]\n",
      " [-1.02998778e-01 -3.31977643e-02]\n",
      " [-6.17960393e-02  1.27286054e-02]\n",
      " [-7.23704547e-02 -4.34023440e-02]\n",
      " [-6.12717867e-02  2.75184028e-02]\n",
      " [-4.34617028e-02  4.69502918e-02]\n",
      " [ 7.43754208e-03 -5.45348972e-02]\n",
      " [-3.29710469e-02  6.22096285e-03]\n",
      " [-4.56759520e-03  3.97482887e-03]\n",
      " [-7.31492788e-02 -9.18149352e-02]\n",
      " [-8.26035291e-02 -4.17427383e-02]\n",
      " [-1.81207433e-03 -1.01978198e-01]\n",
      " [-6.37989640e-02  3.06228288e-02]\n",
      " [-5.69326989e-03  2.63540484e-02]\n",
      " [-3.30915451e-02  3.08994018e-02]\n",
      " [-8.64261538e-02 -3.43733653e-03]\n",
      " [-4.89902608e-02 -2.30672713e-02]\n",
      " [-1.01231679e-01 -1.12741947e-01]\n",
      " [ 1.88417360e-03 -6.71464950e-04]\n",
      " [-4.88782190e-02 -6.00751117e-03]\n",
      " [-2.64062285e-02 -7.71137252e-02]\n",
      " [-2.42695771e-02 -4.20058407e-02]\n",
      " [ 1.26478616e-02  3.15872617e-02]\n",
      " [-3.35436277e-02  4.26372327e-02]\n",
      " [ 1.03755323e-02 -2.28467956e-03]\n",
      " [-6.63283914e-02  4.07446437e-02]\n",
      " [-2.56313868e-02  2.30030082e-02]\n",
      " [-9.62648839e-02 -4.35035080e-02]\n",
      " [-6.34665564e-02  2.69790329e-02]\n",
      " [-1.00064322e-01 -8.33307058e-02]\n",
      " [-7.99640268e-02  1.25662722e-02]\n",
      " [-1.26517117e-02  6.11520894e-02]\n",
      " [-1.27187446e-02 -7.27238134e-02]\n",
      " [-8.08622986e-02 -1.83365792e-02]\n",
      " [-5.16950041e-02  2.56346054e-02]\n",
      " [-6.12090081e-02  5.49939089e-02]\n",
      " [-1.65440366e-02  3.00627835e-02]\n",
      " [-4.63431813e-02  5.12388349e-03]\n",
      " [-6.73666149e-02  3.87700312e-02]\n",
      " [-4.01910916e-02 -5.30189872e-02]\n",
      " [ 1.26500987e-03  1.11285627e-01]\n",
      " [-8.39201808e-02 -4.02461737e-04]\n",
      " [-1.09008580e-01 -2.02952996e-02]\n",
      " [-6.11844659e-02  2.83058733e-03]\n",
      " [-8.09917226e-03  7.57145584e-02]\n",
      " [-3.34064923e-02  1.95286237e-02]\n",
      " [-3.78189832e-02 -1.21386088e-02]\n",
      " [-1.08954951e-01 -1.19075216e-02]\n",
      " [-8.17102343e-02 -7.50186667e-03]\n",
      " [-3.60087343e-02  3.24393027e-02]\n",
      " [-2.24452354e-02  1.16882287e-02]\n",
      " [-5.38574010e-02  5.31399958e-02]\n",
      " [-9.76807773e-02 -2.58703269e-02]\n",
      " [-2.49230228e-02 -2.04065070e-03]\n",
      " [ 2.86973286e-02  7.92521536e-02]\n",
      " [-6.28434122e-02  1.23853125e-02]\n",
      " [-9.34278816e-02 -1.22450404e-02]\n",
      " [-7.67412335e-02  1.54737346e-02]\n",
      " [-7.13332593e-02  3.53190862e-02]\n",
      " [-2.19338387e-03  4.30387631e-03]\n",
      " [-4.75736745e-02  5.96589185e-02]\n",
      " [-1.61265358e-02  3.74316238e-02]\n",
      " [-3.60605940e-02  1.36442147e-02]\n",
      " [-2.13331692e-02  7.61222392e-02]\n",
      " [-1.40235387e-03  3.36731412e-02]\n",
      " [-4.42332700e-02  5.95856421e-02]\n",
      " [-5.95838726e-02  2.60007121e-02]\n",
      " [-2.35153474e-02  8.84858966e-02]\n",
      " [-7.21815526e-02  4.84129377e-02]\n",
      " [-8.42725039e-02  1.40714087e-02]\n",
      " [-4.04567048e-02 -1.80486124e-02]\n",
      " [-4.79846559e-02  5.71240894e-02]\n",
      " [-9.40652341e-02 -1.33108914e-01]\n",
      " [-1.11643165e-01 -8.45653862e-02]\n",
      " [-7.25304931e-02 -6.84257522e-02]\n",
      " [-7.69931301e-02 -3.40383239e-02]\n",
      " [-7.88543969e-02  1.30888708e-02]\n",
      " [-2.88335495e-02  6.36945814e-02]\n",
      " [-9.84466821e-02 -4.69901040e-03]\n",
      " [-6.70349747e-02  5.53899072e-02]\n",
      " [ 2.27470305e-02  2.70950980e-02]\n",
      " [-4.58539203e-02  1.75691359e-02]\n",
      " [-9.04720426e-02 -2.30943803e-02]\n",
      " [-4.96364199e-02  3.79427783e-02]\n",
      " [-8.73996317e-02 -7.44340196e-03]\n",
      " [-1.77057274e-03  2.00114436e-02]\n",
      " [-1.03263661e-01 -2.47108638e-02]\n",
      " [-1.05550773e-02  4.23557945e-02]\n",
      " [-7.24492967e-02  1.86062865e-02]\n",
      " [-9.17014480e-02 -8.68465379e-03]\n",
      " [-4.93068211e-02  3.77054997e-02]\n",
      " [-5.74359000e-02 -1.34129554e-01]\n",
      " [-9.52150226e-02 -5.19389585e-02]\n",
      " [ 8.93722568e-03  6.54440075e-02]\n",
      " [-2.73720548e-02 -2.29865685e-02]\n",
      " [-5.98950982e-02  1.10778026e-02]\n",
      " [-4.00852039e-02  2.20005848e-02]\n",
      " [-8.86964947e-02 -7.54449889e-03]\n",
      " [-6.76828176e-02 -7.34747127e-02]\n",
      " [-6.82749748e-02  4.18487154e-02]\n",
      " [-7.34682083e-02  3.94799933e-03]\n",
      " [ 2.27459874e-02  9.65036452e-02]\n",
      " [-8.85692537e-02  5.12516871e-03]\n",
      " [-1.23900503e-01 -4.65220958e-02]\n",
      " [-7.20277876e-02 -4.19377163e-03]\n",
      " [-6.25326782e-02  2.12278850e-02]\n",
      " [-9.96214747e-02 -2.64210943e-02]\n",
      " [-7.00979084e-02  3.15501504e-02]\n",
      " [ 3.86031903e-03  2.04053335e-02]\n",
      " [-1.05196953e-01 -1.00171655e-01]\n",
      " [-7.32648149e-02 -2.94984672e-02]\n",
      " [ 5.03099523e-04 -2.00623069e-02]\n",
      " [-5.88409901e-02  2.13110335e-02]\n",
      " [-8.94622356e-02  9.11567733e-03]\n",
      " [-1.06341258e-01 -2.14348529e-02]\n",
      " [-4.07719389e-02 -2.28899103e-02]\n",
      " [-2.45604999e-02  8.95609260e-02]\n",
      " [-3.21309790e-02 -4.79698628e-02]\n",
      " [-7.76694864e-02 -5.28497994e-03]\n",
      " [-1.04441531e-02  1.80072300e-02]\n",
      " [-7.71701895e-03  1.40410550e-02]\n",
      " [-2.63493508e-02  6.29197359e-02]\n",
      " [-3.04892287e-02  4.91603054e-02]\n",
      " [ 3.29811797e-02 -3.79463807e-02]\n",
      " [-4.87087481e-02 -2.65610106e-02]\n",
      " [-1.00730971e-01  1.22649595e-03]\n",
      " [-3.76408622e-02 -8.51708204e-02]\n",
      " [-6.03825301e-02  4.53584269e-03]\n",
      " [-7.13216215e-02 -7.53149316e-02]\n",
      " [-3.57329771e-02 -8.82004499e-02]\n",
      " [-8.12408179e-02  1.94030367e-02]\n",
      " [-2.74270773e-03 -1.08299971e-01]\n",
      " [-2.68851258e-02 -8.26506466e-02]\n",
      " [-7.20451958e-03  2.64791138e-02]\n",
      " [-9.32209194e-02 -3.14465538e-03]\n",
      " [-9.64462757e-02 -4.67405841e-02]\n",
      " [-3.77160162e-02 -8.40854496e-02]\n",
      " [-9.78367180e-02 -4.85476181e-02]\n",
      " [ 3.05691361e-02  3.34679671e-02]\n",
      " [-4.68470976e-02 -6.00476190e-02]\n",
      " [ 5.44370301e-02 -3.76867279e-02]\n",
      " [-4.11921069e-02  2.73448639e-02]\n",
      " [-1.43471807e-01 -1.32711858e-01]\n",
      " [-3.95749658e-02  4.34449799e-02]\n",
      " [-1.84522904e-02  7.47476146e-03]\n",
      " [ 2.96928231e-02 -7.65614137e-02]\n",
      " [-6.48855865e-02  4.71143462e-02]\n",
      " [-4.86246310e-02  1.28972493e-02]\n",
      " [-7.13799298e-02 -1.03699528e-02]\n",
      " [-4.50129360e-02  4.64766808e-02]\n",
      " [-1.32591408e-02 -6.69034421e-02]\n",
      " [-9.72821563e-02 -2.64780242e-02]\n",
      " [-8.56352448e-02 -8.20336193e-02]\n",
      " [-7.44950771e-02  1.08803250e-02]\n",
      " [-8.87666196e-02 -1.54638872e-01]\n",
      " [-6.00753129e-02 -5.15804514e-02]\n",
      " [-9.13857818e-02 -1.08957484e-01]\n",
      " [-1.06622741e-01 -2.44071409e-02]\n",
      " [-9.57321078e-02 -1.27601959e-02]\n",
      " [-6.02056533e-02  1.58457942e-02]\n",
      " [-2.42776647e-02  2.07387023e-02]\n",
      " [-8.98455679e-02 -6.30353466e-02]\n",
      " [-8.60670954e-02  3.26007269e-02]\n",
      " [-6.40330613e-02 -1.49130132e-02]\n",
      " [-8.18670988e-02  3.53654101e-03]\n",
      " [-8.32301676e-02 -3.63143943e-02]\n",
      " [-3.69760320e-02  2.06383727e-02]\n",
      " [-9.75595266e-02 -2.85940841e-02]\n",
      " [ 3.64189222e-02 -3.67860235e-02]\n",
      " [-2.86537036e-03 -7.51861930e-02]\n",
      " [ 1.25044398e-03  2.10142396e-02]\n",
      " [-3.91480774e-02  2.26441771e-04]\n",
      " [-3.74500528e-02  1.29732974e-02]\n",
      " [-3.14569138e-02 -8.11650977e-03]\n",
      " [-5.58729842e-03 -5.97653836e-02]\n",
      " [-4.19264436e-02  7.23506138e-03]\n",
      " [-7.14651123e-02  1.44199766e-02]\n",
      " [-2.80873030e-02 -2.01770272e-02]\n",
      " [-8.60278606e-02 -4.86772880e-03]\n",
      " [-3.06519829e-02  8.31044093e-03]\n",
      " [-9.54212397e-02  1.25061385e-02]\n",
      " [-1.07339367e-01  1.40966102e-03]\n",
      " [-5.21365553e-02 -5.32989576e-03]\n",
      " [-1.56666204e-01 -1.01991817e-01]\n",
      " [ 9.09937825e-03 -4.68213335e-02]\n",
      " [-5.80059588e-02  2.72256620e-02]\n",
      " [-7.07880557e-02 -5.47182187e-02]\n",
      " [-8.87473822e-02 -2.18542051e-02]\n",
      " [-5.35018370e-03  8.51475596e-02]\n",
      " [-4.78205495e-02  3.87085266e-02]\n",
      " [-2.24210173e-02 -7.78540522e-02]\n",
      " [-8.37474018e-02  1.80087499e-02]\n",
      " [-4.69303876e-02 -6.70406967e-02]\n",
      " [-2.36456655e-02 -4.74334471e-02]\n",
      " [-7.63008371e-02 -5.62508665e-02]\n",
      " [-7.55343139e-02  1.38301440e-02]\n",
      " [-1.09287992e-01 -1.05301738e-01]\n",
      " [ 6.02634959e-02 -1.47641860e-02]\n",
      " [-2.97093317e-02  5.15841134e-02]\n",
      " [ 4.85504977e-02  3.62779908e-02]\n",
      " [-8.68505538e-02 -6.78935796e-02]\n",
      " [-1.25432685e-01 -1.28877506e-01]\n",
      " [-1.30985454e-01 -1.15658820e-01]\n",
      " [-5.08877560e-02 -7.08329603e-02]\n",
      " [-8.54748040e-02  6.83324412e-03]\n",
      " [-4.96994369e-02  4.81685884e-02]\n",
      " [-9.33781415e-02 -5.20553403e-02]\n",
      " [-3.96891497e-02  5.71495704e-02]\n",
      " [-8.24519843e-02 -4.63249087e-02]\n",
      " [-3.25923786e-04 -2.13751085e-02]\n",
      " [-5.77579290e-02 -3.03768739e-03]\n",
      " [-1.13818124e-01 -6.29980415e-02]\n",
      " [ 2.93678623e-02 -3.19887288e-02]\n",
      " [-1.14828989e-01 -3.37136015e-02]\n",
      " [-8.65428001e-02 -1.17245652e-02]\n",
      " [-7.20149577e-02 -3.06267049e-02]\n",
      " [-1.76705010e-02 -7.11349025e-03]\n",
      " [-1.19535550e-01 -6.97497353e-02]\n",
      " [-9.87298191e-02 -3.44224870e-02]\n",
      " [-1.74075570e-02 -2.89562177e-02]\n",
      " [-1.26840144e-01 -6.25707656e-02]\n",
      " [-1.39559172e-02 -1.22492202e-02]\n",
      " [-8.24625641e-02 -4.08532135e-02]\n",
      " [-1.43155664e-01 -7.05791935e-02]\n",
      " [-1.39514208e-01 -9.20837671e-02]\n",
      " [-7.90733844e-02  5.08331880e-03]\n",
      " [-8.66463035e-02 -2.78088078e-03]\n",
      " [-1.05871260e-01 -1.02234378e-01]\n",
      " [ 1.46354735e-03 -6.07403368e-02]\n",
      " [-1.29258260e-01 -1.25426188e-01]\n",
      " [-4.35696617e-02 -6.32793009e-02]\n",
      " [-1.24348849e-01 -4.89736721e-02]\n",
      " [-2.66137756e-02 -9.70347822e-02]\n",
      " [-7.40207434e-02 -2.22278070e-02]\n",
      " [-6.50793836e-02 -5.66863902e-02]\n",
      " [-1.38846025e-01 -6.10487051e-02]\n",
      " [-1.71360336e-02 -8.42697024e-02]\n",
      " [-1.69073790e-02 -6.27123192e-03]\n",
      " [-8.19084346e-02 -5.41577637e-02]\n",
      " [-8.09000432e-02 -8.57471228e-02]\n",
      " [-8.26405436e-02 -8.16103071e-04]\n",
      " [-6.52031451e-02 -3.05847526e-02]\n",
      " [-2.33332887e-02  4.07166444e-02]\n",
      " [ 4.90455143e-03 -6.33031353e-02]\n",
      " [-1.06191523e-02  2.29410715e-02]\n",
      " [-8.52647573e-02 -4.25969400e-02]\n",
      " [-6.58118576e-02 -4.74749878e-03]\n",
      " [-9.79516804e-02  9.39650461e-03]\n",
      " [-2.92843692e-02 -3.06361150e-02]\n",
      " [-9.25367922e-02 -6.05737343e-02]\n",
      " [-1.59786806e-01 -8.40703100e-02]\n",
      " [-8.05169642e-02 -5.05693257e-02]\n",
      " [-8.19744170e-03  7.50096589e-02]\n",
      " [-8.30952972e-02 -1.01884045e-02]\n",
      " [-5.40825278e-02  5.95089421e-03]\n",
      " [-8.38675946e-02 -3.51120494e-02]\n",
      " [-7.00623095e-02  2.46923901e-02]\n",
      " [-1.48318097e-01 -5.75068556e-02]\n",
      " [-8.48730505e-02 -8.73582959e-02]\n",
      " [-1.04224443e-01 -7.31131807e-02]\n",
      " [-1.44774258e-01 -8.24781209e-02]\n",
      " [-8.58038664e-02 -2.81460062e-02]\n",
      " [-3.32823396e-02 -3.40070203e-03]\n",
      " [ 5.38359061e-02  1.10495150e-01]\n",
      " [-9.21239257e-02 -1.43161677e-02]\n",
      " [-7.33382851e-02 -2.68438067e-02]\n",
      " [ 5.78836538e-03 -1.09837934e-01]\n",
      " [-1.20324776e-01 -1.04652151e-01]\n",
      " [-5.91024570e-03 -9.79701281e-02]\n",
      " [-5.77249378e-02 -6.54139519e-02]\n",
      " [-1.21513963e-01 -1.33687332e-01]\n",
      " [ 1.98138412e-02  8.04422349e-02]\n",
      " [-7.80126154e-02 -1.84638947e-01]\n",
      " [-8.74687731e-02 -3.27800401e-02]\n",
      " [-5.13314754e-02  2.40165852e-02]\n",
      " [-8.78996551e-02 -8.69009346e-02]\n",
      " [-1.10316426e-02 -6.87983260e-02]\n",
      " [-8.22832584e-02 -1.49014816e-02]\n",
      " [-7.10895509e-02 -8.26866329e-02]\n",
      " [-5.36944270e-02  1.73629448e-03]\n",
      " [-5.08965105e-02 -2.22318694e-02]\n",
      " [-1.11074924e-01 -7.61796907e-02]\n",
      " [-1.18415862e-01 -4.76900265e-02]\n",
      " [-9.19599086e-02  2.48262659e-03]\n",
      " [-9.77299809e-02 -4.99049500e-02]\n",
      " [-7.72239119e-02 -1.42406046e-01]] [[-0.09237759  0.00469115]\n",
      " [-0.09931546  0.00557226]\n",
      " [-0.02337091  0.02892122]\n",
      " ...\n",
      " [-0.0891293  -0.01309121]\n",
      " [-0.10957815 -0.02971991]\n",
      " [-0.0797634  -0.0203575 ]]\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function erf>) found for signature:\n \n >>> erf(array(float64, 1d, C))\n \nThere are 2 candidate implementations:\n\u001b[1m  - Of which 2 did not match due to:\n  Type Restricted Function in function 'erf': File: unknown: Line unknown.\n    With argument(s): '(array(float64, 1d, C))':\u001b[0m\n\u001b[1m   No match for registered cases:\n    * (int64,) -> float64\n    * (uint64,) -> float64\n    * (float32,) -> float32\n    * (float64,) -> float64\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function erf>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py (118)\n\u001b[0m\n\u001b[1m\nFile \"../../../../miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py\", line 118:\u001b[0m\n\u001b[1mdef gaussian_integrated_kernel(x):\n\u001b[1m    return 0.5 * (1 + erf(x / SQRT_TWO))\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function gaussian_integrated_kernel at 0x7fcf7928fa30>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py (616)\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function gaussian_integrated_kernel at 0x7fcf7928fa30>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py (616)\n\u001b[0m\n\u001b[1m\nFile \"../../../../miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py\", line 616:\u001b[0m\n\u001b[1mdef baseline_hazard_estimator_eh(\n    <source elided>\n        print('difference shape', difference.shape)\n\u001b[1m        denominator += h_prefactor * gaussian_integrated_kernel(difference)\n\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, y)\n\u001b[1;32m     12\u001b[0m     net \u001b[39m=\u001b[39m NeuralNetRegressor(\n\u001b[1;32m     13\u001b[0m     SurvivalModel, \n\u001b[1;32m     14\u001b[0m     module__n_layers \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 53\u001b[0m     best_model,params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_eval(X, y, net, n_iter, data\u001b[39m.\u001b[39;49mfilename)\n\u001b[1;32m     55\u001b[0m \u001b[39m#train eval function here\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 97\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(X, y, net, n_iter, filename)\u001b[0m\n\u001b[1;32m     95\u001b[0m time_train, event_train \u001b[39m=\u001b[39m transform_back(y_train)\n\u001b[1;32m     96\u001b[0m time_test, event_test \u001b[39m=\u001b[39m transform_back(y_test)\n\u001b[0;32m---> 97\u001b[0m best_preds_train \u001b[39m=\u001b[39m baseline_hazard_estimator_eh(time_train, y_train, best_preds_train)\n\u001b[1;32m     98\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbest_preds_train\u001b[39m\u001b[39m'\u001b[39m,best_preds_train)\n\u001b[1;32m     99\u001b[0m \u001b[39m# save c-index values\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mrstrip()\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThis error may have been caused \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby the following argument(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00margs_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[39m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39;49m\u001b[39mtyping\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mUnsupportedError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[39m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39m\u001b[39munsupported_error\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function erf>) found for signature:\n \n >>> erf(array(float64, 1d, C))\n \nThere are 2 candidate implementations:\n\u001b[1m  - Of which 2 did not match due to:\n  Type Restricted Function in function 'erf': File: unknown: Line unknown.\n    With argument(s): '(array(float64, 1d, C))':\u001b[0m\n\u001b[1m   No match for registered cases:\n    * (int64,) -> float64\n    * (uint64,) -> float64\n    * (float32,) -> float32\n    * (float64,) -> float64\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function erf>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py (118)\n\u001b[0m\n\u001b[1m\nFile \"../../../../miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py\", line 118:\u001b[0m\n\u001b[1mdef gaussian_integrated_kernel(x):\n\u001b[1m    return 0.5 * (1 + erf(x / SQRT_TWO))\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function gaussian_integrated_kernel at 0x7fcf7928fa30>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py (616)\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function gaussian_integrated_kernel at 0x7fcf7928fa30>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py (616)\n\u001b[0m\n\u001b[1m\nFile \"../../../../miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_final.py\", line 616:\u001b[0m\n\u001b[1mdef baseline_hazard_estimator_eh(\n    <source elided>\n        print('difference shape', difference.shape)\n\u001b[1m        denominator += h_prefactor * gaussian_integrated_kernel(difference)\n\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "for dataset in data_set_fns:\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target\n",
    "    y = pd.concat([data.target,data.target], axis=1).to_numpy()\n",
    "    print('Dataset:',data.filename)\n",
    "    print(X.dtypes)\n",
    "    print('y', y)\n",
    "    \n",
    "    net = NeuralNetRegressor(\n",
    "    SurvivalModel, \n",
    "    module__n_layers = 1,\n",
    "    module__in_features = X.shape[1],\n",
    "    #module__num_nodes = 32,\n",
    "    #module__dropout = 0.1, # these could also be removed\n",
    "    module__out_features = 2, # change for EH\n",
    "    # for split sizes when result size = 1\n",
    "    iterator_train__drop_last=True,\n",
    "    #iterator_valid__drop_last=True,\n",
    "    criterion=EHLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__weight_decay = 0.4,\n",
    "    batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "    #callbacks=[EarlyStopping(patience=10)],\n",
    "    callbacks = [\n",
    "            (\n",
    "                \"sched\",\n",
    "                LRScheduler(\n",
    "                    torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=5,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"es\",\n",
    "                EarlyStopping(\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=10,\n",
    "                    load_best=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"seed\", FixSeed(seed=42)),\n",
    "        ],\n",
    "    #TODO: enable stratification, verify\n",
    "    train_split=ValidSplit(0.2), # might cause lower performance in metrics, explain in thesis\n",
    "    lr=0.001,\n",
    "    #max_epochs=1, #0,#100\n",
    "    #train_split=None,\n",
    "    verbose=1\n",
    "    )\n",
    "    best_model,params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test = train_eval(X, y, net, n_iter, data.filename)\n",
    "    \n",
    "#train eval function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cindex_train_METABRIC</th>\n",
       "      <th>cindex_test_METABRIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cindex_train_METABRIC  cindex_test_METABRIC\n",
       "0                    NaN                   NaN\n",
       "1                    NaN                   NaN\n",
       "2                    NaN                   NaN\n",
       "3                    NaN                   NaN\n",
       "4                    NaN                   NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  5  6]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example 2D array\n",
    "array_2d = np.array([[1, 2, 3],\n",
    "                     [4, 5, 6],\n",
    "                     [7, 8, 9],\n",
    "                     [10, 11, 12]])\n",
    "\n",
    "# List of indices to subset\n",
    "indices = [1, 3]\n",
    "\n",
    "# Subset the rows using the indices\n",
    "subset_array = array_2d[indices]\n",
    "\n",
    "print(subset_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
