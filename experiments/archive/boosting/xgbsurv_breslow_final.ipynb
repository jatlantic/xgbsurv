{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBSurv Breslow Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgbsurv.datasets import (load_metabric, load_flchain, load_rgbsg, load_support, load_tcga)\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "from xgbsurv.models.utils import sort_X_y\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.decomposition import PCA\n",
    "# import models\n",
    "from xgbsurv.models.breslow_final import breslow_likelihood,get_cumulative_hazard_function_breslow\n",
    "from xgbsurv.models.efron_final import efron_likelihood\n",
    "from xgbsurv.models.cind_final import cind_loss\n",
    "from xgbsurv.models.deephit_pycox_final import deephit_loss1_pycox\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from xgbsurv.models.utils import sort_X_y_pandas, transform_back, transform\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 50 \n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "validation_size = 0.2\n",
    "model = 'xgbsurv_breslow_'\n",
    "\n",
    "\n",
    "# set seed for scipy\n",
    "np.random.seed(rand_state)\n",
    "\n",
    "# Define parameter grid for random forest classifier\n",
    "param_grid = {\n",
    "'estimator__reg_alpha': scloguniform(1e-10,1),#[1e-10,1], # from hyp augmentation, L1 regularization\n",
    "'estimator__reg_lambda': scloguniform(1e-10,1), #[1e-10,1], #alias l2_regularization, lambda in augmentation\n",
    "'estimator__learning_rate': scloguniform(0.01,1), #[0.001,1], # assumed alias eta from augmentation,\n",
    "'estimator__n_estimators':  scrandint(1,4000), # corresponds to num_rounds\n",
    "'estimator__gamma': loguniform(0.001,1.0),#[0.1,1], # minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "'estimator__colsample_bylevel': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation\n",
    "'estimator__colsample_bynode': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation, uniform(0.1,1),\n",
    "'estimator__colsample_bytree': scuniform(0.5, 1-0.5),#[0.5,1], # from hyp augmentation, seems to exceed the bound, uniform(0.5,1)\n",
    "'estimator__max_depth': scrandint(1,20),#[1,20], # from hyp augmentation\n",
    "'estimator__max_delta_step': scrandint(0,10),#[0,10], # from hyp augmentation\n",
    "'estimator__min_child_weight' : scloguniform(0.1,20-0.1),#[0.1,20], # from hyp augmentation\n",
    "'estimator__subsample': scuniform(0.01,1-0.01),#[0.01,1], # from hyp augmentation\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits) #, shuffle=True, random_state=rand_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_function = make_scorer(breslow_likelihood, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model & Train Test Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_metabric\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6284501432901006\n",
      "Integrated Brier Score: 0.16747642064808885\n",
      "durations 0.76666665 337.03333\n",
      "Concordance Index 0.583568112376493\n",
      "Integrated Brier Score: 0.18167390617388385\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6169851395986578\n",
      "Integrated Brier Score: 0.1707133730119332\n",
      "durations 0.1 330.36667\n",
      "Concordance Index 0.5819780133335956\n",
      "Integrated Brier Score: 0.17826352073638277\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.624959385356734\n",
      "Integrated Brier Score: 0.1714790088779532\n",
      "durations 1.4333333 301.23334\n",
      "Concordance Index 0.6167951945760561\n",
      "Integrated Brier Score: 0.18828237309768828\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.4726086891964127\n",
      "Integrated Brier Score: 0.17919319357052327\n",
      "durations 1.2333333 355.2\n",
      "Concordance Index 0.4249427870441004\n",
      "Integrated Brier Score: 0.1691757242637442\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6269512559808612\n",
      "Integrated Brier Score: 0.16801027052051962\n",
      "durations 1.2666667 351.0\n",
      "Concordance Index 0.594693559037157\n",
      "Integrated Brier Score: 0.17853453986638868\n",
      "load_flchain\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.791601287816677\n",
      "Integrated Brier Score: 0.10367972767769877\n",
      "durations 1.0 5215.0\n",
      "Concordance Index 0.7935107061161736\n",
      "Integrated Brier Score: 0.10663154247176303\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.791395511500282\n",
      "Integrated Brier Score: 0.1056879110465054\n",
      "durations 1.0 5123.0\n",
      "Concordance Index 0.7932322660304316\n",
      "Integrated Brier Score: 0.10535683401653552\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.7974450651716836\n",
      "Integrated Brier Score: 0.1044246674872404\n",
      "durations 1.0 5166.0\n",
      "Concordance Index 0.7794681877886609\n",
      "Integrated Brier Score: 0.10745894833534937\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.7911541196969407\n",
      "Integrated Brier Score: 0.10926193460849863\n",
      "durations 1.0 5171.0\n",
      "Concordance Index 0.7754694742867041\n",
      "Integrated Brier Score: 0.10995464176017744\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.7914684093675225\n",
      "Integrated Brier Score: 0.10617177949503309\n",
      "durations 1.0 5187.0\n",
      "Concordance Index 0.7923414172474291\n",
      "Integrated Brier Score: 0.10186093571398229\n",
      "load_rgbsg\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6809842668806909\n",
      "Integrated Brier Score: 0.19218796873807859\n",
      "durations 0.52566737 87.359344\n",
      "Concordance Index 0.6508700930797248\n",
      "Integrated Brier Score: 0.19396532841921976\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6738946414801134\n",
      "Integrated Brier Score: 0.19286352841511098\n",
      "durations 1.87269 84.0\n",
      "Concordance Index 0.6517648309589623\n",
      "Integrated Brier Score: 0.20003832198042246\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6587190115483874\n",
      "Integrated Brier Score: 0.19620447487479398\n",
      "durations 0.49281314 85.81519\n",
      "Concordance Index 0.6617931771146272\n",
      "Integrated Brier Score: 0.19695383757155055\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6182950131601684\n",
      "Integrated Brier Score: 0.20269742394966503\n",
      "durations 1.4784395 84.0\n",
      "Concordance Index 0.5921559126759806\n",
      "Integrated Brier Score: 0.19914929265778772\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.5363737659169733\n",
      "Integrated Brier Score: 0.20253568296087673\n",
      "durations 0.26283368 84.20534\n",
      "Concordance Index 0.5652522231420407\n",
      "Integrated Brier Score: 0.20252124946798042\n",
      "load_support\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.611759336344305\n",
      "Integrated Brier Score: 0.20166901047188618\n",
      "durations 3.0 2024.0\n",
      "Concordance Index 0.6019665440650188\n",
      "Integrated Brier Score: 0.2060848429874978\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6144755416148034\n",
      "Integrated Brier Score: 0.20549226265026416\n",
      "durations 3.0 2026.0\n",
      "Concordance Index 0.59797256814854\n",
      "Integrated Brier Score: 0.2075568500854337\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6177550602426398\n",
      "Integrated Brier Score: 0.20172061344767975\n",
      "durations 3.0 2029.0\n",
      "Concordance Index 0.5906880699463346\n",
      "Integrated Brier Score: 0.2034496730462497\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6127669007952771\n",
      "Integrated Brier Score: 0.2054989829663625\n",
      "durations 3.0 2029.0\n",
      "Concordance Index 0.5988193787059143\n",
      "Integrated Brier Score: 0.2053404979101242\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.6153794196340254\n",
      "Integrated Brier Score: 0.20328115429302507\n",
      "durations 3.0 2029.0\n",
      "Concordance Index 0.6002068017751959\n",
      "Integrated Brier Score: 0.20440015514481824\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric,  load_flchain, load_rgbsg, load_support] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "data_set_fns_str = ['load_metabric', 'load_flchain', 'load_rgbsg', 'load_support'] \n",
    "one_hot_dict = {'load_flchain': ['mgus'], 'load_rgbsg':['grade'], 'load_support':['cancer', 'race'] }\n",
    "agg_metrics_cindex = []\n",
    "agg_metrics_ibs = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    model = 'xgbsurv_breslow_'\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    filename = data.filename\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(data_set_fns_str[idx])\n",
    "    #if data_set_fns_str[idx] in one_hot_dict.keys():\n",
    "    #   X = pd.get_dummies(X, columns=one_hot_dict[data_set_fns_str[idx]])\n",
    "    #print(X)\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    #print(X.dtypes)\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    # add IBS later\n",
    "    outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                    'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "    best_params = {'best_params_'+dataset_name:[]}\n",
    "    best_model = {'best_model_'+dataset_name:[]}\n",
    "    ct = make_column_transformer(\n",
    "            (StandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "            (OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['category', 'object'])),\n",
    "            remainder='passthrough')\n",
    "    \n",
    "    estimator = XGBSurv(\n",
    "        objective='breslow_objective',\n",
    "        eval_metric='breslow_loss',\n",
    "        random_state=rand_state, \n",
    "        disable_default_eval_metric=True,\n",
    "        early_stopping_rounds=early_stopping_rounds, \n",
    "        base_score=base_score,\n",
    "                        )\n",
    "    pipe = Pipeline([('scaler',ct),\n",
    "                    ('estimator', estimator)])\n",
    "    \n",
    "    rs = RandomizedSearchCV(pipe, param_grid, scoring = scoring_function, n_jobs=-1, verbose=1,\n",
    "                             cv=inner_custom_cv, n_iter=n_iter, refit=True, random_state=rand_state)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        # Split data into training and testing sets for outer fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "        X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "        #print(X_train.shape, type(X_train))\n",
    "        #print(y_train.shape, type(y_train))\n",
    "        #print(y_test.shape, type(y_test))\n",
    "        #print(X_test.shape, type(X_test))\n",
    "        # save splits and data\n",
    "        np.savetxt('splits/'+model+'train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "        np.savetxt('splits/'+model+'test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "        \n",
    "        #np.savetxt('splits/'+model+'X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "        #np.savetxt('splits/'+model+'y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "        rs.fit(X_train, y_train, estimator__eval_test_size=validation_size, estimator__verbose=0)\n",
    "        best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "        best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "        np.savetxt('predictions/'+model+'best_preds_train_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "        np.savetxt('predictions/'+model+'best_preds_test_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "\n",
    "\n",
    "        # save hyperparameter settings\n",
    "        params = rs.best_estimator_.get_params()\n",
    "        best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "        best_model['best_model_'+dataset_name] += [params]\n",
    "        try:\n",
    "            cum_hazard_train = get_cumulative_hazard_function_breslow(\n",
    "                    X_train.values, X_train.values, y_train.values, y_train.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_train.reshape(-1)\n",
    "                    )\n",
    "\n",
    "            df_survival_train = np.exp(-cum_hazard_train)\n",
    "            durations_train, events_train = transform_back(y_train.values)\n",
    "            time_grid_train = np.linspace(durations_train.min(), durations_train.max(), 100)\n",
    "            ev = EvalSurv(df_survival_train, durations_train, events_train, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_train))\n",
    "            cindex_score_train = ev.concordance_td('antolini')\n",
    "            ibs_score_train = ev.integrated_brier_score(time_grid_train)\n",
    "\n",
    "            outer_scores['cindex_train_'+dataset_name] += [cindex_score_train]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [ibs_score_train]\n",
    "\n",
    "        except:\n",
    "            outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [np.nan]\n",
    "            \n",
    "        try:\n",
    "            cum_hazard_test = get_cumulative_hazard_function_breslow(\n",
    "                    X_train.values, X_test.values, y_train.values, y_test.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_test.reshape(-1)\n",
    "                    )\n",
    "            df_survival_test = np.exp(-cum_hazard_test)\n",
    "            durations_test, events_test = transform_back(y_test.values)\n",
    "            print('durations',durations_test.min(), durations_test.max())\n",
    "            time_grid_test = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "            ev = EvalSurv(df_survival_test, durations_test, events_test, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_test))\n",
    "            cindex_score_test = ev.concordance_td('antolini')\n",
    "            ibs_score_test = ev.integrated_brier_score(time_grid_test)\n",
    "\n",
    "            outer_scores['cindex_test_'+dataset_name] += [cindex_score_test]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [ibs_score_test]\n",
    "        except: \n",
    "            outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [np.nan]\n",
    "            \n",
    "    df_best_params = pd.DataFrame(best_params)\n",
    "    df_best_model = pd.DataFrame(best_model)\n",
    "    df_outer_scores = pd.DataFrame(outer_scores)\n",
    "    df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "    df_metrics.to_csv('metrics/'+model+'metric_summary_'+filename, index=False)\n",
    "    # cindex\n",
    "    df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "                                            'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "                                            'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "                                            'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "    # IBS\n",
    "    df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "                                            'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "                                            'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "                                            'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "    agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "    agg_metrics_ibs.append(df_agg_metrics_ibs)\n",
    "\n",
    "df_final_breslow_1_cindex = pd.concat([df for df in agg_metrics_cindex]).round(4)\n",
    "df_final_breslow_1_cindex.to_csv('metrics/final_gbdt_breslow_1_cindex.csv', index=False)\n",
    "df_final_breslow_1_cindex.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_breslow_1_cindex.csv', index=False)  #\n",
    "\n",
    "\n",
    "df_final_breslow_1_ibs = pd.concat([df for df in agg_metrics_ibs]).round(4)\n",
    "df_final_breslow_1_ibs.to_csv('metrics/final_gbdt_breslow_1_ibs.csv', index=False)\n",
    "df_final_breslow_1_ibs.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_breslow_1_ibs.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA Train, Test, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'estimator__reg_alpha': scloguniform(1e-10,1),#[1e-10,1], # from hyp augmentation, L1 regularization\n",
    "'estimator__reg_lambda': scloguniform(1e-10,1), #[1e-10,1], #alias l2_regularization, lambda in augmentation\n",
    "'estimator__learning_rate': scloguniform(0.001,1), #[0.001,1], # assumed alias eta from augmentation,\n",
    "'estimator__n_estimators':  scrandint(1,4000), # corresponds to num_rounds\n",
    "'estimator__gamma': loguniform(0.001,1.0),#[0.1,1], # minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "'estimator__colsample_bylevel': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation\n",
    "'estimator__colsample_bynode': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation, uniform(0.1,1),\n",
    "'estimator__colsample_bytree': scuniform(0.5, 1-0.5),#[0.5,1], # from hyp augmentation, seems to exceed the bound, uniform(0.5,1)\n",
    "'estimator__max_depth': scrandint(1,20),#[1,20], # from hyp augmentation\n",
    "'estimator__max_delta_step': scrandint(0,10),#[0,10], # from hyp augmentation\n",
    "'estimator__min_child_weight' : scloguniform(0.1,20-0.1),#[0.1,20], # from hyp augmentation\n",
    "'estimator__subsample': scuniform(0.01,1-0.01),#[0.01,1], # from hyp augmentation\n",
    "#'pca__n_components': [8, 16, 32, 64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5836867141118773\n",
      "Integrated Brier Score: 0.21176101878979997\n",
      "durations 17.0 4343.0\n",
      "Concordance Index 0.512707182320442\n",
      "Integrated Brier Score: 0.2283581235690097\n",
      "Concordance Index 0.5352995733630125\n",
      "Integrated Brier Score: 0.21122499291172517\n",
      "durations 15.0 3817.0\n",
      "Concordance Index 0.4953577280174768\n",
      "Integrated Brier Score: 0.22566868213254435\n",
      "Concordance Index 0.3535331595713872\n",
      "Integrated Brier Score: 0.21167446671487952\n",
      "durations 59.0 5050.0\n",
      "Concordance Index 0.3279569892473118\n",
      "Integrated Brier Score: 0.2236603665395486\n",
      "Concordance Index 0.48783877692842254\n",
      "Integrated Brier Score: 0.2145945009673613\n",
      "durations 55.0 5041.0\n",
      "Concordance Index 0.5355097365406644\n",
      "Integrated Brier Score: 0.2238195962972718\n",
      "Concordance Index 0.5738744451490171\n",
      "Integrated Brier Score: 0.22153864891178524\n",
      "durations 13.0 3432.0\n",
      "Concordance Index 0.5733678086619263\n",
      "Integrated Brier Score: 0.21256957037237686\n",
      "Concordance Index 0.26105560126954275\n",
      "Integrated Brier Score: 0.18405887220930228\n",
      "durations 5.0 8605.0\n",
      "Concordance Index 0.2170138888888889\n",
      "Integrated Brier Score: 0.2064150325587151\n",
      "Concordance Index 0.5770973174260573\n",
      "Integrated Brier Score: 0.19116596950692605\n",
      "durations 5.0 8008.0\n",
      "Concordance Index 0.46310640032613126\n",
      "Integrated Brier Score: 0.19402390589048654\n",
      "Concordance Index 0.5182543725590083\n",
      "Integrated Brier Score: 0.18861237801026906\n",
      "durations 5.0 8556.0\n",
      "Concordance Index 0.4619402985074627\n",
      "Integrated Brier Score: 0.20096268774801573\n",
      "Concordance Index 0.1701226309921962\n",
      "Integrated Brier Score: 0.19656501929086084\n",
      "durations 1.0 7106.0\n",
      "Concordance Index 0.3677239456256535\n",
      "Integrated Brier Score: 0.18200200391996138\n",
      "Concordance Index 0.5314868734509228\n",
      "Integrated Brier Score: 0.19189120127976633\n",
      "durations 1.0 8391.0\n",
      "Concordance Index 0.476357952325127\n",
      "Integrated Brier Score: 0.19857439749591205\n",
      "Concordance Index 0.25599619504903404\n",
      "Integrated Brier Score: 0.18650827301141953\n",
      "durations 23.0 4760.0\n",
      "Concordance Index 0.2711746253049843\n",
      "Integrated Brier Score: 0.20299419334647853\n",
      "Concordance Index 0.5809638769670958\n",
      "Integrated Brier Score: 0.18863689389840663\n",
      "durations 14.0 4282.0\n",
      "Concordance Index 0.5745548961424333\n",
      "Integrated Brier Score: 0.19228242002548632\n",
      "Concordance Index 0.5818593902764199\n",
      "Integrated Brier Score: 0.18513995666485517\n",
      "durations 11.0 6417.0\n",
      "Concordance Index 0.46090225563909776\n",
      "Integrated Brier Score: 0.20745704047573255\n",
      "Concordance Index 0.551497277676951\n",
      "Integrated Brier Score: 0.17444578140921937\n",
      "durations 2.0 5480.0\n",
      "Concordance Index 0.5454545454545454\n",
      "Integrated Brier Score: 0.212155196162493\n",
      "Concordance Index 0.605867718582603\n",
      "Integrated Brier Score: 0.18168599872129965\n",
      "durations 14.0 5152.0\n",
      "Concordance Index 0.4989106753812636\n",
      "Integrated Brier Score: 0.20410523376717785\n"
     ]
    }
   ],
   "source": [
    "cancer_types = [\n",
    "    'BLCA',\n",
    "    'BRCA',\n",
    "    'HNSC',\n",
    "    'KIRC',\n",
    "    'LGG',\n",
    "    'LIHC',\n",
    "    'LUAD',\n",
    "    'LUSC',\n",
    "    'OV',\n",
    "    'STAD'\n",
    "    ]\n",
    "agg_metrics_cindex = []\n",
    "agg_metrics_ibs = []\n",
    "\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types):\n",
    "    model = 'xgbsurv_breslow_tcga_'\n",
    "    # get name of current dataset\n",
    "    data = load_tcga(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", cancer_type=cancer_type, as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "    filename = data.filename\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "\n",
    "    # add IBS later\n",
    "    outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                    'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "    best_params = {'best_params_'+dataset_name:[]}\n",
    "    best_model = {'best_model_'+dataset_name:[]}\n",
    "    ct = make_column_transformer(\n",
    "            (StandardScaler(), make_column_selector(dtype_include=['float32']))\n",
    "            ,remainder='passthrough')\n",
    "    \n",
    "    estimator = XGBSurv(\n",
    "        objective='breslow_objective',\n",
    "        eval_metric='breslow_loss',\n",
    "        random_state=rand_state, \n",
    "        disable_default_eval_metric=True,\n",
    "        early_stopping_rounds=early_stopping_rounds, \n",
    "        base_score=base_score\n",
    "                        )\n",
    "    \n",
    "    pipe = Pipeline([('scaler',ct),\n",
    "                    #('pca', PCA()),\n",
    "                    ('estimator', estimator)])\n",
    "    \n",
    "    rs = RandomizedSearchCV(pipe, param_grid, scoring = scoring_function, n_jobs=-1, \n",
    "                             cv=inner_custom_cv, n_iter=n_iter, refit=True, random_state=rand_state)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        # Split data into training and testing sets for outer fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "        X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "        #print(y_train.shape, type(y_train))\n",
    "        #print(X_train.shape, type(X_train))\n",
    "        #print(X_test.shape, type(X_test))\n",
    "        #print(y_test.shape, type(y_test))\n",
    "        # save splits and data\n",
    "        np.savetxt('splits/'+model+'train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "        np.savetxt('splits/'+model+'test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "        \n",
    "        #np.savetxt('splits/'+model+'X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "        #np.savetxt('splits/'+model+'y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "        rs.fit(X_train, y_train, estimator__eval_test_size=0.2, estimator__verbose=0)\n",
    "        best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "        best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "        np.savetxt('predictions/'+model+'best_preds_train_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "        np.savetxt('predictions/'+model+'best_preds_test_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "\n",
    "        # save hyperparameter settings\n",
    "        params = rs.best_estimator_.get_params()\n",
    "        best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "        best_model['best_model_'+dataset_name] += [params]\n",
    "        \n",
    "        try:\n",
    "            cum_hazard_train = get_cumulative_hazard_function_breslow(\n",
    "                    X_train.values, X_train.values, y_train.values, y_train.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_train.reshape(-1)\n",
    "                    )\n",
    "\n",
    "            df_survival_train = np.exp(-cum_hazard_train)\n",
    "            durations_train, events_train = transform_back(y_train.values)\n",
    "            time_grid_train = np.linspace(durations_train.min(), durations_train.max(), 100)\n",
    "            ev = EvalSurv(df_survival_train, durations_train, events_train, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_train))\n",
    "            cindex_score_train = ev.concordance_td('antolini')\n",
    "            ibs_score_train = ev.integrated_brier_score(time_grid_train)\n",
    "\n",
    "            outer_scores['cindex_train_'+dataset_name] += [cindex_score_train]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [ibs_score_train]\n",
    "\n",
    "        except:\n",
    "            outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [np.nan]\n",
    "            \n",
    "        try:\n",
    "            cum_hazard_test = get_cumulative_hazard_function_breslow(\n",
    "                    X_train.values, X_test.values, y_train.values, y_test.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_test.reshape(-1)\n",
    "                    )\n",
    "            df_survival_test = np.exp(-cum_hazard_test)\n",
    "            durations_test, events_test = transform_back(y_test.values)\n",
    "            print('durations',durations_test.min(), durations_test.max())\n",
    "            time_grid_test = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "            ev = EvalSurv(df_survival_test, durations_test, events_test, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_test))\n",
    "            cindex_score_test = ev.concordance_td('antolini')\n",
    "            ibs_score_test = ev.integrated_brier_score(time_grid_test)\n",
    "\n",
    "            outer_scores['cindex_test_'+dataset_name] += [cindex_score_test]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [ibs_score_test]\n",
    "        except: \n",
    "            outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [np.nan]\n",
    "            \n",
    "    df_best_params = pd.DataFrame(best_params)\n",
    "    df_best_model = pd.DataFrame(best_model)\n",
    "    df_outer_scores = pd.DataFrame(outer_scores)\n",
    "    df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "    df_metrics.to_csv('metrics/'+model+'metric_summary_'+filename, index=False)\n",
    "            # cindex\n",
    "    df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "                                            'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "                                            'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "                                            'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "    # IBS\n",
    "    df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "                                            'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "                                            'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "                                            'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "\n",
    "    agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "    agg_metrics_ibs.append(df_agg_metrics_ibs)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cindex_train_mean</th>\n",
       "      <th>cindex_train_std</th>\n",
       "      <th>cindex_test_mean</th>\n",
       "      <th>cindex_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.4702</td>\n",
       "      <td>0.1195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  cindex_train_mean  cindex_train_std  cindex_test_mean  \\\n",
       "0    BLCA             0.5068            0.0936            0.4890   \n",
       "0    BRCA             0.4116            0.1831            0.3972   \n",
       "0    HNSC             0.5152            0.1462            0.4702   \n",
       "\n",
       "   cindex_test_std  \n",
       "0           0.0946  \n",
       "0           0.1097  \n",
       "0           0.1195  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_breslow_1_cindex = pd.concat([df for df in agg_metrics_cindex]).round(4)\n",
    "df_final_breslow_1_cindex.to_csv('metrics/final_gbdt_tcga_breslow_1_cindex.csv', index=False)\n",
    "df_final_breslow_1_cindex.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_tcga_breslow_1_cindex.csv', index=False)  #\n",
    "df_final_breslow_1_cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ibs_train_mean</th>\n",
       "      <th>ibs_train_std</th>\n",
       "      <th>ibs_test_mean</th>\n",
       "      <th>ibs_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  ibs_train_mean  ibs_train_std  ibs_test_mean  ibs_test_std\n",
       "0    BLCA          0.2142         0.0043         0.2228        0.0060\n",
       "0    BRCA          0.1905         0.0046         0.1964        0.0092\n",
       "0    HNSC          0.1833         0.0055         0.2038        0.0074"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_breslow_1_ibs = pd.concat([df for df in agg_metrics_ibs]).round(4)\n",
    "df_final_breslow_1_ibs.to_csv('metrics/final_gbdt_tcga_breslow_1_ibs.csv', index=False)\n",
    "df_final_breslow_1_ibs.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_tcga_breslow_1_ibs.csv', index=False) \n",
    "df_final_breslow_1_ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
