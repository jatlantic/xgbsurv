{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBSurv Efron Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgbsurv.datasets import (load_metabric, load_flchain, load_rgbsg, load_support, load_tcga)\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "from xgbsurv.models.utils import sort_X_y\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.decomposition import PCA\n",
    "# import models\n",
    "from xgbsurv.models.efron_final import efron_likelihood, get_cumulative_hazard_function_efron\n",
    "from pycox.evaluation import EvalSurv\n",
    "from xgbsurv.models.utils import sort_X_y_pandas, transform_back, transform\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 50 #0\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "validation_size = 0.2\n",
    "model = 'xgbsurv_efron_'\n",
    "\n",
    "# set seed for scipy\n",
    "np.random.seed(rand_state)\n",
    "\n",
    "# Define parameter grid for random forest classifier\n",
    "param_grid = {\n",
    "'estimator__reg_alpha': scloguniform(1e-10,1),#[1e-10,1], # from hyp augmentation, L1 regularization\n",
    "'estimator__reg_lambda': scloguniform(1e-10,1), #[1e-10,1], #alias l2_regularization, lambda in augmentation\n",
    "'estimator__learning_rate': scloguniform(0.01,1), #[0.001,1], # assumed alias eta from augmentation,\n",
    "'estimator__n_estimators':  scrandint(1,4000), # corresponds to num_rounds\n",
    "'estimator__gamma': loguniform(0.001, 1.0),#[0.1,1], # minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "'estimator__colsample_bylevel': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation\n",
    "'estimator__colsample_bynode': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation, uniform(0.1,1),\n",
    "'estimator__colsample_bytree': scuniform(0.5, 1-0.5),#[0.5,1], # from hyp augmentation, seems to exceed the bound, uniform(0.5,1)\n",
    "'estimator__max_depth': scrandint(1,20),#[1,20], # from hyp augmentation\n",
    "'estimator__max_delta_step': scrandint(0,10),#[0,10], # from hyp augmentation\n",
    "'estimator__min_child_weight' : scloguniform(0.1,20-0.1),#[0.1,20], # from hyp augmentation\n",
    "'estimator__subsample': scuniform(0.01,1-0.01),#[0.01,1], # from hyp augmentation\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_function = make_scorer(efron_likelihood, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model & Train Test Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_metabric\n",
      "MKI67                float32\n",
      "EGFR                 float32\n",
      "PGR                  float32\n",
      "ERBB2                float32\n",
      "hormone_treatment      uint8\n",
      "radiotherapy           uint8\n",
      "chemotherapy           uint8\n",
      "ER_positive            uint8\n",
      "age                  float32\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m\n\u001b[1;32m     59\u001b[0m np\u001b[39m.\u001b[39msavetxt(\u001b[39m'\u001b[39m\u001b[39msplits/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mmodel\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest_index_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfilename, test_index, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[39m#np.savetxt('splits/'+model+'X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m#np.savetxt('splits/'+model+'X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[39m#np.savetxt('splits/'+model+'y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m#np.savetxt('splits/'+model+'y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m rs\u001b[39m.\u001b[39;49mfit(X_train, y_train, estimator__eval_test_size\u001b[39m=\u001b[39;49mvalidation_size, estimator__verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     68\u001b[0m best_preds_train \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[1;32m     69\u001b[0m best_preds_test \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:909\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    907\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    908\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 909\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    910\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    911\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgbsurv/base.py:116\u001b[0m, in \u001b[0;36mXGBSurv.fit\u001b[0;34m(self, X, y, eval_test_size, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     eval_set \u001b[39m=\u001b[39m [(X_train, y_train),(X_test, y_test)]\n\u001b[1;32m    114\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39meval_set\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m eval_set\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(XGBSurv, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_X_y(X,y)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/core.py:1923\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1923\u001b[0m     grad, hess \u001b[39m=\u001b[39m fobj(pred, dtrain)\n\u001b[1;32m   1924\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboost(dtrain, grad, hess)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/sklearn.py:107\u001b[0m, in \u001b[0;36m_objective_decorator.<locals>.inner\u001b[0;34m(preds, dmatrix)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"internal function\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m labels \u001b[39m=\u001b[39m dmatrix\u001b[39m.\u001b[39mget_label()\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m func(labels, preds)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/dispatcher.py:420\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    418\u001b[0m return_val \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     return_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile(\u001b[39mtuple\u001b[39;49m(argtypes))\n\u001b[1;32m    421\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mForceLiteralArg \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    422\u001b[0m     \u001b[39m# Received request for compiler re-entry with the list of arguments\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[39m# indicated by e.requested_args.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[39m# First, check if any of these args are already Literal-ized\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     already_lit_pos \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m e\u001b[39m.\u001b[39mrequested_args\n\u001b[1;32m    426\u001b[0m                        \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[i], types\u001b[39m.\u001b[39mLiteral)]\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/dispatcher.py:965\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[39mwith\u001b[39;00m ev\u001b[39m.\u001b[39mtrigger_event(\u001b[39m\"\u001b[39m\u001b[39mnumba:compile\u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m=\u001b[39mev_details):\n\u001b[1;32m    964\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m         cres \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compiler\u001b[39m.\u001b[39;49mcompile(args, return_type)\n\u001b[1;32m    966\u001b[0m     \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mForceLiteralArg \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    967\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mfolded\u001b[39m(args, kws):\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/dispatcher.py:125\u001b[0m, in \u001b[0;36m_FunctionCompiler.compile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(\u001b[39mself\u001b[39m, args, return_type):\n\u001b[0;32m--> 125\u001b[0m     status, retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_cached(args, return_type)\n\u001b[1;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m status:\n\u001b[1;32m    127\u001b[0m         \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/dispatcher.py:139\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_cached\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_core(args, return_type)\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mTypingError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_failed_cache[key] \u001b[39m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/dispatcher.py:152\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_core\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    149\u001b[0m flags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_customize_flags(flags)\n\u001b[1;32m    151\u001b[0m impl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_implementation(args, {})\n\u001b[0;32m--> 152\u001b[0m cres \u001b[39m=\u001b[39m compiler\u001b[39m.\u001b[39;49mcompile_extra(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtargetdescr\u001b[39m.\u001b[39;49mtyping_context,\n\u001b[1;32m    153\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtargetdescr\u001b[39m.\u001b[39;49mtarget_context,\n\u001b[1;32m    154\u001b[0m                               impl,\n\u001b[1;32m    155\u001b[0m                               args\u001b[39m=\u001b[39;49margs, return_type\u001b[39m=\u001b[39;49mreturn_type,\n\u001b[1;32m    156\u001b[0m                               flags\u001b[39m=\u001b[39;49mflags, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocals,\n\u001b[1;32m    157\u001b[0m                               pipeline_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline_class)\n\u001b[1;32m    158\u001b[0m \u001b[39m# Check typing error if object mode is used\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m cres\u001b[39m.\u001b[39mtyping_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m flags\u001b[39m.\u001b[39menable_pyobject:\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:742\u001b[0m, in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \n\u001b[1;32m    720\u001b[0m \u001b[39mParameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39m    compiler pipeline\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    740\u001b[0m pipeline \u001b[39m=\u001b[39m pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    741\u001b[0m                           args, return_type, flags, \u001b[39mlocals\u001b[39m)\n\u001b[0;32m--> 742\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline\u001b[39m.\u001b[39;49mcompile_extra(func)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:460\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlifted \u001b[39m=\u001b[39m ()\n\u001b[1;32m    459\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlifted_from \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_bytecode()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:528\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfunc_ir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_core()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:494\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 494\u001b[0m     pm\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate)\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mcr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m pass_inst \u001b[39m=\u001b[39m _pass_registry\u001b[39m.\u001b[39mget(pss)\u001b[39m.\u001b[39mpass_inst\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[0;32m--> 356\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runPass(idx, pass_inst, state)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mBaseException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLegacy pass in use\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire_compile_lock\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_machinery.py:311\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m check(pss\u001b[39m.\u001b[39mrun_initialization, internal_state)\n\u001b[1;32m    310\u001b[0m \u001b[39mwith\u001b[39;00m SimpleTimer() \u001b[39mas\u001b[39;00m pass_time:\n\u001b[0;32m--> 311\u001b[0m     mutated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m check(pss\u001b[39m.\u001b[39;49mrun_pass, internal_state)\n\u001b[1;32m    312\u001b[0m \u001b[39mwith\u001b[39;00m SimpleTimer() \u001b[39mas\u001b[39;00m finalize_time:\n\u001b[1;32m    313\u001b[0m     mutated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m check(pss\u001b[39m.\u001b[39mrun_finalizer, internal_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_machinery.py:273\u001b[0m, in \u001b[0;36mPassManager._runPass.<locals>.check\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(func, compiler_state):\n\u001b[0;32m--> 273\u001b[0m     mangled \u001b[39m=\u001b[39m func(compiler_state)\n\u001b[1;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m mangled \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mCompilerPass implementations should return True/False. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mCompilerPass with name \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m did not.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/typed_passes.py:466\u001b[0m, in \u001b[0;36mBaseNativeLowering.run_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mwith\u001b[39;00m targetctx\u001b[39m.\u001b[39mpush_code_library(library):\n\u001b[1;32m    464\u001b[0m     lower \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlowering_class(targetctx, library, fndesc, interp,\n\u001b[1;32m    465\u001b[0m                                 metadata\u001b[39m=\u001b[39mmetadata)\n\u001b[0;32m--> 466\u001b[0m     lower\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m    467\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m flags\u001b[39m.\u001b[39mno_cpython_wrapper:\n\u001b[1;32m    468\u001b[0m         lower\u001b[39m.\u001b[39mcreate_cpython_wrapper(flags\u001b[39m.\u001b[39mrelease_gil)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:187\u001b[0m, in \u001b[0;36mBaseLower.lower\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenlower \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_normal_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfndesc)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenlower \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGeneratorLower(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:241\u001b[0m, in \u001b[0;36mBaseLower.lower_normal_function\u001b[0;34m(self, fndesc)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m# Init argument values\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_function_arguments()\n\u001b[0;32m--> 241\u001b[0m entry_block_tail \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_function_body()\n\u001b[1;32m    243\u001b[0m \u001b[39m# Close tail of entry block, do not emit debug metadata else the\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# unconditional jump gets associated with the metadata from the function\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# body end.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39mwith\u001b[39;00m debuginfo\u001b[39m.\u001b[39msuspend_emission(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder):\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:271\u001b[0m, in \u001b[0;36mBaseLower.lower_function_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mposition_at_end(bb)\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug_print(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m# lower block: \u001b[39m\u001b[39m{\u001b[39;00moffset\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_block(block)\n\u001b[1;32m    272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_lower()\n\u001b[1;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m entry_block_tail\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:285\u001b[0m, in \u001b[0;36mBaseLower.lower_block\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    282\u001b[0m     defaulterrcls \u001b[39m=\u001b[39m partial(LoweringError, loc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc)\n\u001b[1;32m    283\u001b[0m     \u001b[39mwith\u001b[39;00m new_error_context(\u001b[39m'\u001b[39m\u001b[39mlowering \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{inst}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m at \u001b[39m\u001b[39m{loc}\u001b[39;00m\u001b[39m'\u001b[39m, inst\u001b[39m=\u001b[39minst,\n\u001b[1;32m    284\u001b[0m                            loc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc, errcls_\u001b[39m=\u001b[39mdefaulterrcls):\n\u001b[0;32m--> 285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_inst(inst)\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_block(block)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:463\u001b[0m, in \u001b[0;36mLower.lower_inst\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inst, ir\u001b[39m.\u001b[39mAssign):\n\u001b[1;32m    462\u001b[0m     ty \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypeof(inst\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mname)\n\u001b[0;32m--> 463\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_assign(ty, inst)\n\u001b[1;32m    464\u001b[0m     argidx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[39m# If this is a store from an arg, like x = arg.x then tell debuginfo\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39m# that this is the arg\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:675\u001b[0m, in \u001b[0;36mLower.lower_assign\u001b[0;34m(self, ty, inst)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m    674\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ir\u001b[39m.\u001b[39mExpr):\n\u001b[0;32m--> 675\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_expr(ty, value)\n\u001b[1;32m    677\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ir\u001b[39m.\u001b[39mVar):\n\u001b[1;32m    678\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadvar(value\u001b[39m.\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/lowering.py:1417\u001b[0m, in \u001b[0;36mLower.lower_expr\u001b[0;34m(self, resty, expr)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mget_constant_null(resty)\n\u001b[1;32m   1416\u001b[0m \u001b[39melif\u001b[39;00m expr\u001b[39m.\u001b[39mop \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mspecial_ops:\n\u001b[0;32m-> 1417\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49mspecial_ops[expr\u001b[39m.\u001b[39;49mop](\u001b[39mself\u001b[39;49m, expr)\n\u001b[1;32m   1418\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m   1420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(expr)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/np/ufunc/array_exprs.py:406\u001b[0m, in \u001b[0;36m_lower_array_expr\u001b[0;34m(lowerer, expr)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m# Follow the Numpy error model.  Note this also allows e.g. vectorizing\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39m# division (issue #1223).\u001b[39;00m\n\u001b[1;32m    405\u001b[0m flags\u001b[39m.\u001b[39merror_model \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 406\u001b[0m cres \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mcompile_subroutine(builder, impl, inner_sig, flags\u001b[39m=\u001b[39;49mflags,\n\u001b[1;32m    407\u001b[0m                                   caching\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    409\u001b[0m \u001b[39m# Create kernel subclass calling our native function\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumba\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnp\u001b[39;00m \u001b[39mimport\u001b[39;00m npyimpl\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/base.py:863\u001b[0m, in \u001b[0;36mBaseContext.compile_subroutine\u001b[0;34m(self, builder, impl, sig, locals, flags, caching)\u001b[0m\n\u001b[1;32m    861\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_internal_func\u001b[39m.\u001b[39mget(cache_key)\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m cached \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 863\u001b[0m     cres \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_subroutine_no_cache(builder, impl, sig,\n\u001b[1;32m    864\u001b[0m                                              \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m                                              flags\u001b[39m=\u001b[39;49mflags)\n\u001b[1;32m    866\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_internal_func[cache_key] \u001b[39m=\u001b[39m cres\n\u001b[1;32m    868\u001b[0m cres \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_internal_func[cache_key]\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/base.py:834\u001b[0m, in \u001b[0;36mBaseContext._compile_subroutine_no_cache\u001b[0;34m(self, builder, impl, sig, locals, flags)\u001b[0m\n\u001b[1;32m    831\u001b[0m flags\u001b[39m.\u001b[39mno_cpython_wrapper \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    832\u001b[0m flags\u001b[39m.\u001b[39mno_cfunc_wrapper \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m cres \u001b[39m=\u001b[39m compiler\u001b[39m.\u001b[39;49mcompile_internal(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtyping_context, \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    835\u001b[0m                                  library,\n\u001b[1;32m    836\u001b[0m                                  impl, sig\u001b[39m.\u001b[39;49margs,\n\u001b[1;32m    837\u001b[0m                                  sig\u001b[39m.\u001b[39;49mreturn_type, flags,\n\u001b[1;32m    838\u001b[0m                                  \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m)\n\u001b[1;32m    840\u001b[0m \u001b[39m# Allow inlining the function inside callers.\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_code_library\u001b[39m.\u001b[39madd_linking_library(cres\u001b[39m.\u001b[39mlibrary)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:816\u001b[0m, in \u001b[0;36mcompile_internal\u001b[0;34m(typingctx, targetctx, library, func, args, return_type, flags, locals)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39mFor internal use only.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    814\u001b[0m pipeline \u001b[39m=\u001b[39m Compiler(typingctx, targetctx, library,\n\u001b[1;32m    815\u001b[0m                     args, return_type, flags, \u001b[39mlocals\u001b[39m)\n\u001b[0;32m--> 816\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline\u001b[39m.\u001b[39;49mcompile_extra(func)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:460\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlifted \u001b[39m=\u001b[39m ()\n\u001b[1;32m    459\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlifted_from \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_bytecode()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:528\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfunc_ir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_core()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler.py:494\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 494\u001b[0m     pm\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate)\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mcr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m pass_inst \u001b[39m=\u001b[39m _pass_registry\u001b[39m.\u001b[39mget(pss)\u001b[39m.\u001b[39mpass_inst\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[0;32m--> 356\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runPass(idx, pass_inst, state)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mBaseException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLegacy pass in use\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire_compile_lock\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/numba/core/compiler_machinery.py:303\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    295\u001b[0m pss\u001b[39m.\u001b[39manalysis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_analysis\n\u001b[1;32m    297\u001b[0m qualname \u001b[39m=\u001b[39m internal_state\u001b[39m.\u001b[39mfunc_id\u001b[39m.\u001b[39mfunc_qualname\n\u001b[1;32m    299\u001b[0m ev_details \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    300\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpss\u001b[39m.\u001b[39mname()\u001b[39m}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{\u001b[39;00mqualname\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    301\u001b[0m     qualname\u001b[39m=\u001b[39mqualname,\n\u001b[1;32m    302\u001b[0m     module\u001b[39m=\u001b[39minternal_state\u001b[39m.\u001b[39mfunc_id\u001b[39m.\u001b[39mmodname,\n\u001b[0;32m--> 303\u001b[0m     flags\u001b[39m=\u001b[39mpformat(internal_state\u001b[39m.\u001b[39;49mflags\u001b[39m.\u001b[39;49mvalues()),\n\u001b[1;32m    304\u001b[0m     args\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(internal_state\u001b[39m.\u001b[39margs),\n\u001b[1;32m    305\u001b[0m     return_type\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(internal_state\u001b[39m.\u001b[39mreturn_type),\n\u001b[1;32m    306\u001b[0m )\n\u001b[1;32m    307\u001b[0m \u001b[39mwith\u001b[39;00m ev\u001b[39m.\u001b[39mtrigger_event(\u001b[39m\"\u001b[39m\u001b[39mnumba:run_pass\u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m=\u001b[39mev_details):\n\u001b[1;32m    308\u001b[0m     \u001b[39mwith\u001b[39;00m SimpleTimer() \u001b[39mas\u001b[39;00m init_time:\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:62\u001b[0m, in \u001b[0;36mpformat\u001b[0;34m(object, indent, width, depth, compact, sort_dicts, underscore_numbers)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpformat\u001b[39m(\u001b[39mobject\u001b[39m, indent\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m80\u001b[39m, depth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m     58\u001b[0m             compact\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, sort_dicts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, underscore_numbers\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format a Python object into a pretty-printed representation.\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m PrettyPrinter(indent\u001b[39m=\u001b[39;49mindent, width\u001b[39m=\u001b[39;49mwidth, depth\u001b[39m=\u001b[39;49mdepth,\n\u001b[1;32m     61\u001b[0m                          compact\u001b[39m=\u001b[39;49mcompact, sort_dicts\u001b[39m=\u001b[39;49msort_dicts,\n\u001b[0;32m---> 62\u001b[0m                          underscore_numbers\u001b[39m=\u001b[39;49munderscore_numbers)\u001b[39m.\u001b[39;49mpformat(\u001b[39mobject\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:158\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m):\n\u001b[1;32m    157\u001b[0m     sio \u001b[39m=\u001b[39m _StringIO()\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format(\u001b[39mobject\u001b[39;49m, sio, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, {}, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m sio\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:175\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m rep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_repr(\u001b[39mobject\u001b[39;49m, context, level)\n\u001b[1;32m    176\u001b[0m max_width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_width \u001b[39m-\u001b[39m indent \u001b[39m-\u001b[39m allowance\n\u001b[1;32m    177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(rep) \u001b[39m>\u001b[39m max_width:\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:455\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m, context, level):\n\u001b[0;32m--> 455\u001b[0m     \u001b[39mrepr\u001b[39m, readable, recursive \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39mobject\u001b[39;49m, context\u001b[39m.\u001b[39;49mcopy(),\n\u001b[1;32m    456\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_depth, level)\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m readable:\n\u001b[1;32m    458\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:468\u001b[0m, in \u001b[0;36mPrettyPrinter.format\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m, context, maxlevels, level):\n\u001b[1;32m    464\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format object for a specific context, returning a string\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39m    and flags indicating whether the representation is 'readable'\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    and whether the object represents a recursive construct.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_safe_repr(\u001b[39mobject\u001b[39;49m, context, maxlevels, level)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:580\u001b[0m, in \u001b[0;36mPrettyPrinter._safe_repr\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    578\u001b[0m level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_dicts:\n\u001b[0;32m--> 580\u001b[0m     items \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mobject\u001b[39m\u001b[39m.\u001b[39mitems(), key\u001b[39m=\u001b[39m_safe_tuple)\n\u001b[1;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     items \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39mitems()\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/pprint.py:104\u001b[0m, in \u001b[0;36m_safe_tuple\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_tuple\u001b[39m(t):\n\u001b[1;32m    103\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHelper function for comparing 2-tuples\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m _safe_key(t[\u001b[39m0\u001b[39m]), _safe_key(t[\u001b[39m1\u001b[39;49m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric,  load_flchain, load_rgbsg, load_support] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "data_set_fns_str = ['load_metabric', 'load_flchain', 'load_rgbsg', 'load_support'] \n",
    "one_hot_dict = {'load_flchain': ['mgus'],  'load_rgbsg':['grade'],'load_support':['cancer', 'race']}\n",
    "agg_metrics_cindex = []\n",
    "agg_metrics_ibs = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    model = 'xgbsurv_efron_'\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    filename = data.filename\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(data_set_fns_str[idx])\n",
    "    if data_set_fns_str[idx] in one_hot_dict.keys():\n",
    "       X = pd.get_dummies(X, columns=one_hot_dict[data_set_fns_str[idx]])\n",
    "    print(X.dtypes)\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    #print(X.dtypes)\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    # add IBS later\n",
    "    outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                    'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "    best_params = {'best_params_'+dataset_name:[]}\n",
    "    best_model = {'best_model_'+dataset_name:[]}\n",
    "    ct = make_column_transformer(\n",
    "            (StandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "            #(OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'), make_column_selector(dtype_include=['category', 'object'])),\n",
    "            remainder='passthrough')\n",
    "    \n",
    "    estimator = XGBSurv(\n",
    "        objective='efron_objective',\n",
    "        eval_metric='efron_loss',\n",
    "        random_state=rand_state, \n",
    "        disable_default_eval_metric=True,\n",
    "        early_stopping_rounds=early_stopping_rounds, \n",
    "        base_score=base_score,\n",
    "                        )\n",
    "    pipe = Pipeline([('scaler',ct),\n",
    "                    ('estimator', estimator)])\n",
    "    \n",
    "    rs = RandomizedSearchCV(pipe, param_grid, scoring = scoring_function, n_jobs=-1, \n",
    "                             cv=inner_custom_cv, n_iter=n_iter, refit=True, random_state=rand_state)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        # Split data into training and testing sets for outer fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "        X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "        #print(X_train.shape, type(X_train))\n",
    "        #print(y_train.shape, type(y_train))\n",
    "        #print(y_test.shape, type(y_test))\n",
    "        #print(X_test.shape, type(X_test))\n",
    "        # save splits and data\n",
    "        np.savetxt('splits/'+model+'train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "        np.savetxt('splits/'+model+'test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "        \n",
    "        #np.savetxt('splits/'+model+'X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "        #np.savetxt('splits/'+model+'y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "        rs.fit(X_train, y_train, estimator__eval_test_size=validation_size, estimator__verbose=0)\n",
    "        best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "        best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "        np.savetxt('predictions/'+model+'best_preds_train_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "        np.savetxt('predictions/'+model+'best_preds_test_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "\n",
    "\n",
    "        # save hyperparameter settings\n",
    "        params = rs.best_estimator_.get_params\n",
    "        best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "        best_model['best_model_'+dataset_name] += [params]\n",
    "        try:\n",
    "            cum_hazard_train = get_cumulative_hazard_function_efron(\n",
    "                    X_train.values, X_train.values, y_train.values, y_train.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_train.reshape(-1)\n",
    "                    )\n",
    "\n",
    "            df_survival_train = np.exp(-cum_hazard_train)\n",
    "            durations_train, events_train = transform_back(y_train.values)\n",
    "            time_grid_train = np.linspace(durations_train.min(), durations_train.max(), 100)\n",
    "            ev = EvalSurv(df_survival_train, durations_train, events_train, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_train))\n",
    "            cindex_score_train = ev.concordance_td('antolini')\n",
    "            ibs_score_train = ev.integrated_brier_score(time_grid_train)\n",
    "\n",
    "            outer_scores['cindex_train_'+dataset_name] += [cindex_score_train]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [ibs_score_train]\n",
    "\n",
    "        except:\n",
    "            outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [np.nan]\n",
    "            \n",
    "        try:\n",
    "            cum_hazard_test = get_cumulative_hazard_function_efron(\n",
    "                    X_train.values, X_test.values, y_train.values, y_test.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_test.reshape(-1)\n",
    "                    )\n",
    "            df_survival_test = np.exp(-cum_hazard_test)\n",
    "            durations_test, events_test = transform_back(y_test.values)\n",
    "            print('durations',durations_test.min(), durations_test.max())\n",
    "            time_grid_test = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "            ev = EvalSurv(df_survival_test, durations_test, events_test, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_test))\n",
    "            cindex_score_test = ev.concordance_td('antolini')\n",
    "            ibs_score_test = ev.integrated_brier_score(time_grid_test)\n",
    "\n",
    "            outer_scores['cindex_test_'+dataset_name] += [cindex_score_test]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [ibs_score_test]\n",
    "        except: \n",
    "            outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [np.nan]\n",
    "            \n",
    "    df_best_params = pd.DataFrame(best_params)\n",
    "    df_best_model = pd.DataFrame(best_model)\n",
    "    df_outer_scores = pd.DataFrame(outer_scores)\n",
    "    df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "    df_metrics.to_csv('metrics/'+model+'metric_summary_'+filename, index=False)\n",
    "    # cindex\n",
    "    df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "                                            'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "                                            'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "                                            'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "    # IBS\n",
    "    df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "                                            'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "                                            'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "                                            'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "    agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "    agg_metrics_ibs.append(df_agg_metrics_ibs)\n",
    "\n",
    "df_final_breslow_1_cindex = pd.concat([df for df in agg_metrics_cindex]).round(4)\n",
    "df_final_breslow_1_cindex.to_csv('metrics/final_gbdt_efron_1_cindex.csv', index=False)\n",
    "df_final_breslow_1_cindex.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_efron_1_cindex.csv', index=False)  #\n",
    "\n",
    "\n",
    "df_final_breslow_1_ibs = pd.concat([df for df in agg_metrics_ibs]).round(4)\n",
    "df_final_breslow_1_ibs.to_csv('metrics/final_gbdt_efron_1_ibs.csv', index=False)\n",
    "df_final_breslow_1_ibs.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_efron_1_ibs.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA Train, Test, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'estimator__reg_alpha': scloguniform(1e-10,1),#[1e-10,1], # from hyp augmentation, L1 regularization\n",
    "'estimator__reg_lambda': scloguniform(1e-10,1), #[1e-10,1], #alias l2_regularization, lambda in augmentation\n",
    "'estimator__learning_rate': scloguniform(0.001,1), #[0.001,1], # assumed alias eta from augmentation,\n",
    "'estimator__n_estimators':  scrandint(1,4000), # corresponds to num_rounds\n",
    "'estimator__gamma': loguniform(0.001,1.0),#[0.1,1], # minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "'estimator__colsample_bylevel': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation\n",
    "'estimator__colsample_bynode': scuniform(0.1, 1-0.1), #[0.1,1], # from hyp augmentation, uniform(0.1,1),\n",
    "'estimator__colsample_bytree': scuniform(0.5, 1-0.5),#[0.5,1], # from hyp augmentation, seems to exceed the bound, uniform(0.5,1)\n",
    "'estimator__max_depth': scrandint(1,20),#[1,20], # from hyp augmentation\n",
    "'estimator__max_delta_step': scrandint(0,10),#[0,10], # from hyp augmentation\n",
    "'estimator__min_child_weight' : scloguniform(0.1,20-0.1),#[0.1,20], # from hyp augmentation\n",
    "'estimator__subsample': scuniform(0.01,1-0.01),#[0.01,1], # from hyp augmentation\n",
    "#'pca__n_components': [8, 16, 32, 64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index 0.5839311334289814\n",
      "Integrated Brier Score: 0.20449029783416708\n",
      "durations 6.0 3308.0\n",
      "Concordance Index 0.5498426023084995\n",
      "Integrated Brier Score: 0.21370030080381322\n",
      "Concordance Index 0.12550448430493275\n",
      "Integrated Brier Score: 0.2133100706775016\n",
      "durations 1.0 3437.0\n",
      "Concordance Index 0.10789980732177264\n",
      "Integrated Brier Score: 0.2018971424011434\n",
      "Concordance Index 0.5913586673607496\n",
      "Integrated Brier Score: 0.20047267658568269\n",
      "durations 8.0 3675.0\n",
      "Concordance Index 0.5792163543441227\n",
      "Integrated Brier Score: 0.23261824266465217\n",
      "Concordance Index 0.6210485089240754\n",
      "Integrated Brier Score: 0.20583885121964862\n",
      "durations 6.0 3478.0\n",
      "Concordance Index 0.6469465648854962\n",
      "Integrated Brier Score: 0.20902797890493874\n",
      "Concordance Index 0.590408943807002\n",
      "Integrated Brier Score: 0.1987154484787017\n",
      "durations 6.0 2728.0\n",
      "Concordance Index 0.3982011447260834\n",
      "Integrated Brier Score: 0.2294498975809528\n",
      "Concordance Index 0.5992082495291\n",
      "Integrated Brier Score: 0.1948113117771023\n",
      "durations 4.0 3635.0\n",
      "Concordance Index 0.5814663951120163\n",
      "Integrated Brier Score: 0.1959053945709\n",
      "Concordance Index 0.5007094434810027\n",
      "Integrated Brier Score: 0.18982832977435807\n",
      "durations 18.0 4765.0\n",
      "Concordance Index 0.5494388027792624\n",
      "Integrated Brier Score: 0.19938831347750188\n",
      "Concordance Index 0.5925588697017269\n",
      "Integrated Brier Score: 0.19430701457604643\n",
      "durations 11.0 7248.0\n",
      "Concordance Index 0.512087912087912\n",
      "Integrated Brier Score: 0.19553551719533002\n",
      "Concordance Index 0.5483152690002947\n",
      "Integrated Brier Score: 0.18463421037120098\n",
      "durations 28.0 3940.0\n",
      "Concordance Index 0.4615740740740741\n",
      "Integrated Brier Score: 0.21654491585054747\n",
      "Concordance Index 0.4297237604430076\n",
      "Integrated Brier Score: 0.18439952774060017\n",
      "durations 19.0 6732.0\n",
      "Concordance Index 0.4175152749490835\n",
      "Integrated Brier Score: 0.18500383062854145\n",
      "Concordance Index 0.43053559856873186\n",
      "Integrated Brier Score: 0.1963932192815055\n",
      "durations 1.0 3838.0\n",
      "Concordance Index 0.4493373236425823\n",
      "Integrated Brier Score: 0.1989787690226714\n",
      "Concordance Index 0.28527699581841537\n",
      "Integrated Brier Score: 0.19521861862294396\n",
      "durations 4.0 4026.0\n",
      "Concordance Index 0.46093366093366095\n",
      "Integrated Brier Score: 0.19369286582080877\n",
      "Concordance Index 0.5525958601968103\n",
      "Integrated Brier Score: 0.1925635300745\n",
      "durations 12.0 5287.0\n",
      "Concordance Index 0.46024924795874517\n",
      "Integrated Brier Score: 0.2082232656441425\n",
      "Concordance Index 0.48278787215411556\n",
      "Integrated Brier Score: 0.18794835634818485\n",
      "durations 3.0 4765.0\n",
      "Concordance Index 0.4520214320506576\n",
      "Integrated Brier Score: 0.195304679333715\n",
      "Concordance Index 0.2143767164010079\n",
      "Integrated Brier Score: 0.18416852687501373\n",
      "durations 2.0 4694.0\n",
      "Concordance Index 0.20526986825329366\n",
      "Integrated Brier Score: 0.22274546334620318\n",
      "Concordance Index 0.46314892581096706\n",
      "Integrated Brier Score: 0.12518133229296577\n",
      "durations 8.0 4424.0\n",
      "Concordance Index 0.42059672762271416\n",
      "Integrated Brier Score: 0.1361040481326183\n",
      "Concordance Index 0.49892793329362717\n",
      "Integrated Brier Score: 0.14058847987898326\n",
      "durations 9.0 5481.0\n",
      "Concordance Index 0.42528735632183906\n",
      "Integrated Brier Score: 0.1184429692679378\n",
      "Concordance Index 0.37287724405628336\n",
      "Integrated Brier Score: 0.12542096721949583\n",
      "durations 53.0 4624.0\n",
      "Concordance Index 0.24975704567541301\n",
      "Integrated Brier Score: 0.15234541621882905\n",
      "Concordance Index 0.5203786325816954\n",
      "Integrated Brier Score: 0.12407365168072136\n",
      "durations 24.0 3871.0\n",
      "Concordance Index 0.5119284294234593\n",
      "Integrated Brier Score: 0.14636882450594346\n",
      "Concordance Index 0.4878498923408182\n",
      "Integrated Brier Score: 0.12066244504678512\n",
      "durations 11.0 3525.0\n",
      "Concordance Index 0.47752808988764045\n",
      "Integrated Brier Score: 0.16696920864324155\n",
      "Concordance Index 0.5500381647018913\n",
      "Integrated Brier Score: 0.2054527141238668\n",
      "durations 7.0 3540.0\n",
      "Concordance Index 0.62217659137577\n",
      "Integrated Brier Score: 0.2132553794866624\n",
      "Concordance Index 0.289766081871345\n",
      "Integrated Brier Score: 0.2060189217552257\n",
      "durations 14.0 2267.0\n",
      "Concordance Index 0.30457227138643067\n",
      "Integrated Brier Score: 0.2151660488621382\n",
      "Concordance Index 0.2765848013372766\n",
      "Integrated Brier Score: 0.2094701367953498\n",
      "durations 8.0 3720.0\n",
      "Concordance Index 0.1570957095709571\n",
      "Integrated Brier Score: 0.21547506636800412\n",
      "Concordance Index 0.30280492987675306\n",
      "Integrated Brier Score: 0.21841435382217075\n",
      "durations 3.0 2197.0\n",
      "Concordance Index 0.38636363636363635\n",
      "Integrated Brier Score: 0.20994497484322663\n",
      "Concordance Index 0.4297555973337891\n",
      "Integrated Brier Score: 0.20297241084123877\n",
      "durations 8.0 3519.0\n",
      "Concordance Index 0.4562913907284768\n",
      "Integrated Brier Score: 0.23122326027492726\n"
     ]
    }
   ],
   "source": [
    "cancer_types = [\n",
    "    'BLCA',\n",
    "    'BRCA',\n",
    "    'HNSC',\n",
    "    'KIRC',\n",
    "    'LGG',\n",
    "    'LIHC',\n",
    "    'LUAD',\n",
    "    'LUSC',\n",
    "    'OV',\n",
    "    'STAD']\n",
    "agg_metrics_cindex = []\n",
    "agg_metrics_ibs = []\n",
    "\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types):\n",
    "    model = 'xgbsurv_efron_'\n",
    "    # get name of current dataset\n",
    "    data = load_tcga(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", cancer_type=cancer_type, as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "    filename = data.filename\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "\n",
    "    # add IBS later\n",
    "    outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                    'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "    best_params = {'best_params_'+dataset_name:[]}\n",
    "    best_model = {'best_model_'+dataset_name:[]}\n",
    "    ct = make_column_transformer(\n",
    "            (StandardScaler(), make_column_selector(dtype_include=['float32']))\n",
    "            ,remainder='passthrough')\n",
    "    \n",
    "    estimator = XGBSurv(\n",
    "        objective='efron_objective',\n",
    "        eval_metric='efron_loss',\n",
    "        disable_default_eval_metric=True,\n",
    "        early_stopping_rounds=early_stopping_rounds, \n",
    "        base_score=base_score,\n",
    "        random_state=rand_state\n",
    "                        )\n",
    "    \n",
    "    pipe = Pipeline([('scaler',ct),\n",
    "                    #('pca', PCA()),\n",
    "                    ('estimator', estimator)])\n",
    "    \n",
    "    rs = RandomizedSearchCV(pipe, param_grid, scoring = scoring_function, n_jobs=-1, \n",
    "                             cv=inner_custom_cv, n_iter=n_iter, refit=True, random_state=rand_state)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        # Split data into training and testing sets for outer fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "        X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "        #print(y_train.shape, type(y_train))\n",
    "        #print(X_train.shape, type(X_train))\n",
    "        #print(X_test.shape, type(X_test))\n",
    "        #print(y_test.shape, type(y_test))\n",
    "        # save splits and data\n",
    "        np.savetxt('splits/'+model+'train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "        np.savetxt('splits/'+model+'test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "        \n",
    "        #np.savetxt('splits/'+model+'X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "        #np.savetxt('splits/'+model+'y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "        #np.savetxt('splits/'+model+'y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "        rs.fit(X_train, y_train, estimator__eval_test_size=0.2, estimator__verbose=0)\n",
    "        best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "        best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "        np.savetxt('predictions/'+model+'best_preds_train_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "        np.savetxt('predictions/'+model+'best_preds_test_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "\n",
    "        # save hyperparameter settings\n",
    "        params = rs.best_estimator_.get_params\n",
    "        best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "        best_model['best_model_'+dataset_name] += [params]\n",
    "        try:\n",
    "            cum_hazard_train = get_cumulative_hazard_function_efron(\n",
    "                    X_train.values, X_train.values, y_train.values, y_train.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_train.reshape(-1)\n",
    "                    )\n",
    "\n",
    "            df_survival_train = np.exp(-cum_hazard_train)\n",
    "            durations_train, events_train = transform_back(y_train.values)\n",
    "            time_grid_train = np.linspace(durations_train.min(), durations_train.max(), 100)\n",
    "            ev = EvalSurv(df_survival_train, durations_train, events_train, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_train))\n",
    "            cindex_score_train = ev.concordance_td('antolini')\n",
    "            ibs_score_train = ev.integrated_brier_score(time_grid_train)\n",
    "\n",
    "            outer_scores['cindex_train_'+dataset_name] += [cindex_score_train]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [ibs_score_train]\n",
    "\n",
    "        except:\n",
    "            outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_train_'+dataset_name] += [np.nan]\n",
    "            \n",
    "        try:\n",
    "            cum_hazard_test = get_cumulative_hazard_function_efron(\n",
    "                    X_train.values, X_test.values, y_train.values, y_test.values,\n",
    "                    best_preds_train.reshape(-1), best_preds_test.reshape(-1)\n",
    "                    )\n",
    "            df_survival_test = np.exp(-cum_hazard_test)\n",
    "            durations_test, events_test = transform_back(y_test.values)\n",
    "            print('durations',durations_test.min(), durations_test.max())\n",
    "            time_grid_test = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "            ev = EvalSurv(df_survival_test, durations_test, events_test, censor_surv='km')\n",
    "            print('Concordance Index',ev.concordance_td('antolini'))\n",
    "            print('Integrated Brier Score:',ev.integrated_brier_score(time_grid_test))\n",
    "            cindex_score_test = ev.concordance_td('antolini')\n",
    "            ibs_score_test = ev.integrated_brier_score(time_grid_test)\n",
    "\n",
    "            outer_scores['cindex_test_'+dataset_name] += [cindex_score_test]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [ibs_score_test]\n",
    "        except: \n",
    "            outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "            outer_scores['ibs_test_'+dataset_name] += [np.nan]\n",
    "            \n",
    "    df_best_params = pd.DataFrame(best_params)\n",
    "    df_best_model = pd.DataFrame(best_model)\n",
    "    df_outer_scores = pd.DataFrame(outer_scores)\n",
    "    df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "    df_metrics.to_csv('metrics/'+model+'metric_summary_'+filename, index=False)\n",
    "    \n",
    "    # cindex\n",
    "    df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "                                            'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "                                            'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "                                            'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "    # IBS\n",
    "    df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "                                            'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "                                            'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "                                            'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "                                            'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "\n",
    "    agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "    agg_metrics_ibs.append(df_agg_metrics_ibs)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in ['BLCA', 'BRCA', 'HNSC', 'KIRC','LGG']:\n",
    "#     df_outer_scores = pd.read_csv('metrics/xgbsurv_efron_metric_summary_'+name+'_adapted.csv')\n",
    "#     dataset_name = name #+'_adapted'\n",
    "#     # cindex\n",
    "#     df_agg_metrics_cindex = pd.DataFrame({'dataset':[dataset_name],\n",
    "#                                             'cindex_train_mean':df_outer_scores['cindex_train_'+dataset_name].mean(),\n",
    "#                                             'cindex_train_std':df_outer_scores['cindex_train_'+dataset_name].std(),\n",
    "#                                             'cindex_test_mean':df_outer_scores['cindex_test_'+dataset_name].mean(),\n",
    "#                                             'cindex_test_std':df_outer_scores['cindex_test_'+dataset_name].std() })\n",
    "#     # IBS\n",
    "#     df_agg_metrics_ibs = pd.DataFrame({'dataset':[dataset_name],\n",
    "#                                             'ibs_train_mean':df_outer_scores['ibs_train_'+dataset_name].mean(),\n",
    "#                                             'ibs_train_std':df_outer_scores['ibs_train_'+dataset_name].std(),\n",
    "#                                             'ibs_test_mean':df_outer_scores['ibs_test_'+dataset_name].mean(),\n",
    "#                                             'ibs_test_std':df_outer_scores['ibs_test_'+dataset_name].std() })\n",
    "    \n",
    "#     agg_metrics_cindex.append(df_agg_metrics_cindex)\n",
    "#     agg_metrics_ibs.append(df_agg_metrics_ibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cindex_train_mean</th>\n",
       "      <th>cindex_train_std</th>\n",
       "      <th>cindex_test_mean</th>\n",
       "      <th>cindex_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.4749</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIRC</td>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.5715</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGG</td>\n",
       "      <td>0.5906</td>\n",
       "      <td>0.1828</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIHC</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUSC</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OV</td>\n",
       "      <td>0.4686</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAD</td>\n",
       "      <td>0.3698</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.1730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  cindex_train_mean  cindex_train_std  cindex_test_mean  \\\n",
       "0    BLCA             0.5077            0.0944            0.5042   \n",
       "0    BRCA             0.5047            0.0838            0.4832   \n",
       "0    HNSC             0.5115            0.1449            0.4749   \n",
       "0    KIRC             0.5897            0.0827            0.5715   \n",
       "0     LGG             0.5906            0.1828            0.5932   \n",
       "0    LIHC             0.5025            0.2112            0.4564   \n",
       "0    LUAD             0.5341            0.0705            0.5044   \n",
       "0    LUSC             0.3931            0.1400            0.4056   \n",
       "0      OV             0.4686            0.0574            0.4170   \n",
       "0    STAD             0.3698            0.1180            0.3853   \n",
       "\n",
       "   cindex_test_std  \n",
       "0           0.1016  \n",
       "0           0.1567  \n",
       "0           0.1250  \n",
       "0           0.0878  \n",
       "0           0.1658  \n",
       "0           0.2150  \n",
       "0           0.0660  \n",
       "0           0.1121  \n",
       "0           0.1009  \n",
       "0           0.1730  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_efron_1_cindex = pd.concat([df for df in agg_metrics_cindex]).round(4)\n",
    "df_final_efron_1_cindex.sort_values('dataset', ascending=True, inplace=True)\n",
    "df_final_efron_1_cindex.to_csv('metrics/final_gbdt_tcga_efron_1_cindex.csv', index=False)\n",
    "df_final_efron_1_cindex.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_tcga_efron_1_cindex.csv', index=False)  #\n",
    "df_final_efron_1_cindex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ibs_train_mean</th>\n",
       "      <th>ibs_train_std</th>\n",
       "      <th>ibs_test_mean</th>\n",
       "      <th>ibs_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.0072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIRC</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGG</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIHC</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUSC</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OV</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAD</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  ibs_train_mean  ibs_train_std  ibs_test_mean  ibs_test_std\n",
       "0    BLCA          0.2142         0.0043         0.2225        0.0059\n",
       "0    BRCA          0.1905         0.0047         0.1960        0.0092\n",
       "0    HNSC          0.1834         0.0056         0.2039        0.0072\n",
       "0    KIRC          0.2046         0.0037         0.2021        0.0075\n",
       "0     LGG          0.1727         0.0055         0.1931        0.0113\n",
       "0    LIHC          0.2046         0.0057         0.2173        0.0132\n",
       "0    LUAD          0.1896         0.0050         0.1985        0.0114\n",
       "0    LUSC          0.1913         0.0051         0.2038        0.0120\n",
       "0      OV          0.1272         0.0077         0.1440        0.0182\n",
       "0    STAD          0.2085         0.0060         0.2170        0.0082"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_efron_1_ibs = pd.concat([df for df in agg_metrics_ibs]).round(4)\n",
    "df_final_efron_1_ibs.sort_values('dataset', ascending=True, inplace=True)\n",
    "df_final_efron_1_ibs.to_csv('metrics/final_gbdt_tcga_efron_1_ibs.csv', index=False)\n",
    "df_final_efron_1_ibs.to_csv('/Users/JUSC/Documents/644928e0fb7e147893e8ec15/05_thesis/tables/final_gbdt_tcga_efron_1_ibs.csv', index=False) \n",
    "df_final_efron_1_ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cindex_train_STAD': [0.5500381647018913,\n",
       "  0.289766081871345,\n",
       "  0.2765848013372766,\n",
       "  0.30280492987675306,\n",
       "  0.4297555973337891],\n",
       " 'cindex_test_STAD': [0.62217659137577,\n",
       "  0.30457227138643067,\n",
       "  0.1570957095709571,\n",
       "  0.38636363636363635,\n",
       "  0.4562913907284768],\n",
       " 'ibs_train_STAD': [0.2054527141238668,\n",
       "  0.2060189217552257,\n",
       "  0.2094701367953498,\n",
       "  0.21841435382217075,\n",
       "  0.20297241084123877],\n",
       " 'ibs_test_STAD': [0.2132553794866624,\n",
       "  0.2151660488621382,\n",
       "  0.21547506636800412,\n",
       "  0.20994497484322663,\n",
       "  0.23122326027492726]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
