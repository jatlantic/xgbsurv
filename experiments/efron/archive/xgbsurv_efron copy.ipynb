{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBSurv efron Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '»' (U+00BB) (1915269216.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    »\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '»' (U+00BB)\n"
     ]
    }
   ],
   "source": [
    "from xgbsurv.datasets import (load_metabric, load_flchain, load_rgbsg, load_support, load_tcga)\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "from xgbsurv.models.utils import sort_X_y\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.decomposition import PCA\n",
    "# import models\n",
    "from xgbsurv.models.breslow_final import breslow_likelihood,get_cumulative_hazard_function_breslow\n",
    "from xgbsurv.models.efron_final import efron_likelihood\n",
    "from xgbsurv.models.cind_final import cind_loss\n",
    "from xgbsurv.models.deephit_pycox_final import deephit_loss1_pycox\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from xgbsurv.models.utils import sort_X_y_pandas, transform_back, transform\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df\n",
    "import os\n",
    "import sys\n",
    "current_path = os.getcwd() \n",
    "one_level_up = os.path.abspath(os.path.join(current_path,  \"..\"))\n",
    "two_levels_up = os.path.abspath(os.path.join(current_path,  \"..\",\"..\"))\n",
    "sys.path.append(one_level_up+'/gbdt_pipeline')\n",
    "from gbdt_pipeline import get_gbdt_pipeline, train_gbdt, train_gbdt_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m current_path\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_path' is not defined"
     ]
    }
   ],
   "source": [
    "current_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 10\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "validation_size = 0.2\n",
    "\n",
    "\n",
    "# set seed for scipy\n",
    "np.random.seed(rand_state)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (639533006.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def splitefr,nX, y, groups=None):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric,  load_flchain, load_rgbsg, load_support] \n",
    "metrics_list = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    model = 'efron'\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=two_levels_up+\"/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    filename = data.filename\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        print(i)\n",
    "        metric = train_gbdt_complete(dataset_name, X, y, i,  train_index, test_index, model, n_iter)\n",
    "        print(metric)\n",
    "        metrics_list.append(metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(metrics_list)\n",
    "df = df0.applymap(lambda x: x[0] if isinstance(x, list) else x)\n",
    "df.to_csv(current_path+'/metrics/'+model+'_results.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA Train, Test, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLCA_adapted.csv\n",
      "0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Concordance Index 0.5795580110497237\n",
      "Integrated Brier Score: 0.22069817668662348\n",
      "{'model': 'breslow', 'dataset': 'BLCA', 'cindex_train': [0.8630849220103987], 'cindex_test': [0.5795580110497237], 'ibs_train': [0.1442221028427697], 'ibs_score_test': [0.22069817668662348]}\n",
      "1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Concordance Index 0.6040415073730202\n",
      "Integrated Brier Score: 0.22763328758709253\n",
      "{'model': 'breslow', 'dataset': 'BLCA', 'cindex_train': [0.9161194583565201], 'cindex_test': [0.6040415073730202], 'ibs_train': [0.11619468174451228], 'ibs_score_test': [0.22763328758709253]}\n",
      "2\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Concordance Index 0.6027479091995221\n",
      "Integrated Brier Score: 0.24098837996808853\n",
      "{'model': 'breslow', 'dataset': 'BLCA', 'cindex_train': [0.762380538662033], 'cindex_test': [0.6027479091995221], 'ibs_train': [0.18671799337309586], 'ibs_score_test': [0.24098837996808853]}\n",
      "3\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Concordance Index 0.4329896907216495\n",
      "Integrated Brier Score: 0.2164749159451163\n",
      "{'model': 'breslow', 'dataset': 'BLCA', 'cindex_train': [0.6596686295307413], 'cindex_test': [0.4329896907216495], 'ibs_train': [0.20675651971989306], 'ibs_score_test': [0.2164749159451163]}\n",
      "4\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Concordance Index 0.4906270200387847\n",
      "Integrated Brier Score: 0.2147262464217755\n",
      "{'model': 'breslow', 'dataset': 'BLCA', 'cindex_train': [0.5311068836750511], 'cindex_test': [0.4906270200387847], 'ibs_train': [0.21965107998422154], 'ibs_score_test': [0.2147262464217755]}\n",
      "BRCA_adapted.csv\n",
      "0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "cancer_types = [\n",
    "    'BLCA',\n",
    "    'BRCA',\n",
    "    'HNSC',\n",
    "    'KIRC',\n",
    "    'LGG',\n",
    "    'LIHC',\n",
    "    'LUAD',\n",
    "    'LUSC',\n",
    "    'OV',\n",
    "    'STAD'\n",
    "    ]\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for i, cancer_type in enumerate(cancer_types):\n",
    "    model = 'efron'\n",
    "    # get name of current dataset\n",
    "    data = load_tcga(path=two_levels_up+\"/xgbsurv/datasets/data/\",cancer_type=cancer_type, as_frame=True)\n",
    "    filename = data.filename\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        print(i)\n",
    "        metric = train_gbdt_complete(dataset_name, X, y, i,  train_index, test_index, model, n_iter, tcga=True)\n",
    "        print(metric)\n",
    "        metrics_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(metrics_list)\n",
    "df = df0.applymap(lambda x: x[0] if isinstance(x, list) else x)\n",
    "df.to_csv(current_path+'/metrics/'+model+'_tcga_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ibs_train_mean</th>\n",
       "      <th>ibs_train_std</th>\n",
       "      <th>ibs_test_mean</th>\n",
       "      <th>ibs_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  ibs_train_mean  ibs_train_std  ibs_test_mean  ibs_test_std\n",
       "0    BLCA          0.2142         0.0043         0.2228        0.0060\n",
       "0    BRCA          0.1905         0.0046         0.1964        0.0092\n",
       "0    HNSC          0.1833         0.0055         0.2038        0.0074"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
