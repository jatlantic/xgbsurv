{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgbsurv.models.utils import transform\n",
    "from xgbsurv.models.breslow_final import breslow_likelihood, breslow_objective, transform_back\n",
    "from scipy.special import logsumexp\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, hessian\n",
    "import jax.scipy.special as jsp\n",
    "import time as t\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10.782665</td>\n",
       "      <td>6.321241</td>\n",
       "      <td>0.154621</td>\n",
       "      <td>19.208570</td>\n",
       "      <td>17.674405</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>4.839507</td>\n",
       "      <td>9.959547</td>\n",
       "      <td>0.141726</td>\n",
       "      <td>19.185224</td>\n",
       "      <td>12.585120</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_1       x_2       x_3        x_4        x_5      time  event\n",
       "104  10.782665  6.321241  0.154621  19.208570  17.674405  0.000330    1.0\n",
       "638   4.839507  9.959547  0.141726  19.185224  12.585120  0.000471    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hazard = pd.read_csv('/Users/JUSC/Documents/xgbsurv_benchmarking/implementation_testing/simulation_data/survival_simulation_preds_1000.csv').to_numpy()\n",
    "hazard = log_hazard = np.random.normal(0, 1, 1000)\n",
    "df = pd.read_csv('/Users/JUSC/Documents/xgbsurv_benchmarking/implementation_testing/simulation_data/survival_simulation_1000.csv')\n",
    "#df.event = 1\n",
    "df.sort_values(by='time', inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = transform(df.time.to_numpy(), df.event.to_numpy())\n",
    "\n",
    "def breslow_likelihood(log_partial_hazard, time, event):\n",
    "\n",
    "    # Assumes times have been sorted beforehand.\n",
    "    partial_hazard = np.exp(log_partial_hazard)\n",
    "    n_events = np.sum(event)\n",
    "    n_samples = time.shape[0]\n",
    "    #print(n_samples)\n",
    "    previous_time = time[0]\n",
    "    risk_set_sum = 0\n",
    "    likelihood = 0\n",
    "    set_count = 0\n",
    "    accumulated_sum = 0\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        risk_set_sum += partial_hazard[i]\n",
    "\n",
    "    for k in range(n_samples):\n",
    "        current_time = time[k]\n",
    "        if current_time > previous_time:\n",
    "            # correct set-count, have to go back to set the different hazards for the ties\n",
    "            likelihood -= set_count * log(risk_set_sum)\n",
    "            risk_set_sum -= accumulated_sum\n",
    "            set_count = 0\n",
    "            accumulated_sum = 0\n",
    "\n",
    "        if event[k]:\n",
    "            set_count += 1\n",
    "            likelihood += log_partial_hazard[k]\n",
    "\n",
    "        previous_time = current_time\n",
    "        accumulated_sum += partial_hazard[k]\n",
    "    #print(likelihood)\n",
    "    final_likelihood = -likelihood / n_events #n_samples\n",
    "    return final_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function\n",
    "def get_risk_matrix(time):\n",
    "    return (np.outer(time, time) >= jnp.square(time)).astype(int).T\n",
    "\n",
    "def cox_ph_loss(log_partial_hazard, time, event):\n",
    "    # this order seems to be required, albeit not working with check_grad\n",
    "    #print('log_partial_hazard',log_partial_hazard)\n",
    "    #print('y',y)\n",
    "    risk_matrix = get_risk_matrix(time)\n",
    "    hazard_risk = log_partial_hazard*risk_matrix\n",
    "    inp = event*(log_partial_hazard - jsp.logsumexp(hazard_risk, b=risk_matrix, axis=1))\n",
    "    # logsumexp numerically more stable than numpy\n",
    "    loss = np.sum(inp)\n",
    "    #print('loss', loss)\n",
    "    # take negative loss to align with negative gradient\n",
    "    return -loss/jnp.sum(event)\n",
    "\n",
    "time = jnp.array(df.time.to_numpy())\n",
    "event = jnp.array(df.event.to_numpy())\n",
    "#print(cox_ph_loss(hazard,time, event))\n",
    "#grad(cox_ph_loss)(hazard,time, event)\n",
    "#hess = hessian(cox_ph_loss)(hazard,time, event)\n",
    "#np.diag(hess) # this is the correct solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/dh6mkdzs31lc5pkqymtdbh180000gp/T/ipykernel_13345/4044362440.py:50: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_1000.to_latex(index=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "        Function &      Mean &  Standard Deviation &  Sample Size &  Number Repetitions \\\\\n",
      "\\midrule\n",
      "     Breslow\\_Jax & 22.208190 &            1.330617 &         1000 &                  50 \\\\\n",
      "Breslow\\_Explicit &  0.292885 &            0.005615 &         1000 &                  50 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m df_1000 \u001b[39m=\u001b[39m comparison(num_runs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39mprint\u001b[39m(df_1000\u001b[39m.\u001b[39mto_latex(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m---> 51\u001b[0m dff\u001b[39m.\u001b[39mto_csv(path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/results/breslow_jax_comparison.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m df_1000\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dff' is not defined"
     ]
    }
   ],
   "source": [
    "def function1(hazard,time, event):\n",
    "    gradient = grad(cox_ph_loss)(hazard,time, event)\n",
    "    hess = hessian(cox_ph_loss)(hazard,time, event)\n",
    "    return gradient, np.diag(hess)\n",
    "    \n",
    "\n",
    "def function2(hazard,time, event):\n",
    "    return breslow_likelihood(hazard,time, event)\n",
    "\n",
    "path = '/Users/JUSC/Documents/xgbsurv_benchmarking/implementation_testing/simulation_data'\n",
    "def comparison(num_runs = 10, size=1000):\n",
    "    hazard = log_hazard = np.random.normal(0, 1, size)\n",
    "    df = pd.read_csv(path+'/survival_simulation_'+str(size)+'.csv')\n",
    "    df.sort_values(by='time', inplace=True)\n",
    "    time = jnp.array(df.time.to_numpy())\n",
    "    event = jnp.array(df.event.to_numpy())\n",
    "    # Empty list to store the execution times\n",
    "    function1_times = []\n",
    "    function2_times = []\n",
    "\n",
    "    # Loop to run each function and record the execution times\n",
    "    for i in range(num_runs):\n",
    "        start_time = t.time()\n",
    "        function1(hazard,time, event)\n",
    "        end_time = t.time()\n",
    "        function1_times.append(end_time - start_time)\n",
    "\n",
    "        start_time = t.time()\n",
    "        function2(hazard,time, event)\n",
    "        end_time = t.time()\n",
    "        function2_times.append(end_time - start_time)\n",
    "\n",
    "    # Calculate the mean and standard deviation of the execution times for each function\n",
    "    function1_mean = sum(function1_times) / len(function1_times)\n",
    "    function1_std = pd.Series(function1_times).std()\n",
    "    function2_mean = sum(function2_times) / len(function2_times)\n",
    "    function2_std = pd.Series(function2_times).std()\n",
    "\n",
    "    # Create a Pandas dataframe to display the results\n",
    "    df = pd.DataFrame({\n",
    "        'Function': ['Breslow_Jax', 'Breslow_Explicit'],\n",
    "        'Mean': [function1_mean, function2_mean],\n",
    "        'Standard Deviation': [function1_std, function2_std],\n",
    "        'Sample Size': [size, size],\n",
    "        'Number Repetitions': [num_runs, num_runs]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df_1000 = comparison(num_runs = 50, size=1000)\n",
    "print(df_1000.to_latex(index=False))\n",
    "df_1000.to_csv(path+'/results/breslow_jax_comparison.csv', index=False)\n",
    "df_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_10000 = comparison(num_runs = 50, size=10000)\n",
    "df_10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.concat([df_1000,df_10000])\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_1000.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(path+'/results/breslow_jax_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
