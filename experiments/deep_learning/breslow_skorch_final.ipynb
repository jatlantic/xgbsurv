{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBsurv benchmark\n",
    "from xgbsurv.datasets import load_metabric, load_flchain, load_rgbsg, load_support\n",
    "#from xgbsurv.datasets import (load_flchain, load_rgbsg, load_support,\n",
    "#load_tcga)\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "from xgbsurv.models.utils import sort_X_y\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,LabelBinarizer\n",
    "# import models\n",
    "from xgbsurv.models.breslow_final import breslow_likelihood, breslow_estimator\n",
    "from pycox.evaluation import EvalSurv\n",
    "from xgbsurv.models.utils import transform_back, transform\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df\n",
    "import sys\n",
    "#sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import BreslowLoss, breslow_likelihood_torch\n",
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.dataset import CVSplit, ValidSplit\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "deep learning hyperparameter spaces follow pycox paper\n",
    "Time-to-Event Prediction with Neural Networks and Cox Regression\n",
    "page 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 10 # set to 50\n",
    "#n_iter_cind = 200\n",
    "early_stopping_rounds=15\n",
    "base_score = 0.0\n",
    "\n",
    "param_grid_breslow = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    'estimator__lr': scloguniform(0.001,0.01), # scheduler unten einbauen\n",
    "    #'max_epochs':  scrandint(10,20), # corresponds to num_rounds\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, n_layers, in_features, num_nodes, dropout, out_features):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.in_features = in_features\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dropout = dropout\n",
    "        self.out_features = out_features\n",
    "        model = []\n",
    "        # first layer\n",
    "        model.append(torch.nn.Linear(in_features, num_nodes))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout))\n",
    "        model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            model.append(torch.nn.Linear(num_nodes, num_nodes))\n",
    "            #init.kaiming_normal_(model[-1].weight, nonlinearity='relu')\n",
    "            model.append(torch.nn.ReLU())\n",
    "            model.append(torch.nn.Dropout(dropout))\n",
    "            model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        # output layer\n",
    "        model.append(torch.nn.Linear(num_nodes, out_features))\n",
    "    \n",
    "        self.layers = nn.Sequential(*model)\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     if isinstance(layer, nn.Linear):\n",
    "        #         #nn.init.uniform_(layer.weight, a=-0.5, b=0.5)\n",
    "        #         nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.layers(x)\n",
    "        #print(res)\n",
    "        return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stratified inner k-fold cross-validation\n",
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Scorer\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "\n",
    "        #y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, np.ndarray):\n",
    "            y_pred = torch.from_numpy(y_pred)\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, pd.Series):\n",
    "            y_pred = torch.tensor(y_pred.values)\n",
    "        if isinstance(y_true, pd.Series):\n",
    "            y_true = torch.tensor(y_true.values)\n",
    "        score = breslow_likelihood_torch(y_true, y_pred) \n",
    "        return score.numpy()\n",
    "\n",
    "scoring_function = make_scorer(custom_scoring_function, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7871, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = load_flchain(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X.dtypes\n",
    "class BoolToNumericTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[X_copy == True] = 1\n",
    "        X_copy[X_copy == False] = 0\n",
    "        return X_copy.astype(float)\n",
    "    \n",
    "ct = make_column_transformer(\n",
    "(StandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "(BoolToNumericTransformer(), make_column_selector(dtype_include=['bool'])),remainder='passthrough'\n",
    ")\n",
    "X = ct.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.22474487  1.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_selector\n",
    "import pandas as pd\n",
    "\n",
    "# Define a custom transformer to convert True and False values to 1 and 0, respectively\n",
    "class BoolToNumericTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[X_copy == True] = 1\n",
    "        X_copy[X_copy == False] = 0\n",
    "        return X_copy.astype(float)\n",
    "\n",
    "# Let's say you have a pandas DataFrame with columns of different types:\n",
    "df = pd.DataFrame({\n",
    "    'numeric_feature': [1.0, 2.0, 3.0],\n",
    "    'bool_feature': [True, False, True]\n",
    "})\n",
    "\n",
    "# Define the column transformer using make_column_selector and the custom transformer\n",
    "column_transformer = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=['float64'])),\n",
    "    (BoolToNumericTransformer(), make_column_selector(dtype_include=['bool']))\n",
    ")\n",
    "\n",
    "# Apply the transformation to the DataFrame\n",
    "transformed_df = column_transformer.fit_transform(df)\n",
    "\n",
    "print(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchStandardScaler(StandardScaler):\n",
    "    def transform(self, X, copy=None):\n",
    "        X_scaled = super().transform(X, copy=copy)\n",
    "        return torch.from_numpy(X_scaled)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_transformed = super().fit_transform(X, y=y)\n",
    "        return torch.from_numpy(X_transformed)\n",
    "    \n",
    "ct = make_column_transformer(\n",
    "       (StandardScaler(),\n",
    "        make_column_selector(dtype_include=float)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7871, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoolToNumericTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[X_copy == True] = 1\n",
    "        X_copy[X_copy == False] = 0\n",
    "        return X_copy.astype(np.float32)\n",
    "\n",
    "# adapt this for bool case\n",
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        \n",
    "        #to_add = X[X.columns[X.columns.isin(['sex','D'])]]\n",
    "        #X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        #df.columns.get_loc('age')\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        #to_add = to_add.values.reshape(-1, 1)\n",
    "\n",
    "        # Horizontally stack the two arrays\n",
    "        #result = np.hstack((X_transformed, to_add))\n",
    "        \n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "\n",
    "class CustomStandardScaler2(StandardScaler):\n",
    "    \"\"\"Just to change the datatype of bool variables.\"\"\"\n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        \n",
    "        to_return = X\n",
    "        #X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        #df.columns.get_loc('age')\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        #to_add = to_add.values.reshape(-1, 1)\n",
    "\n",
    "        # Horizontally stack the two arrays\n",
    "        #result = np.hstack((X_transformed, to_add))\n",
    "        \n",
    "        # Add your own code here\n",
    "        return to_return.astype(np.float32)\n",
    "    \n",
    "class CustomLabelBinarizer(LabelBinarizer):\n",
    "    def __init__(self, neg_label=0, pos_label=1, sparse_output=False):\n",
    "        super().__init__(neg_label=0, pos_label=1, sparse_output=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Add custom fit logic here\n",
    "        # Call the parent class's fit method\n",
    "        print('fit',X)\n",
    "        super().fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Add custom transform logic here\n",
    "\n",
    "        # Call the parent class's transform method\n",
    "        print('transform',X)\n",
    "        transformed_X = super().transform(X)\n",
    "\n",
    "        return transformed_X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add custom transform logic here\n",
    "\n",
    "        # Call the parent class's transform method\n",
    "        print(y)\n",
    "        print('fit_transform',X.values)\n",
    "        to_add = X[X.columns[X.columns.isin(['sex','D'])]]\n",
    "        X = X[X.columns[~X.columns.isin(['sex','D'])]]\n",
    "        transformed_X = super().fit_transform(X.values)\n",
    "    \n",
    "        return transformed_X.astype(np.float32)\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        # Add custom inverse_transform logic here\n",
    "\n",
    "        # Call the parent class's inverse_transform method\n",
    "        inverse_X = super().inverse_transform(X)\n",
    "\n",
    "        return inverse_X.astype(np.float32)\n",
    "    \n",
    "# ct = make_column_transformer(\n",
    "#         (CustomStandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "#         #(CustomLabelBinarizer(), make_column_selector(dtype_include=['bool'])), remainder='passthrough')\n",
    "\n",
    "ct = CustomStandardScaler()\n",
    "data = load_flchain(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X = ct.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 1 # # set to 50\n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "\n",
    "        dataset_name = filename.split('_')[0]\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        # ct = make_column_transformer(\n",
    "        #  (StandardScaler(),\n",
    "        #  make_column_selector(dtype_include=float,dtype_exclude=bool)),)\n",
    "        # (LabelBinarizer(),\n",
    "        # make_column_selector(dtype_include=bool, dtype_exclude=float)))\n",
    "        ct = make_column_transformer(\n",
    "        (CustomStandardScaler(), make_column_selector(dtype_include=['float32'])),\n",
    "        (CustomStandardScaler2(), make_column_selector(dtype_include=['category'])), remainder='passthrough')\n",
    "        #columns_to_transform = [col for col in X.columns if col != 'sex']\n",
    "        #ct = make_column_transformer(\n",
    "        #(StandardScaler(), columns_to_transform), \n",
    "        #(LabelBinarizer(), make_column_selector(dtype_include='bool')),\n",
    "        #remainder='passthrough'\n",
    "        #)\n",
    "        pipe = Pipeline(\n",
    "        [('scaler', ct),\n",
    "        ('estimator', net)]\n",
    "        )\n",
    "        # pipe = Pipeline([\n",
    "        # ('scale', StandardScaler()),\n",
    "        # ('estimator', net),\n",
    "        # ])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_breslow, scoring = scoring_function, n_jobs=-1, \n",
    "                            cv=inner_custom_cv, n_iter=n_iter, refit=True)\n",
    "        \n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                print(X_train.shape, type(X_train))\n",
    "                print(y_train.shape, type(y_train))\n",
    "                print(X_test.shape, type(X_test))\n",
    "                print(y_test.shape, type(y_test))\n",
    "                # save splits and data\n",
    "                savetxt('splits/train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                savetxt('splits/X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                savetxt('splits/X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                savetxt('splits/y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                savetxt('splits/y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "                \n",
    "                #savetxt('splits/test_index_'+str(i)+'.csv', test_index, delimiter=',')\n",
    "                \n",
    "                # create validation dataset for early stopping\n",
    "                strat = np.sign(y_train)\n",
    "                valid_split = ValidSplit(cv=0.1, stratified=strat, random_state=42)\n",
    "\n",
    "                # train\n",
    "                rs.fit(X_train, y_train)\n",
    "                \n",
    "                # predict\n",
    "                #scaler = StandardScaler()\n",
    "                #X_train = scaler.fit_transform(X_train)\n",
    "                #X_test = scaler.transform(X_test)\n",
    "                print(rs.best_estimator_.predict(X_train))\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "\n",
    "                #print(best_preds_test, type(best_preds_train))\n",
    "                #print(best_preds_test, type(best_preds_test))\n",
    "                # predict survival function\n",
    "                # d = predict_survival_function(X_test, dataframe=True)\n",
    "\n",
    "                # save predictions, get dataset name\n",
    "                savetxt('predictions/train_preds_'+str(i)+'_'+filename, best_preds_train, delimiter=',')\n",
    "                savetxt('predictions/test_preds_'+str(i)+'_'+filename, best_preds_test, delimiter=',')\n",
    "                \n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "                #print(rs.best_params_)\n",
    "                # save c-index values\n",
    "                try:\n",
    "                        score_train = cindex_censored(y_train, best_preds_train.reshape(-1))\n",
    "                        score_test = cindex_censored(y_test, best_preds_test.reshape(-1))\n",
    "                        outer_scores['cindex_train_'+dataset_name] += [score_train]\n",
    "                        outer_scores['cindex_test_'+dataset_name] += [score_test]\n",
    "                except:\n",
    "                        outer_scores['cindex_train_'+dataset_name] += [np.nan]\n",
    "                        outer_scores['cindex_test_'+dataset_name] += [np.nan]\n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_metrics = pd.concat([df_best_params,df_best_model,df_outer_scores], axis=1)\n",
    "        df_metrics.to_csv('metrics/metric_summary_'+str(i)+'_'+filename, index=False)\n",
    "        return best_model, best_params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  float32\n",
       "sex                 category\n",
       "race                 float32\n",
       "n_comorbidities      float32\n",
       "diabetes            category\n",
       "dementia            category\n",
       "cancer              category\n",
       "blood_pressure       float32\n",
       "heart_rate           float32\n",
       "respiration_rate     float32\n",
       "temperature          float32\n",
       "white_blood_cell     float32\n",
       "serum_sodium         float32\n",
       "serum_creatinine     float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_support(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: SUPPORT_adapted.csv\n",
      "age                  float32\n",
      "sex                 category\n",
      "race                 float32\n",
      "n_comorbidities      float32\n",
      "diabetes            category\n",
      "dementia            category\n",
      "cancer              category\n",
      "blood_pressure       float32\n",
      "heart_rate           float32\n",
      "respiration_rate     float32\n",
      "temperature          float32\n",
      "white_blood_cell     float32\n",
      "serum_sodium         float32\n",
      "serum_creatinine     float32\n",
      "dtype: object\n",
      "float32\n",
      "(7098, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(7098,) <class 'pandas.core.series.Series'>\n",
      "(1775, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(1775,) <class 'pandas.core.series.Series'>\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0003\u001b[0m        \u001b[32m3.9078\u001b[0m  0.3023\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.9697\u001b[0m        \u001b[32m3.9037\u001b[0m  0.3030\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.9772\u001b[0m        \u001b[32m3.9202\u001b[0m  0.3051\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0146\u001b[0m        \u001b[32m3.9081\u001b[0m  0.3066\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0078\u001b[0m        \u001b[32m3.8996\u001b[0m  0.3269\n",
      "      2        \u001b[36m3.9227\u001b[0m        \u001b[32m3.9003\u001b[0m  0.2887\n",
      "      2        \u001b[36m3.9287\u001b[0m        \u001b[32m3.8972\u001b[0m  0.2894\n",
      "      2        \u001b[36m3.9237\u001b[0m        \u001b[32m3.9129\u001b[0m  0.2888\n",
      "      2        \u001b[36m3.9481\u001b[0m        \u001b[32m3.9036\u001b[0m  0.2973\n",
      "      2        \u001b[36m3.9254\u001b[0m        \u001b[32m3.8887\u001b[0m  0.3129\n",
      "      3        \u001b[36m3.9125\u001b[0m        \u001b[32m3.8946\u001b[0m  0.2850\n",
      "      3        \u001b[36m3.9025\u001b[0m        \u001b[32m3.8954\u001b[0m  0.2864\n",
      "      3        \u001b[36m3.9089\u001b[0m        \u001b[32m3.9104\u001b[0m  0.2841\n",
      "      3        \u001b[36m3.9195\u001b[0m        \u001b[32m3.8999\u001b[0m  0.2934\n",
      "      3        \u001b[36m3.9064\u001b[0m        \u001b[32m3.8795\u001b[0m  0.3138\n",
      "      4        \u001b[36m3.9053\u001b[0m        \u001b[32m3.9069\u001b[0m  0.2901\n",
      "      4        \u001b[36m3.8850\u001b[0m        \u001b[32m3.8925\u001b[0m  0.2914\n",
      "      4        \u001b[36m3.9014\u001b[0m        \u001b[32m3.8936\u001b[0m  0.2953\n",
      "      4        \u001b[36m3.9024\u001b[0m        \u001b[32m3.8978\u001b[0m  0.2990\n",
      "      4        \u001b[36m3.8965\u001b[0m        \u001b[32m3.8756\u001b[0m  0.3102\n",
      "      5        \u001b[36m3.8923\u001b[0m        \u001b[32m3.9038\u001b[0m  0.2868\n",
      "      5        \u001b[36m3.8817\u001b[0m        \u001b[32m3.8895\u001b[0m  0.2877\n",
      "      5        \u001b[36m3.8869\u001b[0m        \u001b[32m3.8910\u001b[0m  0.2849\n",
      "      5        \u001b[36m3.9005\u001b[0m        \u001b[32m3.8958\u001b[0m  0.2907\n",
      "      5        \u001b[36m3.8875\u001b[0m        \u001b[32m3.8742\u001b[0m  0.3091\n",
      "      6        \u001b[36m3.8734\u001b[0m        3.8899  0.2848\n",
      "      6        \u001b[36m3.8828\u001b[0m        \u001b[32m3.8898\u001b[0m  0.2856\n",
      "      6        \u001b[36m3.8861\u001b[0m        \u001b[32m3.9024\u001b[0m  0.2904\n",
      "      6        \u001b[36m3.8913\u001b[0m        \u001b[32m3.8942\u001b[0m  0.2937\n",
      "      6        \u001b[36m3.8808\u001b[0m        \u001b[32m3.8734\u001b[0m  0.3115\n",
      "      7        \u001b[36m3.8798\u001b[0m        \u001b[32m3.8877\u001b[0m  0.2835\n",
      "      7        \u001b[36m3.8692\u001b[0m        \u001b[32m3.8892\u001b[0m  0.2866\n",
      "      7        \u001b[36m3.8797\u001b[0m        \u001b[32m3.9017\u001b[0m  0.2855\n",
      "      7        3.8974        3.8953  0.2926\n",
      "      7        \u001b[36m3.8759\u001b[0m        \u001b[32m3.8691\u001b[0m  0.3093\n",
      "      8        \u001b[36m3.8756\u001b[0m        \u001b[32m3.8864\u001b[0m  0.2865\n",
      "      8        \u001b[36m3.8772\u001b[0m        \u001b[32m3.9009\u001b[0m  0.2836\n",
      "      8        \u001b[36m3.8656\u001b[0m        \u001b[32m3.8884\u001b[0m  0.2876\n",
      "      8        \u001b[36m3.8867\u001b[0m        3.8952  0.2930\n",
      "      8        \u001b[36m3.8733\u001b[0m        3.8695  0.3057\n",
      "      9        \u001b[36m3.8737\u001b[0m        3.8870  0.2848\n",
      "      9        \u001b[36m3.8631\u001b[0m        3.8895  0.2847\n",
      "      9        \u001b[36m3.8753\u001b[0m        \u001b[32m3.8998\u001b[0m  0.2860\n",
      "      9        \u001b[36m3.8861\u001b[0m        \u001b[32m3.8929\u001b[0m  0.2900\n",
      "      9        \u001b[36m3.8682\u001b[0m        \u001b[32m3.8675\u001b[0m  0.3083\n",
      "     10        3.8758        \u001b[32m3.8845\u001b[0m  0.2838\n",
      "     10        3.8641        3.8904  0.2871\n",
      "     10        \u001b[36m3.8744\u001b[0m        \u001b[32m3.8991\u001b[0m  0.2884\n",
      "     10        \u001b[36m3.8845\u001b[0m        \u001b[32m3.8924\u001b[0m  0.2927\n",
      "     10        3.8703        3.8678  0.3120\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.9905\u001b[0m        \u001b[32m3.8885\u001b[0m  0.3798\n",
      "      2        \u001b[36m3.9480\u001b[0m        \u001b[32m3.8811\u001b[0m  0.3737\n",
      "      3        \u001b[36m3.9241\u001b[0m        \u001b[32m3.8757\u001b[0m  0.3699\n",
      "      4        \u001b[36m3.9103\u001b[0m        \u001b[32m3.8731\u001b[0m  0.3835\n",
      "      5        \u001b[36m3.9053\u001b[0m        \u001b[32m3.8710\u001b[0m  0.3749\n",
      "      6        \u001b[36m3.8983\u001b[0m        \u001b[32m3.8705\u001b[0m  0.3730\n",
      "      7        \u001b[36m3.8929\u001b[0m        \u001b[32m3.8689\u001b[0m  0.3729\n",
      "      8        3.8969        \u001b[32m3.8679\u001b[0m  0.3627\n",
      "      9        \u001b[36m3.8910\u001b[0m        \u001b[32m3.8664\u001b[0m  0.3646\n",
      "     10        \u001b[36m3.8860\u001b[0m        \u001b[32m3.8651\u001b[0m  0.3655\n",
      "[[0.5734406 ]\n",
      " [1.7810507 ]\n",
      " [1.9172676 ]\n",
      " ...\n",
      " [0.99088365]\n",
      " [1.0103163 ]\n",
      " [0.80924433]]\n",
      "(7098, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(7098,) <class 'pandas.core.series.Series'>\n",
      "(1775, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(1775,) <class 'pandas.core.series.Series'>\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m6.0492\u001b[0m        \u001b[32m5.7090\u001b[0m  0.3473\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m6.0415\u001b[0m        \u001b[32m5.7134\u001b[0m  0.3531\n",
      "      2        \u001b[36m5.9959\u001b[0m        \u001b[32m5.7073\u001b[0m  0.3390\n",
      "      2        \u001b[36m5.9828\u001b[0m        \u001b[32m5.7085\u001b[0m  0.3441\n",
      "      3        \u001b[36m5.9585\u001b[0m        \u001b[32m5.7038\u001b[0m  0.3361\n",
      "      3        \u001b[36m5.9498\u001b[0m        5.7113  0.3409\n",
      "      4        \u001b[36m5.9423\u001b[0m        \u001b[32m5.6992\u001b[0m  0.3323\n",
      "      4        \u001b[36m5.9408\u001b[0m        \u001b[32m5.7068\u001b[0m  0.3423\n",
      "      5        \u001b[36m5.9413\u001b[0m        5.6997  0.3388\n",
      "      5        \u001b[36m5.9335\u001b[0m        \u001b[32m5.7006\u001b[0m  0.3464\n",
      "      6        \u001b[36m5.9319\u001b[0m        5.7022  0.3322\n",
      "      6        \u001b[36m5.9320\u001b[0m        5.7020  0.3382\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m6.0754\u001b[0m        \u001b[32m5.7195\u001b[0m  0.3500\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m6.0388\u001b[0m        \u001b[32m5.7318\u001b[0m  0.3503\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m6.0825\u001b[0m        \u001b[32m5.7622\u001b[0m  0.3516\n",
      "      7        \u001b[36m5.9248\u001b[0m        5.7017  0.3320\n",
      "      7        \u001b[36m5.9216\u001b[0m        \u001b[32m5.7001\u001b[0m  0.3404\n",
      "      2        \u001b[36m6.0024\u001b[0m        5.7197  0.3338\n",
      "      2        \u001b[36m5.9849\u001b[0m        5.7327  0.3354\n",
      "      2        \u001b[36m6.0076\u001b[0m        \u001b[32m5.7569\u001b[0m  0.3374\n",
      "      8        \u001b[36m5.9237\u001b[0m        5.7001  0.3321\n",
      "      8        \u001b[36m5.9207\u001b[0m        \u001b[32m5.6991\u001b[0m  0.3384\n",
      "      3        \u001b[36m5.9554\u001b[0m        \u001b[32m5.7167\u001b[0m  0.3356\n",
      "      3        \u001b[36m5.9351\u001b[0m        \u001b[32m5.7305\u001b[0m  0.3340\n",
      "      3        \u001b[36m5.9579\u001b[0m        \u001b[32m5.7555\u001b[0m  0.3352\n",
      "      9        5.9237        \u001b[32m5.6984\u001b[0m  0.3277\n",
      "      9        \u001b[36m5.9188\u001b[0m        5.7016  0.3349\n",
      "      4        \u001b[36m5.9349\u001b[0m        \u001b[32m5.7283\u001b[0m  0.3345\n",
      "      4        \u001b[36m5.9461\u001b[0m        \u001b[32m5.7165\u001b[0m  0.3379\n",
      "      4        \u001b[36m5.9363\u001b[0m        \u001b[32m5.7537\u001b[0m  0.3377\n",
      "     10        \u001b[36m5.9226\u001b[0m        \u001b[32m5.6976\u001b[0m  0.3346\n",
      "     10        \u001b[36m5.9172\u001b[0m        \u001b[32m5.6975\u001b[0m  0.3439\n",
      "      5        \u001b[36m5.9259\u001b[0m        5.7310  0.3306\n",
      "      5        \u001b[36m5.9266\u001b[0m        \u001b[32m5.7468\u001b[0m  0.3296\n",
      "      5        \u001b[36m5.9388\u001b[0m        \u001b[32m5.7165\u001b[0m  0.3373\n",
      "      6        \u001b[36m5.9193\u001b[0m        5.7329  0.3254\n",
      "      6        \u001b[36m5.9206\u001b[0m        \u001b[32m5.7416\u001b[0m  0.3268\n",
      "      6        \u001b[36m5.9386\u001b[0m        \u001b[32m5.7127\u001b[0m  0.3265\n",
      "      7        \u001b[36m5.9149\u001b[0m        5.7327  0.3298\n",
      "      7        \u001b[36m5.9181\u001b[0m        5.7420  0.3292\n",
      "      7        \u001b[36m5.9318\u001b[0m        \u001b[32m5.7113\u001b[0m  0.3307\n",
      "      8        \u001b[36m5.9103\u001b[0m        5.7329  0.3324\n",
      "      8        \u001b[36m5.9305\u001b[0m        5.7122  0.3328\n",
      "      8        \u001b[36m5.9139\u001b[0m        5.7445  0.3377\n",
      "      9        \u001b[36m5.9089\u001b[0m        5.7322  0.3323\n",
      "      9        \u001b[36m5.9263\u001b[0m        \u001b[32m5.7111\u001b[0m  0.3348\n",
      "      9        \u001b[36m5.9037\u001b[0m        5.7465  0.3342\n",
      "     10        \u001b[36m5.9064\u001b[0m        5.7328  0.3342\n",
      "     10        5.9064        5.7432  0.3318\n",
      "     10        5.9288        \u001b[32m5.7086\u001b[0m  0.3342\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m6.0647\u001b[0m        \u001b[32m5.6946\u001b[0m  0.4002\n",
      "      2        \u001b[36m6.0059\u001b[0m        5.6947  0.3837\n",
      "      3        \u001b[36m5.9689\u001b[0m        \u001b[32m5.6918\u001b[0m  0.3867\n",
      "      4        \u001b[36m5.9491\u001b[0m        \u001b[32m5.6876\u001b[0m  0.3831\n",
      "      5        \u001b[36m5.9483\u001b[0m        \u001b[32m5.6841\u001b[0m  0.3774\n",
      "      6        \u001b[36m5.9398\u001b[0m        5.6849  0.3692\n",
      "      7        \u001b[36m5.9396\u001b[0m        \u001b[32m5.6837\u001b[0m  0.3810\n",
      "      8        \u001b[36m5.9311\u001b[0m        \u001b[32m5.6820\u001b[0m  0.3776\n",
      "      9        5.9328        \u001b[32m5.6794\u001b[0m  0.3731\n",
      "     10        \u001b[36m5.9295\u001b[0m        \u001b[32m5.6790\u001b[0m  0.3744\n",
      "[[-0.04621872]\n",
      " [ 0.9369985 ]\n",
      " [ 1.0946279 ]\n",
      " ...\n",
      " [ 0.6252822 ]\n",
      " [ 0.67942625]\n",
      " [ 0.658503  ]]\n",
      "(7098, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(7098,) <class 'pandas.core.series.Series'>\n",
      "(1775, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(1775,) <class 'pandas.core.series.Series'>\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1347\u001b[0m        \u001b[32m3.8926\u001b[0m  0.6258\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1498\u001b[0m        \u001b[32m3.9220\u001b[0m  0.6351\n",
      "      2        \u001b[36m3.8994\u001b[0m        \u001b[32m3.8710\u001b[0m  0.6259\n",
      "      2        \u001b[36m3.9047\u001b[0m        \u001b[32m3.9167\u001b[0m  0.6391\n",
      "      3        \u001b[36m3.8787\u001b[0m        3.8825  0.6316\n",
      "      3        \u001b[36m3.8873\u001b[0m        3.9239  0.6408\n",
      "      4        \u001b[36m3.8737\u001b[0m        \u001b[32m3.8670\u001b[0m  0.6345\n",
      "      4        \u001b[36m3.8818\u001b[0m        3.9204  0.6422\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.4066\u001b[0m        \u001b[32m3.8970\u001b[0m  0.6508\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1720\u001b[0m        \u001b[32m3.9285\u001b[0m  0.6522\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1066\u001b[0m        \u001b[32m3.9139\u001b[0m  0.6568\n",
      "      5        \u001b[36m3.8545\u001b[0m        \u001b[32m3.8637\u001b[0m  0.6347\n",
      "      5        \u001b[36m3.8591\u001b[0m        3.9225  0.6472\n",
      "      2        \u001b[36m3.9158\u001b[0m        \u001b[32m3.8814\u001b[0m  0.6385\n",
      "      2        \u001b[36m3.9341\u001b[0m        \u001b[32m3.9128\u001b[0m  0.6385\n",
      "      2        \u001b[36m3.8953\u001b[0m        \u001b[32m3.8969\u001b[0m  0.6451\n",
      "      6        \u001b[36m3.8441\u001b[0m        3.8749  0.6315\n",
      "      6        \u001b[36m3.8433\u001b[0m        3.9229  0.6406\n",
      "      3        \u001b[36m3.8997\u001b[0m        3.9373  0.6374\n",
      "      3        \u001b[36m3.8940\u001b[0m        \u001b[32m3.8763\u001b[0m  0.6386\n",
      "      3        \u001b[36m3.8689\u001b[0m        \u001b[32m3.8878\u001b[0m  0.6454\n",
      "      7        \u001b[36m3.8371\u001b[0m        3.8718  0.6347\n",
      "      7        \u001b[36m3.8384\u001b[0m        3.9243  0.6397\n",
      "      4        \u001b[36m3.8834\u001b[0m        \u001b[32m3.8758\u001b[0m  0.6389\n",
      "      4        \u001b[36m3.8990\u001b[0m        3.9205  0.6397\n",
      "      4        \u001b[36m3.8598\u001b[0m        3.9012  0.6466\n",
      "      8        \u001b[36m3.8130\u001b[0m        3.8799  0.6349\n",
      "      8        \u001b[36m3.8244\u001b[0m        \u001b[32m3.8891\u001b[0m  0.6379\n",
      "      5        \u001b[36m3.8663\u001b[0m        \u001b[32m3.8724\u001b[0m  0.6135\n",
      "      5        \u001b[36m3.8825\u001b[0m        \u001b[32m3.9112\u001b[0m  0.6310\n",
      "      5        \u001b[36m3.8435\u001b[0m        \u001b[32m3.8844\u001b[0m  0.6393\n",
      "      9        \u001b[36m3.7901\u001b[0m        \u001b[32m3.8583\u001b[0m  0.6225\n",
      "      9        \u001b[36m3.8043\u001b[0m        3.9050  0.6300\n",
      "      6        \u001b[36m3.8656\u001b[0m        3.8917  0.6195\n",
      "      6        \u001b[36m3.8763\u001b[0m        3.9313  0.6292\n",
      "      6        \u001b[36m3.8415\u001b[0m        3.8890  0.6333\n",
      "     10        \u001b[36m3.7631\u001b[0m        3.8713  0.6291\n",
      "     10        \u001b[36m3.7930\u001b[0m        \u001b[32m3.8657\u001b[0m  0.6327\n",
      "      7        \u001b[36m3.8515\u001b[0m        \u001b[32m3.8680\u001b[0m  0.6184\n",
      "      7        \u001b[36m3.8622\u001b[0m        3.9308  0.6263\n",
      "      7        \u001b[36m3.8195\u001b[0m        3.8860  0.6276\n",
      "      8        \u001b[36m3.8299\u001b[0m        \u001b[32m3.8538\u001b[0m  0.6087\n",
      "      8        \u001b[36m3.8443\u001b[0m        3.9210  0.6129\n",
      "      8        \u001b[36m3.7874\u001b[0m        \u001b[32m3.8724\u001b[0m  0.6192\n",
      "      9        \u001b[36m3.8118\u001b[0m        3.8592  0.6057\n",
      "      9        \u001b[36m3.8340\u001b[0m        3.9140  0.6151\n",
      "      9        3.7908        3.9016  0.6178\n",
      "     10        \u001b[36m3.8014\u001b[0m        \u001b[32m3.8266\u001b[0m  0.6046\n",
      "     10        \u001b[36m3.8237\u001b[0m        3.9170  0.6123\n",
      "     10        \u001b[36m3.7656\u001b[0m        \u001b[32m3.8395\u001b[0m  0.6209\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0904\u001b[0m        \u001b[32m3.8696\u001b[0m  0.6029\n",
      "      2        \u001b[36m3.9035\u001b[0m        \u001b[32m3.8601\u001b[0m  0.5912\n",
      "      3        \u001b[36m3.8947\u001b[0m        \u001b[32m3.8561\u001b[0m  0.5977\n",
      "      4        \u001b[36m3.8826\u001b[0m        3.8565  0.5995\n",
      "      5        \u001b[36m3.8722\u001b[0m        3.8590  0.5949\n",
      "      6        \u001b[36m3.8558\u001b[0m        3.8621  0.5879\n",
      "      7        \u001b[36m3.8490\u001b[0m        \u001b[32m3.8552\u001b[0m  0.5925\n",
      "      8        \u001b[36m3.8212\u001b[0m        3.8556  0.5930\n",
      "      9        \u001b[36m3.8054\u001b[0m        \u001b[32m3.8370\u001b[0m  0.6242\n",
      "     10        \u001b[36m3.7884\u001b[0m        \u001b[32m3.8245\u001b[0m  0.5988\n",
      "[[ 8.801232 ]\n",
      " [13.138171 ]\n",
      " [11.46954  ]\n",
      " ...\n",
      " [13.74191  ]\n",
      " [ 8.8807535]\n",
      " [ 9.008586 ]]\n",
      "(7099, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(7099,) <class 'pandas.core.series.Series'>\n",
      "(1774, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(1774,) <class 'pandas.core.series.Series'>\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.6965\u001b[0m        \u001b[32m4.5072\u001b[0m  0.3134\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7518\u001b[0m        \u001b[32m4.5054\u001b[0m  0.3215\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7263\u001b[0m        \u001b[32m4.5178\u001b[0m  0.3262\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7244\u001b[0m        \u001b[32m4.5321\u001b[0m  0.3503\n",
      "      2        \u001b[36m4.6542\u001b[0m        \u001b[32m4.5064\u001b[0m  0.3103\n",
      "      2        \u001b[36m4.6767\u001b[0m        \u001b[32m4.5034\u001b[0m  0.3117\n",
      "      2        \u001b[36m4.6610\u001b[0m        4.5187  0.3123\n",
      "      2        \u001b[36m4.6703\u001b[0m        \u001b[32m4.5317\u001b[0m  0.3366\n",
      "      3        \u001b[36m4.6257\u001b[0m        \u001b[32m4.5060\u001b[0m  0.3106\n",
      "      3        \u001b[36m4.6574\u001b[0m        4.5038  0.3103\n",
      "      3        \u001b[36m4.6330\u001b[0m        4.5191  0.3118\n",
      "      3        \u001b[36m4.6473\u001b[0m        \u001b[32m4.5311\u001b[0m  0.3373\n",
      "      4        \u001b[36m4.6055\u001b[0m        4.5060  0.3141\n",
      "      4        \u001b[36m4.6298\u001b[0m        \u001b[32m4.5028\u001b[0m  0.3177\n",
      "      4        \u001b[36m4.6176\u001b[0m        4.5189  0.3206\n",
      "      4        \u001b[36m4.6376\u001b[0m        \u001b[32m4.5310\u001b[0m  0.3407\n",
      "      5        \u001b[36m4.5952\u001b[0m        \u001b[32m4.5060\u001b[0m  0.3171\n",
      "      5        \u001b[36m4.6105\u001b[0m        \u001b[32m4.5026\u001b[0m  0.3164\n",
      "      5        \u001b[36m4.6174\u001b[0m        4.5184  0.3181\n",
      "      5        \u001b[36m4.6173\u001b[0m        \u001b[32m4.5304\u001b[0m  0.3431\n",
      "      6        \u001b[36m4.5873\u001b[0m        \u001b[32m4.5056\u001b[0m  0.3169\n",
      "      6        4.6198        \u001b[32m4.5026\u001b[0m  0.3149\n",
      "      6        \u001b[36m4.6020\u001b[0m        \u001b[32m4.5173\u001b[0m  0.3178\n",
      "      6        \u001b[36m4.6095\u001b[0m        4.5308  0.3407\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7099\u001b[0m        \u001b[32m4.4859\u001b[0m  0.3199\n",
      "      7        4.5894        \u001b[32m4.5052\u001b[0m  0.3123\n",
      "      7        \u001b[36m4.5980\u001b[0m        \u001b[32m4.5026\u001b[0m  0.3127\n",
      "      7        \u001b[36m4.5980\u001b[0m        \u001b[32m4.5164\u001b[0m  0.3122\n",
      "      7        \u001b[36m4.6057\u001b[0m        4.5305  0.3373\n",
      "      2        \u001b[36m4.6636\u001b[0m        \u001b[32m4.4851\u001b[0m  0.3133\n",
      "      8        \u001b[36m4.5792\u001b[0m        \u001b[32m4.5050\u001b[0m  0.3142\n",
      "      8        \u001b[36m4.5912\u001b[0m        \u001b[32m4.5024\u001b[0m  0.3158\n",
      "      8        \u001b[36m4.5972\u001b[0m        \u001b[32m4.5153\u001b[0m  0.3169\n",
      "      8        \u001b[36m4.6001\u001b[0m        \u001b[32m4.5301\u001b[0m  0.3431\n",
      "      3        \u001b[36m4.6354\u001b[0m        \u001b[32m4.4847\u001b[0m  0.3159\n",
      "      9        \u001b[36m4.5740\u001b[0m        \u001b[32m4.5048\u001b[0m  0.3195\n",
      "      9        \u001b[36m4.5903\u001b[0m        4.5024  0.3188\n",
      "      9        \u001b[36m4.5910\u001b[0m        4.5154  0.3212\n",
      "      9        \u001b[36m4.5946\u001b[0m        4.5302  0.3439\n",
      "      4        4.6408        \u001b[32m4.4843\u001b[0m  0.3184\n",
      "     10        4.5765        \u001b[32m4.5045\u001b[0m  0.3162\n",
      "     10        4.5915        \u001b[32m4.5022\u001b[0m  0.3177\n",
      "     10        \u001b[36m4.5862\u001b[0m        \u001b[32m4.5151\u001b[0m  0.3196\n",
      "     10        \u001b[36m4.5921\u001b[0m        4.5304  0.3394\n",
      "      5        \u001b[36m4.6152\u001b[0m        \u001b[32m4.4837\u001b[0m  0.3116\n",
      "      6        \u001b[36m4.6113\u001b[0m        \u001b[32m4.4832\u001b[0m  0.3093\n",
      "      7        \u001b[36m4.6070\u001b[0m        \u001b[32m4.4829\u001b[0m  0.3109\n",
      "      8        \u001b[36m4.6020\u001b[0m        4.4831  0.3135\n",
      "      9        \u001b[36m4.6018\u001b[0m        4.4832  0.3053\n",
      "     10        \u001b[36m4.5998\u001b[0m        4.4830  0.2969\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.6920\u001b[0m        \u001b[32m4.5044\u001b[0m  0.4148\n",
      "      2        \u001b[36m4.6598\u001b[0m        \u001b[32m4.5036\u001b[0m  0.3979\n",
      "      3        \u001b[36m4.6245\u001b[0m        4.5037  0.3994\n",
      "      4        \u001b[36m4.6162\u001b[0m        \u001b[32m4.5032\u001b[0m  0.4071\n",
      "      5        \u001b[36m4.6063\u001b[0m        \u001b[32m4.5031\u001b[0m  0.4072\n",
      "      6        \u001b[36m4.5978\u001b[0m        \u001b[32m4.5025\u001b[0m  0.4040\n",
      "      7        \u001b[36m4.5901\u001b[0m        \u001b[32m4.5020\u001b[0m  0.4004\n",
      "      8        \u001b[36m4.5860\u001b[0m        \u001b[32m4.5008\u001b[0m  0.4025\n",
      "      9        \u001b[36m4.5848\u001b[0m        \u001b[32m4.5003\u001b[0m  0.4015\n",
      "     10        4.5855        4.5004  0.3951\n",
      "[[0.24980661]\n",
      " [0.31633186]\n",
      " [0.32388103]\n",
      " ...\n",
      " [0.29786837]\n",
      " [0.31900364]\n",
      " [0.30895543]]\n",
      "(7099, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(7099,) <class 'pandas.core.series.Series'>\n",
      "(1774, 14) <class 'pandas.core.frame.DataFrame'>\n",
      "(1774,) <class 'pandas.core.series.Series'>\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7194\u001b[0m        \u001b[32m4.4886\u001b[0m  0.2879\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7191\u001b[0m        \u001b[32m4.4849\u001b[0m  0.2908\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.6477\u001b[0m        \u001b[32m4.5020\u001b[0m  0.3110\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.6790\u001b[0m        \u001b[32m4.4824\u001b[0m  0.2946\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.6909\u001b[0m        \u001b[32m4.4995\u001b[0m  0.2927\n",
      "      2        \u001b[36m4.6607\u001b[0m        \u001b[32m4.4881\u001b[0m  0.2795\n",
      "      2        \u001b[36m4.6385\u001b[0m        \u001b[32m4.4813\u001b[0m  0.2784\n",
      "      2        \u001b[36m4.6025\u001b[0m        \u001b[32m4.4967\u001b[0m  0.2897\n",
      "      2        \u001b[36m4.5997\u001b[0m        \u001b[32m4.4784\u001b[0m  0.2842\n",
      "      2        \u001b[36m4.6153\u001b[0m        \u001b[32m4.4970\u001b[0m  0.2884\n",
      "      3        \u001b[36m4.6370\u001b[0m        \u001b[32m4.4842\u001b[0m  0.2797\n",
      "      3        \u001b[36m4.6207\u001b[0m        \u001b[32m4.4807\u001b[0m  0.2852\n",
      "      3        \u001b[36m4.5756\u001b[0m        \u001b[32m4.4949\u001b[0m  0.2902\n",
      "      3        \u001b[36m4.5957\u001b[0m        \u001b[32m4.4749\u001b[0m  0.2808\n",
      "      3        \u001b[36m4.6040\u001b[0m        4.4982  0.2847\n",
      "      4        \u001b[36m4.6097\u001b[0m        \u001b[32m4.4837\u001b[0m  0.2821\n",
      "      4        \u001b[36m4.6154\u001b[0m        \u001b[32m4.4793\u001b[0m  0.2814\n",
      "      4        \u001b[36m4.5786\u001b[0m        \u001b[32m4.4711\u001b[0m  0.2790\n",
      "      4        4.5784        \u001b[32m4.4917\u001b[0m  0.2861\n",
      "      4        \u001b[36m4.5853\u001b[0m        4.4972  0.2839\n",
      "      5        4.6189        \u001b[32m4.4823\u001b[0m  0.2768\n",
      "      5        \u001b[36m4.5987\u001b[0m        \u001b[32m4.4787\u001b[0m  0.2767\n",
      "      5        \u001b[36m4.5687\u001b[0m        \u001b[32m4.4706\u001b[0m  0.2774\n",
      "      5        \u001b[36m4.5641\u001b[0m        \u001b[32m4.4906\u001b[0m  0.2875\n",
      "      5        \u001b[36m4.5839\u001b[0m        \u001b[32m4.4966\u001b[0m  0.2849\n",
      "      6        \u001b[36m4.6041\u001b[0m        \u001b[32m4.4805\u001b[0m  0.2814\n",
      "      6        \u001b[36m4.5861\u001b[0m        4.4804  0.2829\n",
      "      6        \u001b[36m4.5637\u001b[0m        4.4706  0.2822\n",
      "      6        \u001b[36m4.5627\u001b[0m        4.4919  0.2906\n",
      "      6        \u001b[36m4.5716\u001b[0m        4.4975  0.2906\n",
      "      7        4.6053        \u001b[32m4.4794\u001b[0m  0.2918\n",
      "      7        \u001b[36m4.5773\u001b[0m        4.4805  0.2964\n",
      "      7        \u001b[36m4.5572\u001b[0m        \u001b[32m4.4696\u001b[0m  0.2948\n",
      "      7        \u001b[36m4.5547\u001b[0m        4.4923  0.2999\n",
      "      7        \u001b[36m4.5700\u001b[0m        \u001b[32m4.4957\u001b[0m  0.2934\n",
      "      8        \u001b[36m4.5986\u001b[0m        \u001b[32m4.4792\u001b[0m  0.2867\n",
      "      8        4.5824        4.4788  0.2875\n",
      "      8        4.5648        \u001b[32m4.4692\u001b[0m  0.2869\n",
      "      8        \u001b[36m4.5668\u001b[0m        \u001b[32m4.4942\u001b[0m  0.2894\n",
      "      8        4.5580        4.4919  0.2971\n",
      "      9        \u001b[36m4.5928\u001b[0m        4.4801  0.2867\n",
      "      9        4.5789        \u001b[32m4.4767\u001b[0m  0.2860\n",
      "      9        \u001b[36m4.5503\u001b[0m        \u001b[32m4.4675\u001b[0m  0.2850\n",
      "      9        \u001b[36m4.5603\u001b[0m        4.4956  0.2913\n",
      "      9        \u001b[36m4.5527\u001b[0m        \u001b[32m4.4899\u001b[0m  0.2953\n",
      "     10        \u001b[36m4.5821\u001b[0m        4.4792  0.2874\n",
      "     10        4.5797        \u001b[32m4.4762\u001b[0m  0.2888\n",
      "     10        4.5547        \u001b[32m4.4656\u001b[0m  0.2885\n",
      "     10        4.5658        4.4954  0.2929\n",
      "     10        \u001b[36m4.5514\u001b[0m        \u001b[32m4.4881\u001b[0m  0.2916\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7118\u001b[0m        \u001b[32m4.5182\u001b[0m  0.3702\n",
      "      2        \u001b[36m4.6391\u001b[0m        \u001b[32m4.5029\u001b[0m  0.3635\n",
      "      3        \u001b[36m4.6116\u001b[0m        \u001b[32m4.4999\u001b[0m  0.3645\n",
      "      4        \u001b[36m4.5921\u001b[0m        \u001b[32m4.4981\u001b[0m  0.3770\n",
      "      5        4.5981        4.4985  0.3630\n",
      "      6        \u001b[36m4.5807\u001b[0m        \u001b[32m4.4967\u001b[0m  0.3618\n",
      "      7        \u001b[36m4.5772\u001b[0m        4.4970  0.3570\n",
      "      8        \u001b[36m4.5771\u001b[0m        \u001b[32m4.4959\u001b[0m  0.3581\n",
      "      9        \u001b[36m4.5657\u001b[0m        \u001b[32m4.4950\u001b[0m  0.3584\n",
      "     10        \u001b[36m4.5656\u001b[0m        4.4955  0.3552\n",
      "[[0.79044163]\n",
      " [0.5497812 ]\n",
      " [0.63392043]\n",
      " ...\n",
      " [0.6000451 ]\n",
      " [0.7612376 ]\n",
      " [0.5478362 ]]\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_support] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "for dataset in data_set_fns:\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target\n",
    "    print('Dataset:',data.filename)\n",
    "    print(X.dtypes)\n",
    "    print(y.dtypes)\n",
    "    \n",
    "    net = NeuralNet(\n",
    "    SurvivalModel, \n",
    "    module__n_layers = 1,\n",
    "    module__in_features = X.shape[1],\n",
    "    #module__num_nodes = 32,\n",
    "    #module__dropout = 0.1, # these could also be removed\n",
    "    module__out_features = 1,\n",
    "    # for split sizes when result size = 1\n",
    "    iterator_train__drop_last=True,\n",
    "    #iterator_valid__drop_last=True,\n",
    "    criterion=BreslowLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__weight_decay = 0.4,\n",
    "    batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    "    #TODO: enable stratification, verify\n",
    "    train_split=ValidSplit(0.2), # might cause lower performance in metrics, explain in thesis\n",
    "    #lr=0.001,\n",
    "    #max_epochs=1, #0,#100\n",
    "    #train_split=None,\n",
    "    verbose=1\n",
    "    )\n",
    "    best_model,params, outer_scores, best_preds_train, best_preds_test, X_train, X_test, y_train, y_test = train_eval(X, y, net, n_iter, data.filename)\n",
    "    \n",
    "#train eval function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params_SUPPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'estimator__batch_size': 512, 'estimator__lr'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'estimator__batch_size': 64, 'estimator__lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'estimator__batch_size': 128, 'estimator__lr'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'estimator__batch_size': 256, 'estimator__lr'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'estimator__batch_size': 512, 'estimator__lr'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 best_params_SUPPORT\n",
       "0  {'estimator__batch_size': 512, 'estimator__lr'...\n",
       "1  {'estimator__batch_size': 64, 'estimator__lr':...\n",
       "2  {'estimator__batch_size': 128, 'estimator__lr'...\n",
       "3  {'estimator__batch_size': 256, 'estimator__lr'...\n",
       "4  {'estimator__batch_size': 512, 'estimator__lr'..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breslow_estimator(log_hazard, time, event):\n",
    "    #time, event = transform_back(y)\n",
    "    risk_score = np.exp(log_hazard)\n",
    "    print(risk_score.shape)\n",
    "    is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "\n",
    "    if is_sorted(time) == False:\n",
    "        order = np.argsort(time, kind=\"mergesort\")\n",
    "        time = time[order]\n",
    "        event = event[order]\n",
    "        risk_score = risk_score[order]\n",
    "\n",
    "    uniq_times = np.unique(time)\n",
    "    idx = np.digitize(time, np.unique(time))\n",
    "    breaks = np.flatnonzero(np.concatenate(([1], np.diff(idx))))\n",
    "    # numpy diff nth discrete difference over index, add 1 at the beginning\n",
    "    # flatnonzero return indices that are nonzero in flattened version\n",
    "    n_events = np.add.reduceat(event, breaks, axis=0)\n",
    "\n",
    "    # consider removing zero rows\n",
    "    risk_matrix = np.unique((np.outer(time,time)>=np.square(time)).astype(int).T, axis=0)\n",
    "    print(risk_matrix.shape)\n",
    "    denominator = np.sum(risk_score.reshape(-1)*risk_matrix,axis=1)[::-1] \n",
    "\n",
    "    baseline_hazard = n_events / denominator\n",
    "    cum_hazard_baseline = np.cumsum(n_events / denominator)\n",
    "    baseline_survival = np.exp(-cum_hazard_baseline)\n",
    "    return uniq_times, baseline_hazard, cum_hazard_baseline, baseline_survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 1)\n",
      "(1381, 1523)\n"
     ]
    }
   ],
   "source": [
    "time, event = transform_back(y_train)\n",
    "uniq_times_old, baseline_hazard, cum_hazard_baseline_old, baseline_survival_old = breslow_estimator(best_preds_train, time, event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.exp(-(cum_hazard_baseline_old*np.exp(best_preds_train[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0.10000000149011612,
          0.7666666507720947,
          1.2333333492279053,
          1.4333332777023315,
          1.7666666507720947,
          2,
          2.4000000953674316,
          2.5,
          2.5333333015441895,
          3.366666555404663,
          3.5,
          3.7666666507720947,
          4.166666507720947,
          4.433333396911621,
          5.066666603088379,
          5.433333396911621,
          5.5,
          6.266666889190674,
          7.800000190734863,
          8.066666603088379,
          9.066666603088379,
          9.133333206176758,
          9.433333396911621,
          9.600000381469727,
          9.699999809265137,
          9.833333015441895,
          10.066666603088379,
          10.633333206176758,
          10.833333015441895,
          11.600000381469727,
          11.699999809265137,
          11.866666793823242,
          12.266666412353516,
          12.399999618530273,
          12.933333396911621,
          13.399999618530273,
          13.533333778381348,
          13.800000190734863,
          14.133333206176758,
          14.166666984558105,
          14.199999809265137,
          14.399999618530273,
          14.433333396911621,
          14.699999809265137,
          14.800000190734863,
          15.066666603088379,
          15.166666984558105,
          15.199999809265137,
          15.366666793823242,
          15.5,
          15.533333778381348,
          15.600000381469727,
          15.633333206176758,
          15.699999809265137,
          15.866666793823242,
          16.16666603088379,
          16.299999237060547,
          16.600000381469727,
          16.700000762939453,
          16.733333587646484,
          16.83333396911621,
          17.66666603088379,
          17.766666412353516,
          17.83333396911621,
          17.933332443237305,
          18.233333587646484,
          18.266666412353516,
          18.799999237060547,
          18.83333396911621,
          18.933332443237305,
          19,
          19.03333282470703,
          19.16666603088379,
          19.399999618530273,
          19.600000381469727,
          19.733333587646484,
          19.83333396911621,
          19.899999618530273,
          20,
          20.200000762939453,
          20.266666412353516,
          20.83333396911621,
          21,
          21.066667556762695,
          21.16666603088379,
          21.299999237060547,
          21.700000762939453,
          21.899999618530273,
          21.933332443237305,
          22.133333206176758,
          22.233333587646484,
          22.399999618530273,
          22.66666603088379,
          23.200000762939453,
          23.266666412353516,
          23.33333396911621,
          23.366666793823242,
          23.433332443237305,
          23.733333587646484,
          23.799999237060547,
          23.83333396911621,
          23.899999618530273,
          23.933332443237305,
          24.100000381469727,
          24.33333396911621,
          24.633333206176758,
          24.799999237060547,
          24.866666793823242,
          24.899999618530273,
          25.03333282470703,
          25.233333587646484,
          25.33333396911621,
          25.433332443237305,
          25.53333282470703,
          25.633333206176758,
          26,
          26.266666412353516,
          26.33333396911621,
          26.733333587646484,
          26.766666412353516,
          27,
          27.066667556762695,
          27.200000762939453,
          27.299999237060547,
          27.399999618530273,
          27.46666717529297,
          27.799999237060547,
          27.866666793823242,
          27.96666717529297,
          28,
          28.066667556762695,
          28.566667556762695,
          28.600000381469727,
          29,
          29.03333282470703,
          29.066667556762695,
          29.233333587646484,
          29.299999237060547,
          29.66666603088379,
          29.899999618530273,
          30.066667556762695,
          30.133333206176758,
          30.16666603088379,
          30.299999237060547,
          30.366666793823242,
          30.433332443237305,
          30.700000762939453,
          30.799999237060547,
          30.933332443237305,
          30.96666717529297,
          31,
          31.066667556762695,
          31.16666603088379,
          31.299999237060547,
          31.433332443237305,
          31.799999237060547,
          31.933332443237305,
          32.03333282470703,
          32.06666564941406,
          32.63333511352539,
          32.733333587646484,
          32.83333206176758,
          32.86666488647461,
          32.93333435058594,
          33.13333511352539,
          33.36666488647461,
          33.56666564941406,
          33.70000076293945,
          33.79999923706055,
          33.900001525878906,
          34.29999923706055,
          34.56666564941406,
          34.66666793823242,
          34.70000076293945,
          35,
          35.03333282470703,
          35.20000076293945,
          35.233333587646484,
          35.36666488647461,
          35.400001525878906,
          35.46666717529297,
          35.53333282470703,
          35.599998474121094,
          35.63333511352539,
          35.70000076293945,
          36.16666793823242,
          36.36666488647461,
          36.56666564941406,
          36.63333511352539,
          36.766666412353516,
          36.93333435058594,
          36.96666717529297,
          37,
          37.5,
          37.766666412353516,
          37.86666488647461,
          37.900001525878906,
          37.96666717529297,
          38.03333282470703,
          38.13333511352539,
          38.43333435058594,
          38.56666564941406,
          38.79999923706055,
          39.16666793823242,
          39.20000076293945,
          39.29999923706055,
          39.43333435058594,
          39.53333282470703,
          39.79999923706055,
          39.83333206176758,
          39.86666488647461,
          40.70000076293945,
          41.16666793823242,
          41.36666488647461,
          41.46666717529297,
          41.53333282470703,
          41.83333206176758,
          42.06666564941406,
          42.29999923706055,
          42.33333206176758,
          42.36666488647461,
          42.43333435058594,
          42.5,
          42.56666564941406,
          42.599998474121094,
          42.63333511352539,
          42.70000076293945,
          42.900001525878906,
          42.96666717529297,
          43.03333282470703,
          43.099998474121094,
          43.13333511352539,
          43.16666793823242,
          43.20000076293945,
          43.266666412353516,
          43.29999923706055,
          43.400001525878906,
          43.83333206176758,
          43.86666488647461,
          43.900001525878906,
          44.13333511352539,
          44.233333587646484,
          44.400001525878906,
          44.599998474121094,
          44.63333511352539,
          44.733333587646484,
          44.79999923706055,
          44.83333206176758,
          44.86666488647461,
          45.03333282470703,
          45.16666793823242,
          45.33333206176758,
          45.5,
          45.70000076293945,
          45.733333587646484,
          45.79999923706055,
          45.93333435058594,
          46.06666564941406,
          46.16666793823242,
          46.36666488647461,
          46.43333435058594,
          46.53333282470703,
          46.66666793823242,
          46.83333206176758,
          47.03333282470703,
          47.13333511352539,
          47.43333435058594,
          47.63333511352539,
          47.900001525878906,
          48.16666793823242,
          48.43333435058594,
          48.599998474121094,
          48.79999923706055,
          49.20000076293945,
          49.233333587646484,
          49.29999923706055,
          49.43333435058594,
          49.46666717529297,
          49.53333282470703,
          49.66666793823242,
          49.733333587646484,
          49.766666412353516,
          50,
          50.03333282470703,
          50.06666564941406,
          50.233333587646484,
          50.46666717529297,
          50.53333282470703,
          50.66666793823242,
          50.766666412353516,
          50.900001525878906,
          51,
          51.20000076293945,
          51.400001525878906,
          51.46666717529297,
          51.66666793823242,
          51.70000076293945,
          51.96666717529297,
          52.06666564941406,
          52.29999923706055,
          52.33333206176758,
          52.46666717529297,
          52.5,
          52.63333511352539,
          52.733333587646484,
          52.900001525878906,
          52.96666717529297,
          53.36666488647461,
          53.63333511352539,
          54.099998474121094,
          54.266666412353516,
          54.33333206176758,
          54.766666412353516,
          54.93333435058594,
          55,
          55.03333282470703,
          55.20000076293945,
          55.36666488647461,
          55.400001525878906,
          55.46666717529297,
          55.63333511352539,
          55.66666793823242,
          55.733333587646484,
          55.766666412353516,
          55.83333206176758,
          55.93333435058594,
          56.33333206176758,
          56.5,
          56.766666412353516,
          56.93333435058594,
          57.233333587646484,
          57.29999923706055,
          57.400001525878906,
          57.63333511352539,
          57.66666793823242,
          57.93333435058594,
          58,
          58.13333511352539,
          58.43333435058594,
          58.599998474121094,
          58.66666793823242,
          58.766666412353516,
          58.93333435058594,
          59.5,
          59.599998474121094,
          59.70000076293945,
          59.79999923706055,
          59.93333435058594,
          60.13333511352539,
          60.266666412353516,
          60.66666793823242,
          60.70000076293945,
          60.86666488647461,
          61.099998474121094,
          61.33333206176758,
          61.43333435058594,
          61.70000076293945,
          61.79999923706055,
          61.900001525878906,
          61.96666717529297,
          62.13333511352539,
          62.33333206176758,
          62.63333511352539,
          62.766666412353516,
          62.86666488647461,
          62.900001525878906,
          63,
          63.03333282470703,
          63.20000076293945,
          63.5,
          63.53333282470703,
          63.56666564941406,
          63.733333587646484,
          63.79999923706055,
          63.83333206176758,
          63.86666488647461,
          64,
          64.03333282470703,
          64.23332977294922,
          64.30000305175781,
          64.36666870117188,
          64.5999984741211,
          64.69999694824219,
          64.93333435058594,
          65.16666412353516,
          65.23332977294922,
          65.4000015258789,
          65.5,
          65.83333587646484,
          65.86666870117188,
          66.63333129882812,
          66.73332977294922,
          66.83333587646484,
          67.80000305175781,
          68.06666564941406,
          68.13333129882812,
          68.19999694824219,
          68.26667022705078,
          68.76667022705078,
          69.0999984741211,
          69.33333587646484,
          69.4000015258789,
          69.5,
          69.80000305175781,
          70.06666564941406,
          70.16666412353516,
          70.23332977294922,
          70.26667022705078,
          70.46666717529297,
          70.53333282470703,
          70.5999984741211,
          70.9000015258789,
          71,
          71.06666564941406,
          71.16666412353516,
          71.46666717529297,
          71.5,
          71.63333129882812,
          71.83333587646484,
          72.26667022705078,
          72.30000305175781,
          72.36666870117188,
          72.46666717529297,
          72.56666564941406,
          72.9000015258789,
          73.13333129882812,
          73.46666717529297,
          73.69999694824219,
          73.83333587646484,
          74.03333282470703,
          74.0999984741211,
          74.46666717529297,
          74.73332977294922,
          75.23332977294922,
          75.33333587646484,
          75.36666870117188,
          75.4000015258789,
          75.5,
          75.69999694824219,
          75.86666870117188,
          75.96666717529297,
          76,
          76.23332977294922,
          76.63333129882812,
          76.69999694824219,
          76.73332977294922,
          76.86666870117188,
          77.23332977294922,
          77.4000015258789,
          77.46666717529297,
          77.5,
          77.66666412353516,
          77.86666870117188,
          78.46666717529297,
          78.5999984741211,
          78.69999694824219,
          78.76667022705078,
          78.86666870117188,
          79.0999984741211,
          79.13333129882812,
          79.16666412353516,
          79.30000305175781,
          79.33333587646484,
          79.36666870117188,
          79.80000305175781,
          79.86666870117188,
          80.23332977294922,
          80.43333435058594,
          80.5,
          80.66666412353516,
          80.73332977294922,
          80.83333587646484,
          81.03333282470703,
          81.06666564941406,
          81.0999984741211,
          81.13333129882812,
          81.33333587646484,
          81.5,
          81.56666564941406,
          81.80000305175781,
          81.93333435058594,
          82.0999984741211,
          82.63333129882812,
          82.73332977294922,
          82.96666717529297,
          83.36666870117188,
          83.53333282470703,
          83.63333129882812,
          83.66666412353516,
          84.19999694824219,
          84.23332977294922,
          84.5,
          84.63333129882812,
          84.73332977294922,
          84.9000015258789,
          85,
          85.03333282470703,
          85.13333129882812,
          85.30000305175781,
          85.33333587646484,
          85.36666870117188,
          85.5,
          85.86666870117188,
          85.93333435058594,
          85.96666717529297,
          86,
          86.06666564941406,
          86.0999984741211,
          86.13333129882812,
          86.23332977294922,
          86.36666870117188,
          86.4000015258789,
          86.53333282470703,
          86.5999984741211,
          86.80000305175781,
          86.83333587646484,
          87,
          87.0999984741211,
          87.23332977294922,
          87.46666717529297,
          87.53333282470703,
          87.73332977294922,
          87.83333587646484,
          88.23332977294922,
          88.33333587646484,
          88.46666717529297,
          88.5,
          88.66666412353516,
          88.80000305175781,
          88.93333435058594,
          89.03333282470703,
          89.0999984741211,
          89.33333587646484,
          89.36666870117188,
          89.53333282470703,
          89.76667022705078,
          89.9000015258789,
          89.96666717529297,
          90,
          90.23332977294922,
          90.26667022705078,
          90.30000305175781,
          90.4000015258789,
          90.5999984741211,
          90.80000305175781,
          91.06666564941406,
          91.0999984741211,
          91.13333129882812,
          91.23332977294922,
          91.26667022705078,
          91.53333282470703,
          91.5999984741211,
          91.63333129882812,
          92.4000015258789,
          92.5,
          92.73332977294922,
          92.76667022705078,
          92.86666870117188,
          93.30000305175781,
          93.36666870117188,
          94.03333282470703,
          94.23332977294922,
          94.56666564941406,
          94.69999694824219,
          94.73332977294922,
          94.93333435058594,
          95.73332977294922,
          95.83333587646484,
          95.86666870117188,
          96.76667022705078,
          96.83333587646484,
          96.9000015258789,
          96.96666717529297,
          97.26667022705078,
          97.30000305175781,
          97.4000015258789,
          97.43333435058594,
          97.76667022705078,
          98.0999984741211,
          98.26667022705078,
          98.46666717529297,
          98.5,
          98.56666564941406,
          98.69999694824219,
          98.76667022705078,
          98.83333587646484,
          99,
          99.36666870117188,
          99.4000015258789,
          99.53333282470703,
          99.69999694824219,
          99.76667022705078,
          100.13333129882812,
          100.16666412353516,
          100.30000305175781,
          100.46666717529297,
          100.73332977294922,
          100.83333587646484,
          100.86666870117188,
          101.06666564941406,
          101.26667022705078,
          101.4000015258789,
          101.56666564941406,
          101.63333129882812,
          101.9000015258789,
          101.96666717529297,
          102,
          102.06666564941406,
          102.0999984741211,
          102.30000305175781,
          102.4000015258789,
          102.56666564941406,
          102.69999694824219,
          102.76667022705078,
          102.96666717529297,
          103.46666717529297,
          103.63333129882812,
          103.80000305175781,
          103.83333587646484,
          104,
          104.03333282470703,
          104.0999984741211,
          104.30000305175781,
          104.4000015258789,
          104.46666717529297,
          104.53333282470703,
          104.66666412353516,
          104.76667022705078,
          105.19999694824219,
          105.46666717529297,
          105.5999984741211,
          105.66666412353516,
          105.96666717529297,
          106.13333129882812,
          106.56666564941406,
          106.80000305175781,
          106.96666717529297,
          107.06666564941406,
          107.0999984741211,
          107.26667022705078,
          107.46666717529297,
          107.86666870117188,
          108.06666564941406,
          108.16666412353516,
          108.30000305175781,
          108.43333435058594,
          108.5999984741211,
          108.76667022705078,
          108.93333435058594,
          109,
          109.03333282470703,
          109.19999694824219,
          109.23332977294922,
          109.5999984741211,
          109.76667022705078,
          109.83333587646484,
          109.93333435058594,
          110.26667022705078,
          110.46666717529297,
          110.63333129882812,
          110.76667022705078,
          110.83333587646484,
          110.86666870117188,
          111,
          111.06666564941406,
          111.16666412353516,
          111.36666870117188,
          111.53333282470703,
          111.56666564941406,
          111.63333129882812,
          111.69999694824219,
          111.83333587646484,
          111.86666870117188,
          111.96666717529297,
          112,
          112.13333129882812,
          112.4000015258789,
          112.46666717529297,
          112.56666564941406,
          112.63333129882812,
          112.66666412353516,
          113.36666870117188,
          113.43333435058594,
          113.56666564941406,
          113.66666412353516,
          113.83333587646484,
          114,
          114.33333587646484,
          114.46666717529297,
          114.5,
          114.53333282470703,
          114.5999984741211,
          114.76667022705078,
          114.9000015258789,
          115.30000305175781,
          115.5999984741211,
          116.0999984741211,
          116.23332977294922,
          116.43333435058594,
          116.46666717529297,
          116.53333282470703,
          116.63333129882812,
          116.93333435058594,
          117,
          117.03333282470703,
          117.56666564941406,
          117.5999984741211,
          117.66666412353516,
          117.86666870117188,
          117.9000015258789,
          118,
          118.03333282470703,
          118.13333129882812,
          118.19999694824219,
          118.30000305175781,
          118.69999694824219,
          119,
          119.33333587646484,
          119.46666717529297,
          119.73332977294922,
          119.80000305175781,
          119.86666870117188,
          121.53333282470703,
          121.66666412353516,
          121.73332977294922,
          121.96666717529297,
          122,
          122.13333129882812,
          122.19999694824219,
          122.26667022705078,
          122.4000015258789,
          122.5,
          122.69999694824219,
          122.80000305175781,
          122.83333587646484,
          123,
          123.26667022705078,
          123.30000305175781,
          123.53333282470703,
          123.69999694824219,
          123.9000015258789,
          124,
          124.0999984741211,
          124.13333129882812,
          124.19999694824219,
          124.26667022705078,
          124.56666564941406,
          124.80000305175781,
          125.26667022705078,
          125.33333587646484,
          125.5999984741211,
          125.69999694824219,
          125.76667022705078,
          125.80000305175781,
          125.83333587646484,
          125.9000015258789,
          126.46666717529297,
          126.63333129882812,
          126.66666412353516,
          126.86666870117188,
          127.0999984741211,
          127.53333282470703,
          127.63333129882812,
          127.83333587646484,
          128.10000610351562,
          128.1999969482422,
          128.26666259765625,
          128.36666870117188,
          128.39999389648438,
          128.53334045410156,
          128.56666564941406,
          129.23333740234375,
          129.3333282470703,
          129.43333435058594,
          130.1999969482422,
          130.43333435058594,
          130.46665954589844,
          130.6999969482422,
          130.89999389648438,
          131.06666564941406,
          131.10000610351562,
          131.13333129882812,
          131.26666259765625,
          131.3333282470703,
          131.60000610351562,
          131.6666717529297,
          132.03334045410156,
          132.06666564941406,
          132.3000030517578,
          132.3333282470703,
          132.53334045410156,
          132.56666564941406,
          134.26666259765625,
          134.36666870117188,
          134.46665954589844,
          134.5,
          134.73333740234375,
          134.8333282470703,
          135.1666717529297,
          135.3000030517578,
          135.3333282470703,
          135.6666717529297,
          136,
          136.06666564941406,
          136.1666717529297,
          136.23333740234375,
          136.6999969482422,
          136.93333435058594,
          137.6666717529297,
          137.8000030517578,
          137.93333435058594,
          138.10000610351562,
          138.13333129882812,
          138.3333282470703,
          138.56666564941406,
          138.89999389648438,
          139.1666717529297,
          139.3000030517578,
          139.43333435058594,
          139.53334045410156,
          139.60000610351562,
          139.63333129882812,
          140.06666564941406,
          140.1999969482422,
          140.23333740234375,
          140.3333282470703,
          140.5,
          140.60000610351562,
          140.76666259765625,
          140.86666870117188,
          141.03334045410156,
          141.1666717529297,
          141.56666564941406,
          141.73333740234375,
          142.43333435058594,
          142.46665954589844,
          142.56666564941406,
          142.8000030517578,
          143.13333129882812,
          143.1666717529297,
          143.53334045410156,
          143.60000610351562,
          144.3333282470703,
          144.39999389648438,
          144.43333435058594,
          144.63333129882812,
          144.6666717529297,
          144.6999969482422,
          144.76666259765625,
          144.93333435058594,
          145.3000030517578,
          145.36666870117188,
          145.43333435058594,
          145.5,
          145.63333129882812,
          146,
          146.03334045410156,
          146.06666564941406,
          146.36666870117188,
          146.39999389648438,
          146.76666259765625,
          146.8333282470703,
          146.89999389648438,
          146.93333435058594,
          147.1666717529297,
          147.36666870117188,
          147.6666717529297,
          147.76666259765625,
          147.93333435058594,
          148.06666564941406,
          148.10000610351562,
          148.56666564941406,
          148.8000030517578,
          149.3000030517578,
          149.43333435058594,
          149.60000610351562,
          149.6999969482422,
          149.73333740234375,
          149.76666259765625,
          149.86666870117188,
          150.10000610351562,
          150.5,
          150.56666564941406,
          150.60000610351562,
          150.73333740234375,
          151,
          151.06666564941406,
          151.6666717529297,
          151.89999389648438,
          151.93333435058594,
          152.06666564941406,
          152.1999969482422,
          152.3000030517578,
          152.3333282470703,
          152.93333435058594,
          153.1999969482422,
          153.3000030517578,
          153.53334045410156,
          153.56666564941406,
          153.8333282470703,
          153.86666870117188,
          154,
          154.5,
          154.6999969482422,
          155.36666870117188,
          155.39999389648438,
          155.73333740234375,
          156.3333282470703,
          157.10000610351562,
          157.73333740234375,
          157.8000030517578,
          158.03334045410156,
          158.53334045410156,
          158.63333129882812,
          158.96665954589844,
          159,
          159.06666564941406,
          159.23333740234375,
          159.6999969482422,
          159.73333740234375,
          160,
          160.3000030517578,
          160.3333282470703,
          161.06666564941406,
          162.76666259765625,
          162.8333282470703,
          163.10000610351562,
          163.1666717529297,
          163.1999969482422,
          163.39999389648438,
          163.43333435058594,
          163.53334045410156,
          163.73333740234375,
          164.3333282470703,
          164.5,
          164.56666564941406,
          164.6999969482422,
          164.73333740234375,
          164.89999389648438,
          164.96665954589844,
          165.1666717529297,
          165.1999969482422,
          165.36666870117188,
          165.39999389648438,
          165.43333435058594,
          165.6666717529297,
          166.03334045410156,
          166.6666717529297,
          167.5,
          168.1999969482422,
          168.26666259765625,
          168.53334045410156,
          168.6999969482422,
          168.96665954589844,
          169,
          169.23333740234375,
          169.6666717529297,
          170.03334045410156,
          170.26666259765625,
          170.3000030517578,
          170.6666717529297,
          170.8333282470703,
          170.86666870117188,
          170.89999389648438,
          171.10000610351562,
          171.3000030517578,
          171.63333129882812,
          172,
          172.3000030517578,
          172.8000030517578,
          172.86666870117188,
          172.89999389648438,
          173.03334045410156,
          173.60000610351562,
          173.63333129882812,
          174.13333129882812,
          174.5,
          174.56666564941406,
          174.8000030517578,
          174.8333282470703,
          175.1666717529297,
          175.3333282470703,
          175.63333129882812,
          175.8000030517578,
          175.89999389648438,
          175.96665954589844,
          176.03334045410156,
          176.10000610351562,
          176.26666259765625,
          176.36666870117188,
          176.5,
          176.60000610351562,
          176.6999969482422,
          176.76666259765625,
          177.26666259765625,
          177.3333282470703,
          177.53334045410156,
          177.60000610351562,
          177.63333129882812,
          177.89999389648438,
          178.1666717529297,
          178.39999389648438,
          178.56666564941406,
          178.63333129882812,
          178.73333740234375,
          179.10000610351562,
          180.56666564941406,
          180.63333129882812,
          180.8333282470703,
          181.23333740234375,
          181.86666870117188,
          182.23333740234375,
          182.3333282470703,
          182.5,
          182.60000610351562,
          182.8333282470703,
          182.89999389648438,
          182.93333435058594,
          183.43333435058594,
          183.96665954589844,
          184.1666717529297,
          184.26666259765625,
          184.3333282470703,
          184.39999389648438,
          184.6999969482422,
          184.8000030517578,
          185,
          185.13333129882812,
          185.1666717529297,
          185.3000030517578,
          185.3333282470703,
          185.60000610351562,
          185.6999969482422,
          185.93333435058594,
          186.10000610351562,
          186.13333129882812,
          186.1999969482422,
          186.36666870117188,
          186.39999389648438,
          186.43333435058594,
          187.03334045410156,
          187.3000030517578,
          187.86666870117188,
          187.93333435058594,
          188.3333282470703,
          188.53334045410156,
          189.10000610351562,
          189.13333129882812,
          189.43333435058594,
          189.86666870117188,
          189.89999389648438,
          190.10000610351562,
          190.1666717529297,
          190.1999969482422,
          191.13333129882812,
          191.23333740234375,
          191.46665954589844,
          191.8000030517578,
          191.93333435058594,
          192.13333129882812,
          192.1999969482422,
          192.60000610351562,
          193.13333129882812,
          193.1666717529297,
          193.6999969482422,
          193.96665954589844,
          194.10000610351562,
          194.1666717529297,
          194.23333740234375,
          194.3000030517578,
          194.36666870117188,
          194.39999389648438,
          194.53334045410156,
          194.56666564941406,
          194.6999969482422,
          195.3000030517578,
          195.36666870117188,
          195.53334045410156,
          195.6999969482422,
          195.93333435058594,
          196.53334045410156,
          196.56666564941406,
          196.63333129882812,
          196.86666870117188,
          197.43333435058594,
          197.6666717529297,
          197.73333740234375,
          197.8333282470703,
          198.10000610351562,
          198.13333129882812,
          198.3000030517578,
          198.3333282470703,
          198.43333435058594,
          198.60000610351562,
          199.03334045410156,
          199.10000610351562,
          199.13333129882812,
          199.3000030517578,
          199.36666870117188,
          199.53334045410156,
          199.93333435058594,
          199.96665954589844,
          200.10000610351562,
          200.13333129882812,
          200.43333435058594,
          200.6999969482422,
          200.76666259765625,
          201.1666717529297,
          201.46665954589844,
          201.76666259765625,
          201.8333282470703,
          201.89999389648438,
          201.93333435058594,
          202.10000610351562,
          202.76666259765625,
          203,
          203.26666259765625,
          203.6999969482422,
          204.1999969482422,
          204.39999389648438,
          204.43333435058594,
          205.03334045410156,
          205.73333740234375,
          206.13333129882812,
          206.56666564941406,
          207.1666717529297,
          207.63333129882812,
          207.96665954589844,
          208.39999389648438,
          208.96665954589844,
          209.03334045410156,
          209.26666259765625,
          210.96665954589844,
          211.1999969482422,
          211.39999389648438,
          211.53334045410156,
          211.89999389648438,
          211.93333435058594,
          211.96665954589844,
          212.1999969482422,
          212.36666870117188,
          212.6999969482422,
          213,
          213.10000610351562,
          213.1999969482422,
          213.36666870117188,
          213.5,
          213.89999389648438,
          214.43333435058594,
          214.6999969482422,
          214.8000030517578,
          215.1666717529297,
          216.73333740234375,
          216.86666870117188,
          216.96665954589844,
          217.10000610351562,
          217.56666564941406,
          217.63333129882812,
          217.76666259765625,
          218.3000030517578,
          219.1666717529297,
          219.46665954589844,
          219.6666717529297,
          219.76666259765625,
          220.03334045410156,
          220.23333740234375,
          220.3000030517578,
          220.89999389648438,
          220.93333435058594,
          221.06666564941406,
          221.1999969482422,
          221.23333740234375,
          221.60000610351562,
          221.76666259765625,
          221.89999389648438,
          221.93333435058594,
          222.03334045410156,
          222.10000610351562,
          222.1999969482422,
          222.3333282470703,
          222.6999969482422,
          223.3000030517578,
          223.8333282470703,
          224.10000610351562,
          224.23333740234375,
          224.3000030517578,
          224.43333435058594,
          224.56666564941406,
          224.60000610351562,
          224.86666870117188,
          225.1666717529297,
          225.39999389648438,
          225.5,
          225.6999969482422,
          226.06666564941406,
          226.1999969482422,
          226.6999969482422,
          226.73333740234375,
          227.46665954589844,
          227.73333740234375,
          227.8000030517578,
          227.8333282470703,
          227.86666870117188,
          227.89999389648438,
          228,
          228.10000610351562,
          228.3333282470703,
          228.76666259765625,
          228.8000030517578,
          228.89999389648438,
          229.06666564941406,
          229.36666870117188,
          229.8333282470703,
          229.89999389648438,
          230.1666717529297,
          230.46665954589844,
          230.5,
          231.03334045410156,
          231.6666717529297,
          232.39999389648438,
          232.73333740234375,
          232.76666259765625,
          232.96665954589844,
          233.86666870117188,
          234.13333129882812,
          234.3333282470703,
          234.39999389648438,
          234.43333435058594,
          234.60000610351562,
          235.39999389648438,
          235.56666564941406,
          235.6666717529297,
          236.03334045410156,
          236.06666564941406,
          236.13333129882812,
          236.63333129882812,
          236.6999969482422,
          237.26666259765625,
          237.36666870117188,
          237.5,
          238.06666564941406,
          238.5,
          239.1666717529297,
          239.23333740234375,
          239.3000030517578,
          239.3333282470703,
          239.39999389648438,
          240.03334045410156,
          240.43333435058594,
          240.46665954589844,
          240.6999969482422,
          240.8333282470703,
          241.39999389648438,
          241.60000610351562,
          241.86666870117188,
          242.56666564941406,
          243.1666717529297,
          243.5,
          244.1999969482422,
          244.43333435058594,
          245.23333740234375,
          245.5,
          246.60000610351562,
          247,
          247.36666870117188,
          247.8333282470703,
          248.76666259765625,
          249.53334045410156,
          250.6666717529297,
          250.8000030517578,
          250.8333282470703,
          251.06666564941406,
          251.1999969482422,
          251.63333129882812,
          251.8000030517578,
          252,
          252.10000610351562,
          252.26666259765625,
          252.3000030517578,
          252.3333282470703,
          252.86666870117188,
          252.96665954589844,
          253.53334045410156,
          254.5,
          254.63333129882812,
          254.93333435058594,
          254.96665954589844,
          255,
          255.3000030517578,
          255.36666870117188,
          255.60000610351562,
          256.8666687011719,
          257.1666564941406,
          257.5666809082031,
          257.6333312988281,
          257.6666564941406,
          258.1666564941406,
          258.3333435058594,
          258.8666687011719,
          259.5333251953125,
          259.76666259765625,
          260,
          260.20001220703125,
          260.73333740234375,
          261.20001220703125,
          262,
          262.1333312988281,
          262.8666687011719,
          263.23333740234375,
          263.3666687011719,
          263.4333190917969,
          263.6000061035156,
          263.70001220703125,
          264.23333740234375,
          264.6000061035156,
          264.76666259765625,
          265,
          265.1333312988281,
          265.5666809082031,
          265.9333190917969,
          266.1000061035156,
          266.9333190917969,
          267.23333740234375,
          267.26666259765625,
          267.3999938964844,
          268.4333190917969,
          268.8999938964844,
          269,
          269.3333435058594,
          269.6333312988281,
          269.8999938964844,
          270.1333312988281,
          270.29998779296875,
          270.5666809082031,
          271.26666259765625,
          271.3333435058594,
          271.8666687011719,
          271.9333190917969,
          272.1000061035156,
          272.8999938964844,
          274.0333251953125,
          274.20001220703125,
          274.3999938964844,
          274.5,
          275.23333740234375,
          275.6000061035156,
          275.6333312988281,
          275.73333740234375,
          277.3666687011719,
          278.26666259765625,
          278.4666748046875,
          279.1000061035156,
          279.79998779296875,
          280.70001220703125,
          281.3666687011719,
          281.5,
          282.3666687011719,
          282.5666809082031,
          282.8333435058594,
          285.70001220703125,
          287.23333740234375,
          287.9333190917969,
          291.1666564941406,
          292.0333251953125,
          292.6666564941406,
          295.3333435058594,
          296.8666687011719,
          297.23333740234375,
          297.79998779296875,
          298.0333251953125,
          299.3999938964844,
          300.70001220703125,
          300.8666687011719,
          301.23333740234375,
          307.6333312988281,
          318.20001220703125,
          322.8333435058594,
          330.3666687011719,
          335.6000061035156,
          337.0333251953125,
          355.20001220703125
         ],
         "xaxis": "x",
         "y": [
          0.9993432119942207,
          0.9993432119942207,
          0.9993432119942207,
          0.9993432119942207,
          0.9993432119942207,
          0.9993432119942207,
          0.9993432119942207,
          0.9993432119942207,
          0.9986833912229232,
          0.9986833912229232,
          0.9980226911239997,
          0.9980226911239997,
          0.9973615441048873,
          0.9967003957821851,
          0.9960392465703335,
          0.9960392465703335,
          0.9953776608283454,
          0.9947160761346208,
          0.9940544952744307,
          0.993392911978239,
          0.9927313286820636,
          0.9920697472588607,
          0.9914081618213679,
          0.9907465770580204,
          0.9900849923948246,
          0.9894233926397351,
          0.988761792283161,
          0.9881001955238978,
          0.987438598987736,
          0.9867765617941712,
          0.9861145191042716,
          0.984790873595973,
          0.9841288314921989,
          0.9841288314921989,
          0.9834663469877376,
          0.9834663469877376,
          0.9828029734625424,
          0.9821395980800066,
          0.9814762223835564,
          0.9808128449989916,
          0.9801494707624232,
          0.9794860906469586,
          0.9788227122691269,
          0.9781593281958596,
          0.9774959457745351,
          0.9761696344053757,
          0.975506255264256,
          0.9748428764294275,
          0.9735165685624019,
          0.9728531878644698,
          0.9721898107868304,
          0.9715264295637233,
          0.9708630490394204,
          0.9701996689779326,
          0.9688733646471682,
          0.9682099776616468,
          0.9675465918880356,
          0.9668832075573366,
          0.9648944268510273,
          0.9642310469471048,
          0.9635676670088316,
          0.9629042883523761,
          0.9629042883523761,
          0.9629042883523761,
          0.9622399962423974,
          0.9615757075078406,
          0.9609114207516536,
          0.9602471305721085,
          0.9595828405890109,
          0.9589185531557088,
          0.9589185531557088,
          0.9582538101554403,
          0.957589068601274,
          0.956924328794265,
          0.956924328794265,
          0.9549300963214125,
          0.9542648944539558,
          0.9535996941049834,
          0.9529344946382384,
          0.9522692910560819,
          0.9522692910560819,
          0.9516036265659243,
          0.9509379622720807,
          0.950272298505647,
          0.9496066374199682,
          0.9489409790207453,
          0.9482753031636237,
          0.9476096283844446,
          0.9469439548693346,
          0.9462782833236961,
          0.9456126119714234,
          0.9449464736422284,
          0.9436146699844538,
          0.9429485353786136,
          0.9422824034757065,
          0.9416162677547171,
          0.940950128735486,
          0.9402839860763544,
          0.9396178467798303,
          0.9396178467798303,
          0.9389512386300168,
          0.9389512386300168,
          0.9382841599137427,
          0.937617083807097,
          0.9369500105409705,
          0.9362829386412247,
          0.935615855715378,
          0.9342821643128114,
          0.9336150831166085,
          0.9336150831166085,
          0.9329475277263545,
          0.9329475277263545,
          0.9322794971790608,
          0.9322794971790608,
          0.9316109848944717,
          0.9309424558043957,
          0.9302739277751887,
          0.9296054014606673,
          0.9282688343130254,
          0.9276002938673132,
          0.9269317566019707,
          0.9262632247042691,
          0.9255946963093785,
          0.9249261691671636,
          0.9242576440471545,
          0.923589119413111,
          0.9229205962680466,
          0.9222520757177828,
          0.9215835557942315,
          0.920915036726502,
          0.9202465186487793,
          0.9195779955809023,
          0.9189094744911339,
          0.9182409372524268,
          0.917572400649397,
          0.9169038626158096,
          0.9162353253658644,
          0.9155667748810054,
          0.9148982270368062,
          0.9142296803292053,
          0.9135611192552843,
          0.9128925573951552,
          0.9122239977867855,
          0.9115554411075469,
          0.9102188146913504,
          0.9095502570464701,
          0.9088812013644104,
          0.9082121268627538,
          0.9075430535222085,
          0.9068739822268723,
          0.9062049129204242,
          0.9055358452385636,
          0.9055358452385636,
          0.9048662841249365,
          0.9041967064266927,
          0.9035271298740898,
          0.9028575434201495,
          0.9021879578107543,
          0.9015183730462634,
          0.9008487902077751,
          0.9001791825072745,
          0.8995095718025146,
          0.8995095718025146,
          0.8988394675279073,
          0.898169363983393,
          0.8974992624515324,
          0.8974992624515324,
          0.8968286505207538,
          0.8961580388589445,
          0.8954874311249449,
          0.8948168225603692,
          0.8941462128935926,
          0.8934755974380615,
          0.8914652697310745,
          0.890794655775254,
          0.8901240432398871,
          0.889453431781082,
          0.888782822008411,
          0.8881122092217867,
          0.887441594372391,
          0.8867709833447454,
          0.8861003739943907,
          0.8854297663470173,
          0.8847591504635806,
          0.8840885362568689,
          0.8834179163774813,
          0.8827472990994584,
          0.8820766842717885,
          0.8814060574968217,
          0.8807354255393581,
          0.8800647950011706,
          0.8793941633604916,
          0.8787235362363621,
          0.8780529103843491,
          0.8773822786623466,
          0.8767116480544811,
          0.8760410194870278,
          0.8753703934990367,
          0.8733600713079503,
          0.8726894574613407,
          0.8720188466336114,
          0.87134823484896,
          0.8700075363341944,
          0.8693368401232657,
          0.8686661370392477,
          0.8679954365023862,
          0.8679954365023862,
          0.8673242202191211,
          0.8666530073881499,
          0.865981791130122,
          0.8653105771947146,
          0.8646393653101527,
          0.8632974226982463,
          0.8626261828250011,
          0.8612842227938021,
          0.8606129708225946,
          0.8599417211788893,
          0.8585997280360522,
          0.8579284645284555,
          0.8572571938240755,
          0.8565859070555885,
          0.8559146135275432,
          0.8552433219907883,
          0.8539012504177198,
          0.8532299532278658,
          0.8525586594275635,
          0.8518873674389094,
          0.8512160748829776,
          0.8498740243117537,
          0.8492027318518562,
          0.8478606861087286,
          0.8471893952317986,
          0.8471893952317986,
          0.845846288644717,
          0.8451744680658964,
          0.8445026488812355,
          0.8438308283077077,
          0.843159009834798,
          0.843159009834798,
          0.8424866519216533,
          0.8418142877889306,
          0.8418142877889306,
          0.8411413854845874,
          0.8404684802212623,
          0.8397955762849656,
          0.8384503089222327,
          0.8377774093639876,
          0.8371045100799169,
          0.8364316124291056,
          0.8364316124291056,
          0.8357581793597677,
          0.8350847468180193,
          0.8337373041154099,
          0.8330632823517652,
          0.8323892500152787,
          0.8317152194370072,
          0.831041191837899,
          0.8296936864317725,
          0.8290196639607228,
          0.8283456431015216,
          0.82767162598959,
          0.8269976078052419,
          0.8263235788227704,
          0.8256495424532381,
          0.8249754988317777,
          0.8243014582650096,
          0.8236274086679157,
          0.8229533538679032,
          0.8216058032212098,
          0.8209317543405729,
          0.8189112773393044,
          0.8182372021624753,
          0.8182372021624753,
          0.8175625761219926,
          0.8168879424580704,
          0.8162133119667296,
          0.8155386849250478,
          0.8141899712738867,
          0.813515337514376,
          0.8128406871829386,
          0.8121660357218874,
          0.8114913593854373,
          0.8108166818872276,
          0.8101420034819241,
          0.8101420034819241,
          0.8094667651710057,
          0.8094667651710057,
          0.8087909621257907,
          0.8081151461616259,
          0.807439332322719,
          0.8067635202668658,
          0.8060877064872689,
          0.8054118971758338,
          0.8047360912590624,
          0.8040602853631469,
          0.8033844742589913,
          0.8027086646197183,
          0.8013576183407907,
          0.8006818132388915,
          0.800005985535639,
          0.7993301614866962,
          0.7986543379764446,
          0.7979785176298659,
          0.7973026990442926,
          0.7966268829701706,
          0.7959510688585945,
          0.7952752544608449,
          0.7945994393700684,
          0.7939236153234027,
          0.7932477956330721,
          0.7925719734960353,
          0.7918961302382929,
          0.7912202747680328,
          0.7905444189951562,
          0.7898685558953981,
          0.7891926954284302,
          0.7885168368739718,
          0.7885168368739718,
          0.7878404040301188,
          0.7871639678881874,
          0.786487534870159,
          0.7858111032950473,
          0.7851346701314111,
          0.7851346701314111,
          0.7844576614364672,
          0.7844576614364672,
          0.7837800644516262,
          0.7831024689790761,
          0.7824248760776102,
          0.7817472865816779,
          0.7810696920946284,
          0.7797150751447691,
          0.7790374769118925,
          0.7790374769118925,
          0.7783592896818365,
          0.7783592896818365,
          0.7776805051510751,
          0.7770017231421801,
          0.7770017231421801,
          0.7770017231421801,
          0.7763217603634596,
          0.7756418012082585,
          0.7749618307682408,
          0.7742818633531879,
          0.773601896972422,
          0.7729219337159428,
          0.7729219337159428,
          0.7722413803192681,
          0.7722413803192681,
          0.7715602254526508,
          0.7715602254526508,
          0.7715602254526508,
          0.7708778718710738,
          0.7701955177571075,
          0.7701955177571075,
          0.7701955177571075,
          0.7701955177571075,
          0.7688278086208139,
          0.768143632254401,
          0.7674588476600497,
          0.7667740669523786,
          0.7667740669523786,
          0.7667740669523786,
          0.7660880632104136,
          0.7660880632104136,
          0.7654014494039131,
          0.7654014494039131,
          0.764714222137709,
          0.7640263835853689,
          0.7633385469071603,
          0.7626500948734005,
          0.7619616389716438,
          0.7619616389716438,
          0.7612725549973708,
          0.7605834721019243,
          0.7598943928710993,
          0.7592053149521727,
          0.7592053149521727,
          0.7592053149521727,
          0.758514987830243,
          0.758514987830243,
          0.7578240306415063,
          0.7571330726369473,
          0.7564421119520446,
          0.7557511532119889,
          0.7550601925875635,
          0.7550601925875635,
          0.754368596476515,
          0.7536770005170926,
          0.7536770005170926,
          0.7529847664484166,
          0.7522925313868198,
          0.7522925313868198,
          0.7509074321084057,
          0.75021456539262,
          0.7495216987148685,
          0.7488288282166019,
          0.7481359631425978,
          0.7474431038534026,
          0.7467502418417798,
          0.7460573713683198,
          0.7460573713683198,
          0.7460573713683198,
          0.7453632020140591,
          0.7446690373109038,
          0.7446690373109038,
          0.7446690373109038,
          0.7446690373109038,
          0.7439729294361972,
          0.7432768244390932,
          0.7425807133732819,
          0.7418846043939322,
          0.7418846043939322,
          0.7411878482240479,
          0.7404910964841905,
          0.7404910964841905,
          0.7404910964841905,
          0.7397930220991527,
          0.7397930220991527,
          0.7397930220991527,
          0.7397930220991527,
          0.7397930220991527,
          0.7390922773657986,
          0.7383915374149255,
          0.7383915374149255,
          0.7369893652085174,
          0.7362879455328863,
          0.7362879455328863,
          0.7355858643212773,
          0.7355858643212773,
          0.7348831110100553,
          0.734180335237488,
          0.7334775555116531,
          0.732774763250163,
          0.7320719740400277,
          0.7313685143807667,
          0.7313685143807667,
          0.7306643739691706,
          0.7299602307744067,
          0.7299602307744067,
          0.729255395901583,
          0.7285505519898036,
          0.7278456815528885,
          0.7278456815528885,
          0.7278456815528885,
          0.7278456815528885,
          0.7278456815528885,
          0.7271380693213443,
          0.7271380693213443,
          0.7264297683354344,
          0.725721470943591,
          0.7250131773311143,
          0.7243048849404811,
          0.723596596259798,
          0.7228883129200864,
          0.7228883129200864,
          0.7228883129200864,
          0.722178647499575,
          0.7214689618375256,
          0.7207592674766453,
          0.720049573612672,
          0.720049573612672,
          0.7193391757446315,
          0.7186287755221268,
          0.7179183768626755,
          0.7172079821123152,
          0.7172079821123152,
          0.7164968786657457,
          0.7157857776648544,
          0.7157857776648544,
          0.7143614732801298,
          0.7143614732801298,
          0.7143614732801298,
          0.7129343429547554,
          0.7122204112764696,
          0.7107932652493376,
          0.7100793226647416,
          0.7093653829029846,
          0.7086514425948123,
          0.7079375088909687,
          0.7072235665214852,
          0.7072235665214852,
          0.7065089074678473,
          0.7057935315906075,
          0.7057935315906075,
          0.7043620628253658,
          0.7036459696741819,
          0.7029298791382178,
          0.7022137750877313,
          0.7007823019058853,
          0.7000661927563723,
          0.6993500869941975,
          0.6993500869941975,
          0.6986332524117653,
          0.6979164219949762,
          0.697199591011689,
          0.6964827596282953,
          0.6964827596282953,
          0.6957651817843771,
          0.6957651817843771,
          0.6957651817843771,
          0.6957651817843771,
          0.6950453872231034,
          0.694325595240135,
          0.694325595240135,
          0.6936050625746704,
          0.6921647269497212,
          0.6921647269497212,
          0.6921647269497212,
          0.6907214250388535,
          0.6899994074108209,
          0.6899994074108209,
          0.6892766427680017,
          0.6892766427680017,
          0.6892766427680017,
          0.6892766427680017,
          0.6885516011880323,
          0.687826558186584,
          0.6863772509703951,
          0.6856522198530868,
          0.6849271791043513,
          0.6842021416516283,
          0.6842021416516283,
          0.6842021416516283,
          0.6834755752084379,
          0.6834755752084379,
          0.6834755752084379,
          0.6827474746417408,
          0.6820193706609223,
          0.6812912623876076,
          0.6805631603679393,
          0.6791077397148474,
          0.6783796471668778,
          0.6776515434066236,
          0.6769234376280482,
          0.6769234376280482,
          0.6761945562786134,
          0.6754656605898578,
          0.6747359831595281,
          0.6740063071486518,
          0.6732766373613811,
          0.672546959472122,
          0.6718172760468574,
          0.671087599267259,
          0.6696290449302975,
          0.6696290449302975,
          0.6688985799814955,
          0.6681681100253251,
          0.6674376394103781,
          0.6674376394103781,
          0.6674376394103781,
          0.6674376394103781,
          0.6667039774763887,
          0.6659703022631012,
          0.6652366228917175,
          0.6645029440547098,
          0.6637692664716781,
          0.6630355899957587,
          0.6630355899957587,
          0.6623010987509044,
          0.6615665996256141,
          0.6608321031733312,
          0.6608321031733312,
          0.6608321031733312,
          0.660095989051158,
          0.6593598544854495,
          0.6586237203779267,
          0.657887579025915,
          0.6571514288089177,
          0.6564144466524984,
          0.6556774679869141,
          0.6549404904851778,
          0.65346735991553,
          0.65346735991553,
          0.6527287270024152,
          0.6527287270024152,
          0.6519892612102671,
          0.6512497924046394,
          0.6505103275084684,
          0.6505103275084684,
          0.6505103275084684,
          0.6497691702638874,
          0.6497691702638874,
          0.6490271717900781,
          0.6482851730656509,
          0.6475431753095123,
          0.6468003342380594,
          0.6468003342380594,
          0.6460566450323205,
          0.6453129340736026,
          0.6453129340736026,
          0.6445683500955691,
          0.6438237681008622,
          0.6430791807713968,
          0.6423345702526829,
          0.6415899576779536,
          0.6415899576779536,
          0.6415899576779536,
          0.6408436159885386,
          0.640097280865692,
          0.6393509402508298,
          0.6393509402508298,
          0.6393509402508298,
          0.6386019910203236,
          0.6386019910203236,
          0.6378521750775362,
          0.6371014691193571,
          0.6371014691193571,
          0.6371014691193571,
          0.6363481114021907,
          0.6355947545357282,
          0.6355947545357282,
          0.6355947545357282,
          0.6348396162795789,
          0.6333302160108036,
          0.6325750579522861,
          0.6318190023548531,
          0.6310629502996655,
          0.6303069013251885,
          0.6295499565644086,
          0.6287930060734438,
          0.6280360224116822,
          0.6272790317534355,
          0.6272790317534355,
          0.6265211322057221,
          0.6265211322057221,
          0.6257622998907488,
          0.625003469493016,
          0.624244642457401,
          0.624244642457401,
          0.6234848805006978,
          0.6227251238405195,
          0.6227251238405195,
          0.6227251238405195,
          0.6219635115716629,
          0.6212019032376849,
          0.6204402842759466,
          0.6204402842759466,
          0.6196777277409278,
          0.6189151756219046,
          0.6189151756219046,
          0.6189151756219046,
          0.6181507485622705,
          0.6181507485622705,
          0.6173844377136437,
          0.6173844377136437,
          0.616617172316428,
          0.616617172316428,
          0.616617172316428,
          0.6158480039060465,
          0.6158480039060465,
          0.6158480039060465,
          0.6150759677842197,
          0.6143039098297787,
          0.6143039098297787,
          0.6135308884647849,
          0.6135308884647849,
          0.6135308884647849,
          0.6135308884647849,
          0.6135308884647849,
          0.6127539818255706,
          0.6119770811030449,
          0.6112001777009962,
          0.6112001777009962,
          0.6112001777009962,
          0.6104213080312937,
          0.6104213080312937,
          0.6096414322966132,
          0.6088615556863671,
          0.6088615556863671,
          0.6080806762779457,
          0.6072998005808765,
          0.6072998005808765,
          0.6065179302593172,
          0.6065179302593172,
          0.6065179302593172,
          0.6049511872044366,
          0.6041673048121544,
          0.6041673048121544,
          0.6033824125147094,
          0.6025975259228853,
          0.6025975259228853,
          0.6025975259228853,
          0.6025975259228853,
          0.6025975259228853,
          0.6018085330154453,
          0.601019549806045,
          0.601019549806045,
          0.601019549806045,
          0.6002284984424625,
          0.5994374410722406,
          0.5994374410722406,
          0.5994374410722406,
          0.5986442976093115,
          0.5986442976093115,
          0.59785009707929,
          0.59785009707929,
          0.5970548263586111,
          0.5962595623448929,
          0.5954643035044159,
          0.5946690473206986,
          0.5946690473206986,
          0.5946690473206986,
          0.5946690473206986,
          0.5946690473206986,
          0.5938684584864569,
          0.5938684584864569,
          0.5914666889788568,
          0.5914666889788568,
          0.5906639241417432,
          0.5898611673061464,
          0.5890583862946855,
          0.5882556127679786,
          0.5882556127679786,
          0.5874517570442278,
          0.5866478716509097,
          0.5858439826544839,
          0.5858439826544839,
          0.584232910932341,
          0.584232910932341,
          0.584232910932341,
          0.5834245897894297,
          0.5834245897894297,
          0.5826140434912342,
          0.5826140434912342,
          0.5826140434912342,
          0.581801235135985,
          0.581801235135985,
          0.581801235135985,
          0.581801235135985,
          0.581801235135985,
          0.581801235135985,
          0.5801631026938887,
          0.5785249591303344,
          0.5777053003244529,
          0.5768856452868394,
          0.5768856452868394,
          0.5760636702369034,
          0.5760636702369034,
          0.5760636702369034,
          0.5760636702369034,
          0.575236995116505,
          0.575236995116505,
          0.5735777427381911,
          0.5727475282679164,
          0.5727475282679164,
          0.5719160788764474,
          0.5710846350562864,
          0.5702519864259809,
          0.5694193370059774,
          0.5677552568703683,
          0.566922617851249,
          0.5660887639304001,
          0.5660887639304001,
          0.5652524703920512,
          0.564416167656452,
          0.5627448058367222,
          0.5619085166314872,
          0.5610722145452521,
          0.5610722145452521,
          0.5610722145452521,
          0.5610722145452521,
          0.5610722145452521,
          0.5602296414252732,
          0.5602296414252732,
          0.5593858166929839,
          0.5593858166929839,
          0.5585407245799232,
          0.5585407245799232,
          0.5576930855237916,
          0.5576930855237916,
          0.556842893495806,
          0.5559926976435416,
          0.5551424881857859,
          0.5551424881857859,
          0.5551424881857859,
          0.5551424881857859,
          0.5542883698189487,
          0.5542883698189487,
          0.5542883698189487,
          0.5542883698189487,
          0.5542883698189487,
          0.5542883698189487,
          0.5534263270681802,
          0.5534263270681802,
          0.5525629532717053,
          0.5516995865981965,
          0.5516995865981965,
          0.5516995865981965,
          0.5508335103443786,
          0.5508335103443786,
          0.5499660747159106,
          0.5490986295150062,
          0.5490986295150062,
          0.5482298208266028,
          0.5482298208266028,
          0.5482298208266028,
          0.5482298208266028,
          0.5482298208266028,
          0.5473554724403322,
          0.5473554724403322,
          0.5473554724403322,
          0.5473554724403322,
          0.5464755130712098,
          0.5464755130712098,
          0.5464755130712098,
          0.5455912933206276,
          0.5455912933206276,
          0.5455912933206276,
          0.5447042189835114,
          0.5438157171407061,
          0.5438157171407061,
          0.5438157171407061,
          0.5438157171407061,
          0.5438157171407061,
          0.5438157171407061,
          0.5438157171407061,
          0.5429169741429147,
          0.5429169741429147,
          0.5420167113627824,
          0.5420167113627824,
          0.5411149643531139,
          0.5411149643531139,
          0.5411149643531139,
          0.5411149643531139,
          0.5411149643531139,
          0.5411149643531139,
          0.5402041457488348,
          0.5392933394380975,
          0.5392933394380975,
          0.5392933394380975,
          0.5392933394380975,
          0.5383763785455646,
          0.5365440276924643,
          0.5356270693605326,
          0.5356270693605326,
          0.5347069579954228,
          0.5347069579954228,
          0.5337852453449142,
          0.5337852453449142,
          0.53286194028743,
          0.5319385930062802,
          0.5319385930062802,
          0.5319385930062802,
          0.5310120361094413,
          0.5310120361094413,
          0.5300822541485903,
          0.5291524733349793,
          0.5291524733349793,
          0.5291524733349793,
          0.5282193935189562,
          0.5272863177607108,
          0.5263532492383518,
          0.5263532492383518,
          0.5263532492383518,
          0.5263532492383518,
          0.5254152032839574,
          0.5254152032839574,
          0.5254152032839574,
          0.5244738020527961,
          0.5244738020527961,
          0.523530716532853,
          0.523530716532853,
          0.5225859391228189,
          0.5225859391228189,
          0.5216394598680412,
          0.5216394598680412,
          0.5206912681426857,
          0.5206912681426857,
          0.5206912681426857,
          0.5197396269534021,
          0.5187879821069936,
          0.5178363525922538,
          0.5178363525922538,
          0.5168829509557432,
          0.5168829509557432,
          0.5159260605855968,
          0.5159260605855968,
          0.5159260605855968,
          0.5159260605855968,
          0.5149620400327468,
          0.5149620400327468,
          0.5149620400327468,
          0.5120646048137545,
          0.5110969816015202,
          0.5110969816015202,
          0.5110969816015202,
          0.5101257060824324,
          0.5101257060824324,
          0.5091525529543783,
          0.5062386676338948,
          0.5062386676338948,
          0.5062386676338948,
          0.5052617280317324,
          0.5042848037876139,
          0.5042848037876139,
          0.5033059333997331,
          0.5033059333997331,
          0.5033059333997331,
          0.5023232472738166,
          0.5013405652329971,
          0.5003578479484239,
          0.49937507630428113,
          0.49937507630428113,
          0.4983903876926455,
          0.4983903876926455,
          0.49740377436161975,
          0.49641715418586957,
          0.49641715418586957,
          0.49641715418586957,
          0.49542661964204643,
          0.49542661964204643,
          0.49443211535939147,
          0.49343762099164634,
          0.49343762099164634,
          0.49244111901769083,
          0.49144462910405384,
          0.4904481315453829,
          0.4894516403613691,
          0.4894516403613691,
          0.4894516403613691,
          0.4894516403613691,
          0.48844904928244937,
          0.48844904928244937,
          0.48844904928244937,
          0.48744224458736507,
          0.4864354477066479,
          0.4854286603082221,
          0.484421868383766,
          0.484421868383766,
          0.484421868383766,
          0.484421868383766,
          0.484421868383766,
          0.48340454030490015,
          0.48340454030490015,
          0.48238294088931255,
          0.48238294088931255,
          0.48238294088931255,
          0.48238294088931255,
          0.4813548308163719,
          0.4803267372756827,
          0.4803267372756827,
          0.4803267372756827,
          0.4792942516920312,
          0.4792942516920312,
          0.4792942516920312,
          0.4792942516920312,
          0.4792942516920312,
          0.4792942516920312,
          0.4782505511173546,
          0.47720686617756447,
          0.47616088100741605,
          0.47616088100741605,
          0.4751125561832039,
          0.47406425083980513,
          0.4730159532091778,
          0.4730159532091778,
          0.4719653145544331,
          0.4709146889631434,
          0.46986405333662246,
          0.4688134242768129,
          0.4688134242768129,
          0.4688134242768129,
          0.467758102135497,
          0.467758102135497,
          0.4667004132287011,
          0.4656426534664784,
          0.4645848933053637,
          0.4645848933053637,
          0.4635247505010807,
          0.46246461615734225,
          0.4603468049862759,
          0.4592867132152696,
          0.45822659998868803,
          0.45822659998868803,
          0.4571640363559097,
          0.4561014602213995,
          0.45503888392224867,
          0.4539763022904927,
          0.4539763022904927,
          0.4539763022904927,
          0.4539763022904927,
          0.4539763022904927,
          0.4539763022904927,
          0.4529011829814159,
          0.4518260823816827,
          0.4507510010219463,
          0.4496759054659726,
          0.4486008163470436,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44752570462402297,
          0.44642142670999685,
          0.44642142670999685,
          0.44531442148866207,
          0.44531442148866207,
          0.44420466031828465,
          0.4430949072962962,
          0.4430949072962962,
          0.4430949072962962,
          0.4419795187777981,
          0.4408641547220993,
          0.4408641547220993,
          0.4408641547220993,
          0.43974313007437377,
          0.43974313007437377,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43861914463768814,
          0.43745970241359444,
          0.43745970241359444,
          0.4362971370132584,
          0.4362971370132584,
          0.4362971370132584,
          0.4362971370132584,
          0.4362971370132584,
          0.4362971370132584,
          0.43511899041947666,
          0.43511899041947666,
          0.43511899041947666,
          0.43511899041947666,
          0.43511899041947666,
          0.43511899041947666,
          0.4339247790464399,
          0.4339247790464399,
          0.43272729261631804,
          0.43272729261631804,
          0.43152317211891356,
          0.43152317211891356,
          0.43152317211891356,
          0.43031231315835017,
          0.4291014091050655,
          0.4291014091050655,
          0.4291014091050655,
          0.4291014091050655,
          0.4291014091050655,
          0.4278767839863135,
          0.4278767839863135,
          0.4278767839863135,
          0.42664517019968773,
          0.42664517019968773,
          0.4254100260899342,
          0.4254100260899342,
          0.4229361642253444,
          0.4229361642253444,
          0.42169377407605474,
          0.42169377407605474,
          0.42169377407605474,
          0.42169377407605474,
          0.42169377407605474,
          0.42169377407605474,
          0.4204137563206503,
          0.41913375290848925,
          0.41913375290848925,
          0.41913375290848925,
          0.41913375290848925,
          0.41784196110238436,
          0.41784196110238436,
          0.41784196110238436,
          0.41654217380535075,
          0.41654217380535075,
          0.4152383220688496,
          0.4152383220688496,
          0.4139303890780292,
          0.4139303890780292,
          0.4139303890780292,
          0.41261419583588954,
          0.41261419583588954,
          0.4112938049927867,
          0.4112938049927867,
          0.4099691850798564,
          0.40864455367236346,
          0.40731988136299746,
          0.40467487056769014,
          0.40467487056769014,
          0.40467487056769014,
          0.4033414447723521,
          0.4033414447723521,
          0.40200364436772035,
          0.40066583932268746,
          0.40066583932268746,
          0.40066583932268746,
          0.40066583932268746,
          0.399314630625438,
          0.399314630625438,
          0.399314630625438,
          0.399314630625438,
          0.399314630625438,
          0.399314630625438,
          0.399314630625438,
          0.399314630625438,
          0.39793078386481395,
          0.39793078386481395,
          0.39793078386481395,
          0.3965372833585835,
          0.3951438221743381,
          0.39375038943288587,
          0.3923569737273505,
          0.39096358092815253,
          0.39096358092815253,
          0.38956021150552395,
          0.38956021150552395,
          0.38815180809321487,
          0.3867433909734146,
          0.3867433909734146,
          0.385329877650143,
          0.385329877650143,
          0.385329877650143,
          0.3839059149614043,
          0.3824818524784032,
          0.3824818524784032,
          0.3824818524784032,
          0.38104707648497127,
          0.38104707648497127,
          0.37960688478635735,
          0.3781667012281643,
          0.3781667012281643,
          0.3767210107366807,
          0.37526979476420724,
          0.37526979476420724,
          0.3738129750139029,
          0.37235617704465984,
          0.37235617704465984,
          0.37235617704465984,
          0.37088797975376786,
          0.36940814592991433,
          0.36940814592991433,
          0.36940814592991433,
          0.3679163204338626,
          0.36642452665579167,
          0.36642452665579167,
          0.36642452665579167,
          0.36642452665579167,
          0.36491434984204074,
          0.36491434984204074,
          0.36339796106396477,
          0.36339796106396477,
          0.36187526478390875,
          0.3603525826033678,
          0.3603525826033678,
          0.35881685696629545,
          0.3572811780107688,
          0.3557455661566709,
          0.3557455661566709,
          0.354203339417081,
          0.351125699235958,
          0.351125699235958,
          0.3495768449837173,
          0.34802801971437886,
          0.34802801971437886,
          0.34802801971437886,
          0.34802801971437886,
          0.34645822847952695,
          0.3448884384695845,
          0.34331866100986547,
          0.34331866100986547,
          0.34331866100986547,
          0.3417271689542276,
          0.3401356878901385,
          0.3401356878901385,
          0.3401356878901385,
          0.3385291945895996,
          0.3385291945895996,
          0.33691503276993207,
          0.33691503276993207,
          0.3352852898498887,
          0.3352852898498887,
          0.33364757902275005,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33200987448276914,
          0.33029649208426864,
          0.33029649208426864,
          0.32856522785613745,
          0.32856522785613745,
          0.32856522785613745,
          0.32856522785613745,
          0.32680631893902756,
          0.3250474857666629,
          0.3232887109919787,
          0.32152998347498685,
          0.3197713223685466,
          0.3197713223685466,
          0.31800302275421805,
          0.31800302275421805,
          0.3162249141971326,
          0.3162249141971326,
          0.3162249141971326,
          0.3162249141971326,
          0.3144164457054591,
          0.3144164457054591,
          0.3144164457054591,
          0.3144164457054591,
          0.3144164457054591,
          0.3144164457054591,
          0.3125546508289215,
          0.3125546508289215,
          0.3125546508289215,
          0.3106705741303484,
          0.30878659466485914,
          0.30878659466485914,
          0.30689102702420157,
          0.30499537955351064,
          0.30309981418309806,
          0.30309981418309806,
          0.3011923429089984,
          0.3011923429089984,
          0.3011923429089984,
          0.29926065324460205,
          0.29926065324460205,
          0.29926065324460205,
          0.29926065324460205,
          0.29926065324460205,
          0.29926065324460205,
          0.29926065324460205,
          0.29725150790050114,
          0.2952422465535017,
          0.2952422465535017,
          0.2932191627430943,
          0.2932191627430943,
          0.2932191627430943,
          0.2932191627430943,
          0.2932191627430943,
          0.2932191627430943,
          0.2932191627430943,
          0.2911091969149574,
          0.2911091969149574,
          0.2911091969149574,
          0.2911091969149574,
          0.2911091969149574,
          0.2911091969149574,
          0.28892037506127577,
          0.28892037506127577,
          0.28892037506127577,
          0.28892037506127577,
          0.28892037506127577,
          0.28664575190350094,
          0.28664575190350094,
          0.2843528225458814,
          0.2843528225458814,
          0.28204140071887157,
          0.28204140071887157,
          0.28204140071887157,
          0.27969138274729133,
          0.27969138274729133,
          0.27730144713219607,
          0.27730144713219607,
          0.27730144713219607,
          0.27730144713219607,
          0.27730144713219607,
          0.2748264832858473,
          0.2748264832858473,
          0.2723293343814282,
          0.2723293343814282,
          0.2723293343814282,
          0.2697859964784704,
          0.26724277173508215,
          0.26724277173508215,
          0.26467552229911595,
          0.26467552229911595,
          0.26208339816783194,
          0.26208339816783194,
          0.26208339816783194,
          0.26208339816783194,
          0.26208339816783194,
          0.2593850051330855,
          0.2593850051330855,
          0.2593850051330855,
          0.2593850051330855,
          0.25660011478356415,
          0.25660011478356415,
          0.25660011478356415,
          0.25660011478356415,
          0.25660011478356415,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.25368991511678396,
          0.250316725564733,
          0.250316725564733,
          0.250316725564733,
          0.250316725564733,
          0.2468020651968482,
          0.24328729158276036,
          0.24328729158276036,
          0.24328729158276036,
          0.23961458222393425,
          0.23961458222393425,
          0.23961458222393425,
          0.23582684430465742,
          0.23582684430465742,
          0.23197739370666842,
          0.23197739370666842,
          0.23197739370666842,
          0.23197739370666842,
          0.23197739370666842,
          0.2278556043215459,
          0.2278556043215459,
          0.2278556043215459,
          0.2278556043215459,
          0.2278556043215459,
          0.2278556043215459,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.22332724850465074,
          0.21663758229897975,
          0.21663758229897975,
          0.21663758229897975,
          0.21663758229897975,
          0.21663758229897975,
          0.21663758229897975,
          0.20873303699608411,
          0.20873303699608411,
          0.20873303699608411,
          0.20017896211401087,
          0.1916265567441194,
          0.1830758250794285,
          0.1830758250794285,
          0.1830758250794285,
          0.1830758250794285,
          0.17314269260005774,
          0.1632119298031502,
          0.1532819737002058,
          0.1532819737002058,
          0.1532819737002058,
          0.1532819737002058,
          0.14097896873502344,
          0.14097896873502344,
          0.12750363736820644,
          0.12750363736820644,
          0.12750363736820644,
          0.12750363736820644,
          0.12750363736820644,
          0.12750363736820644,
          0.12750363736820644,
          0.09122136944806272,
          0.09122136944806272,
          0.03342821935617133
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "px.line(x =uniq_times_old, y = p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 1)\n",
      "(1381, 1522)\n",
      "cum_hazard_baseline_old (1381,)\n",
      "cum_hazard_baseline_old_new.shape (381, 1)\n",
      "preds (381, 381)\n",
      "uni_times.shape (374,)\n",
      "y_train (1522,)\n",
      "y_test (381,)\n",
      "preds (381, 374)\n",
      "times (374,)\n",
      "Integrated Brier Score: 0.551\n"
     ]
    }
   ],
   "source": [
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "data = load_metabric(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=False)\n",
    "X  = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# use from arrays and then build the two survival struc arrays\n",
    "# do test predictions in shape of (n_samples, n_times) and put in unique times\n",
    "# for the last time point the unique time point has to be decremente by a tiny bit!\n",
    "time, event = transform_back(y_train)\n",
    "time_train, event_train = transform_back(y_train)\n",
    "y_train = Surv.from_arrays( event_train.astype(dtype=bool),time_train)\n",
    "time_test, event_test = transform_back(y_test)\n",
    "y_test = Surv.from_arrays(event_test.astype(dtype=bool),time_test)\n",
    "uniq_times_old, baseline_hazard, cum_hazard_baseline_old, baseline_survival_old = breslow_estimator(best_preds_train, time, event)\n",
    "print('cum_hazard_baseline_old', cum_hazard_baseline_old.shape)\n",
    "# cumbaseline hazard for each (unique) time step of the test data\n",
    "cum_hazard_baseline_old_new = np.interp(time_test, np.unique(time_train), cum_hazard_baseline_old)\n",
    "best_preds_test = np.ones(y_test.shape[0])\n",
    "print('cum_hazard_baseline_old_new.shape',cum_hazard_baseline_old_new[:, None].shape)\n",
    "#preds = np.exp(-(cum_hazard_baseline_old_new[:,None]*np.exp(best_preds_test)))\n",
    "# as many as there unique time steps\n",
    "#cum_hazard_baseline_old_new = np.ones((334))\n",
    "preds = np.exp(-(np.outer(np.exp(best_preds_test), np.exp(cum_hazard_baseline_old_new))))\n",
    "print('preds',preds.shape)\n",
    "preds = np.ones((381,374))\n",
    "uni_times = np.unique(time_test)\n",
    "print('uni_times.shape',uni_times.shape)\n",
    "times = np.unique(time_test)\n",
    "#times = np.arange(time_test.min(),time_test.max())\n",
    "times = np.delete(times,-1)\n",
    "# the highest time has to be decremented, but at the same time only a range seems to work\n",
    "times = np.append(times,337.03333-0.1)\n",
    "print('y_train',y_train.shape)\n",
    "print('y_test',y_test.shape)\n",
    "print('preds',preds.shape)\n",
    "print('times',times.shape)\n",
    "ibs = integrated_brier_score(y_train, y_test, preds, times)\n",
    "print(\"Integrated Brier Score: {:.3f}\".format(ibs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337.0333251953125"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## process\n",
    "hazard for each unique time step multiplied by the predicted hazard\n",
    "applying surv function exp(-x)\n",
    "preds hence (individuals, unique times)\n",
    "unique times with the last value slightly decremented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7666667 337.03333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  3.76666665,   4.76666665,   5.76666665,   6.76666665,\n",
       "         7.76666665,   8.76666665,   9.76666665,  10.76666665,\n",
       "        11.76666665,  12.76666665,  13.76666665,  14.76666665,\n",
       "        15.76666665,  16.76666665,  17.76666665,  18.76666665,\n",
       "        19.76666665,  20.76666665,  21.76666665,  22.76666665,\n",
       "        23.76666665,  24.76666665,  25.76666665,  26.76666665,\n",
       "        27.76666665,  28.76666665,  29.76666665,  30.76666665,\n",
       "        31.76666665,  32.76666665,  33.76666665,  34.76666665,\n",
       "        35.76666665,  36.76666665,  37.76666665,  38.76666665,\n",
       "        39.76666665,  40.76666665,  41.76666665,  42.76666665,\n",
       "        43.76666665,  44.76666665,  45.76666665,  46.76666665,\n",
       "        47.76666665,  48.76666665,  49.76666665,  50.76666665,\n",
       "        51.76666665,  52.76666665,  53.76666665,  54.76666665,\n",
       "        55.76666665,  56.76666665,  57.76666665,  58.76666665,\n",
       "        59.76666665,  60.76666665,  61.76666665,  62.76666665,\n",
       "        63.76666665,  64.76666665,  65.76666665,  66.76666665,\n",
       "        67.76666665,  68.76666665,  69.76666665,  70.76666665,\n",
       "        71.76666665,  72.76666665,  73.76666665,  74.76666665,\n",
       "        75.76666665,  76.76666665,  77.76666665,  78.76666665,\n",
       "        79.76666665,  80.76666665,  81.76666665,  82.76666665,\n",
       "        83.76666665,  84.76666665,  85.76666665,  86.76666665,\n",
       "        87.76666665,  88.76666665,  89.76666665,  90.76666665,\n",
       "        91.76666665,  92.76666665,  93.76666665,  94.76666665,\n",
       "        95.76666665,  96.76666665,  97.76666665,  98.76666665,\n",
       "        99.76666665, 100.76666665, 101.76666665, 102.76666665,\n",
       "       103.76666665, 104.76666665, 105.76666665, 106.76666665,\n",
       "       107.76666665, 108.76666665, 109.76666665, 110.76666665,\n",
       "       111.76666665, 112.76666665, 113.76666665, 114.76666665,\n",
       "       115.76666665, 116.76666665, 117.76666665, 118.76666665,\n",
       "       119.76666665, 120.76666665, 121.76666665, 122.76666665,\n",
       "       123.76666665, 124.76666665, 125.76666665, 126.76666665,\n",
       "       127.76666665, 128.76666665, 129.76666665, 130.76666665,\n",
       "       131.76666665, 132.76666665, 133.76666665, 134.76666665,\n",
       "       135.76666665, 136.76666665, 137.76666665, 138.76666665,\n",
       "       139.76666665, 140.76666665, 141.76666665, 142.76666665,\n",
       "       143.76666665, 144.76666665, 145.76666665, 146.76666665,\n",
       "       147.76666665, 148.76666665, 149.76666665, 150.76666665,\n",
       "       151.76666665, 152.76666665, 153.76666665, 154.76666665,\n",
       "       155.76666665, 156.76666665, 157.76666665, 158.76666665,\n",
       "       159.76666665, 160.76666665, 161.76666665, 162.76666665,\n",
       "       163.76666665, 164.76666665, 165.76666665, 166.76666665,\n",
       "       167.76666665, 168.76666665, 169.76666665, 170.76666665,\n",
       "       171.76666665, 172.76666665, 173.76666665, 174.76666665,\n",
       "       175.76666665, 176.76666665, 177.76666665, 178.76666665,\n",
       "       179.76666665, 180.76666665, 181.76666665, 182.76666665,\n",
       "       183.76666665, 184.76666665, 185.76666665, 186.76666665,\n",
       "       187.76666665, 188.76666665, 189.76666665, 190.76666665,\n",
       "       191.76666665, 192.76666665, 193.76666665, 194.76666665,\n",
       "       195.76666665, 196.76666665, 197.76666665, 198.76666665,\n",
       "       199.76666665, 200.76666665, 201.76666665, 202.76666665,\n",
       "       203.76666665, 204.76666665, 205.76666665, 206.76666665,\n",
       "       207.76666665, 208.76666665, 209.76666665, 210.76666665,\n",
       "       211.76666665, 212.76666665, 213.76666665, 214.76666665,\n",
       "       215.76666665, 216.76666665, 217.76666665, 218.76666665,\n",
       "       219.76666665, 220.76666665, 221.76666665, 222.76666665,\n",
       "       223.76666665, 224.76666665, 225.76666665, 226.76666665,\n",
       "       227.76666665, 228.76666665, 229.76666665, 230.76666665,\n",
       "       231.76666665, 232.76666665, 233.76666665, 234.76666665,\n",
       "       235.76666665, 236.76666665, 237.76666665, 238.76666665,\n",
       "       239.76666665, 240.76666665, 241.76666665, 242.76666665,\n",
       "       243.76666665, 244.76666665, 245.76666665, 246.76666665,\n",
       "       247.76666665, 248.76666665, 249.76666665, 250.76666665,\n",
       "       251.76666665, 252.76666665, 253.76666665, 254.76666665,\n",
       "       255.76666665, 256.76666665, 257.76666665, 258.76666665,\n",
       "       259.76666665, 260.76666665, 261.76666665, 262.76666665,\n",
       "       263.76666665, 264.76666665, 265.76666665, 266.76666665,\n",
       "       267.76666665, 268.76666665, 269.76666665, 270.76666665,\n",
       "       271.76666665, 272.76666665, 273.76666665, 274.76666665,\n",
       "       275.76666665, 276.76666665, 277.76666665, 278.76666665,\n",
       "       279.76666665, 280.76666665, 281.76666665, 282.76666665,\n",
       "       283.76666665, 284.76666665, 285.76666665, 286.76666665,\n",
       "       287.76666665, 288.76666665, 289.76666665, 290.76666665,\n",
       "       291.76666665, 292.76666665, 293.76666665, 294.76666665,\n",
       "       295.76666665, 296.76666665, 297.76666665, 298.76666665,\n",
       "       299.76666665, 300.76666665, 301.76666665, 302.76666665,\n",
       "       303.76666665, 304.76666665, 305.76666665, 306.76666665,\n",
       "       307.76666665, 308.76666665, 309.76666665, 310.76666665,\n",
       "       311.76666665, 312.76666665, 313.76666665, 314.76666665,\n",
       "       315.76666665, 316.76666665, 317.76666665, 318.76666665,\n",
       "       319.76666665, 320.76666665, 321.76666665, 322.76666665,\n",
       "       323.76666665, 324.76666665, 325.76666665, 326.76666665,\n",
       "       327.76666665, 328.76666665, 329.76666665, 330.76666665,\n",
       "       331.76666665, 332.76666665, 333.76666665, 334.76666665,\n",
       "       335.76666665, 336.76666665])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(time_test.min(),time_test.max())\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.7666667,   5.5      ,   5.8333335,   7.8      ,   9.133333 ,\n",
       "        10.633333 ,  10.833333 ,  11.866667 ,  12.266666 ,  13.4      ,\n",
       "        14.7      ,  15.2      ,  16.566668 ,  16.6      ,  16.7      ,\n",
       "        17.666666 ,  17.833334 ,  18.266666 ,  18.833334 ,  20.2      ,\n",
       "        20.433332 ,  21.       ,  22.133333 ,  22.233334 ,  23.2      ,\n",
       "        23.8      ,  23.833334 ,  23.9      ,  23.933332 ,  24.633333 ,\n",
       "        24.866667 ,  25.233334 ,  25.433332 ,  25.633333 ,  26.333334 ,\n",
       "        27.466667 ,  27.866667 ,  28.566668 ,  28.833334 ,  29.066668 ,\n",
       "        29.3      ,  30.8      ,  31.166666 ,  32.066666 ,  32.733334 ,\n",
       "        32.833332 ,  32.866665 ,  33.133335 ,  34.3      ,  34.333332 ,\n",
       "        34.566666 ,  34.633335 ,  34.7      ,  34.766666 ,  35.       ,\n",
       "        35.2      ,  36.4      ,  36.633335 ,  37.       ,  37.5      ,\n",
       "        37.733334 ,  38.133335 ,  38.8      ,  41.466667 ,  41.833332 ,\n",
       "        42.633335 ,  42.666668 ,  42.9      ,  43.1      ,  43.2      ,\n",
       "        43.833332 ,  43.9      ,  44.733334 ,  45.166668 ,  45.6      ,\n",
       "        45.7      ,  45.733334 ,  46.066666 ,  46.366665 ,  46.666668 ,\n",
       "        47.033333 ,  47.433334 ,  48.133335 ,  48.433334 ,  48.533333 ,\n",
       "        49.533333 ,  49.566666 ,  49.766666 ,  50.533333 ,  50.766666 ,\n",
       "        51.7      ,  51.766666 ,  52.066666 ,  52.3      ,  52.5      ,\n",
       "        52.633335 ,  54.1      ,  55.833332 ,  56.333332 ,  56.766666 ,\n",
       "        58.133335 ,  58.933334 ,  59.7      ,  60.7      ,  61.1      ,\n",
       "        61.8      ,  61.9      ,  62.133335 ,  62.333332 ,  62.766666 ,\n",
       "        63.033333 ,  63.5      ,  63.833332 ,  63.866665 ,  64.6      ,\n",
       "        68.76667  ,  69.4      ,  69.8      ,  70.066666 ,  70.6      ,\n",
       "        71.6      ,  71.63333  ,  72.26667  ,  72.9      ,  73.13333  ,\n",
       "        73.46667  ,  74.46667  ,  76.23333  ,  78.166664 ,  78.6      ,\n",
       "        78.76667  ,  79.3      ,  80.433334 ,  80.5      ,  80.833336 ,\n",
       "        81.1      ,  81.13333  ,  82.63333  ,  83.53333  ,  85.13333  ,\n",
       "        85.73333  ,  85.86667  ,  86.066666 ,  86.23333  ,  87.       ,\n",
       "        88.46667  ,  88.933334 ,  89.36667  ,  89.9      ,  89.96667  ,\n",
       "        90.4      ,  93.36667  ,  94.23333  ,  94.933334 ,  95.833336 ,\n",
       "        96.2      ,  96.96667  ,  97.26667  ,  97.3      ,  98.76667  ,\n",
       "        98.833336 ,  99.36667  , 100.86667  , 101.066666 , 101.23333  ,\n",
       "       101.4      , 102.03333  , 102.066666 , 102.7      , 104.       ,\n",
       "       104.4      , 104.76667  , 105.2      , 105.96667  , 106.8      ,\n",
       "       107.066666 , 108.3      , 108.433334 , 111.1      , 111.36667  ,\n",
       "       111.6      , 112.       , 112.46667  , 112.8      , 112.933334 ,\n",
       "       113.433334 , 114.76667  , 114.9      , 115.6      , 115.63333  ,\n",
       "       117.03333  , 117.666664 , 117.76667  , 118.       , 118.3      ,\n",
       "       118.53333  , 119.       , 121.96667  , 122.13333  , 122.2      ,\n",
       "       122.7      , 123.26667  , 124.13333  , 124.566666 , 125.9      ,\n",
       "       126.666664 , 127.53333  , 127.833336 , 128.96666  , 129.23334  ,\n",
       "       129.33333  , 130.43333  , 130.9      , 131.06667  , 131.13333  ,\n",
       "       131.66667  , 134.26666  , 135.3      , 135.33333  , 136.       ,\n",
       "       136.06667  , 136.16667  , 137.8      , 138.33333  , 139.16667  ,\n",
       "       139.3      , 139.6      , 140.23334  , 140.5      , 140.6      ,\n",
       "       140.76666  , 142.43333  , 143.       , 143.53334  , 143.6      ,\n",
       "       144.46666  , 144.66667  , 144.96666  , 145.5      , 146.9      ,\n",
       "       146.93333  , 147.93333  , 149.4      , 149.7      , 149.76666  ,\n",
       "       149.86667  , 150.46666  , 152.3      , 152.33333  , 152.93333  ,\n",
       "       153.3      , 153.83333  , 153.9      , 154.       , 154.7      ,\n",
       "       162.83333  , 163.16667  , 163.4      , 164.03334  , 164.33333  ,\n",
       "       164.5      , 165.16667  , 168.7      , 168.96666  , 169.       ,\n",
       "       169.83333  , 170.8      , 171.3      , 174.5      , 174.83333  ,\n",
       "       175.16667  , 175.63333  , 175.9      , 176.1      , 176.36667  ,\n",
       "       176.5      , 177.63333  , 178.16667  , 178.4      , 180.73334  ,\n",
       "       182.33333  , 182.5      , 182.6      , 183.43333  , 184.8      ,\n",
       "       185.       , 186.2      , 186.53334  , 186.83333  , 187.03334  ,\n",
       "       187.93333  , 188.73334  , 190.2      , 191.46666  , 191.8      ,\n",
       "       191.93333  , 192.2      , 194.16667  , 195.36667  , 195.8      ,\n",
       "       195.86667  , 196.56667  , 196.86667  , 199.03334  , 199.36667  ,\n",
       "       199.93333  , 200.1      , 200.33333  , 201.16667  , 204.2      ,\n",
       "       205.6      , 205.9      , 206.13333  , 207.16667  , 208.96666  ,\n",
       "       211.53334  , 211.9      , 211.93333  , 212.2      , 214.43333  ,\n",
       "       215.16667  , 216.03334  , 217.56667  , 219.46666  , 220.3      ,\n",
       "       220.93333  , 221.6      , 222.33333  , 224.3      , 224.43333  ,\n",
       "       226.06667  , 227.46666  , 227.9      , 228.33333  , 229.06667  ,\n",
       "       229.33333  , 237.5      , 238.36667  , 239.3      , 241.6      ,\n",
       "       243.76666  , 248.76666  , 250.83333  , 251.63333  , 251.8      ,\n",
       "       252.       , 254.63333  , 255.1      , 258.13333  , 259.76666  ,\n",
       "       260.2      , 262.86667  , 263.7      , 266.1      , 267.26666  ,\n",
       "       267.4      , 268.43332  , 268.9      , 269.33334  , 269.63333  ,\n",
       "       271.86667  , 275.63333  , 278.36667  , 279.8      , 281.36667  ,\n",
       "       282.36667  , 285.7      , 297.8      , 307.93332  , 318.2      ,\n",
       "       330.36667  , 335.6      , 335.73334  , 337.03333  ], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(time_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time, new_event = transform_back(y_test)\n",
    "old_time, old_event = transform_back(y_train)\n",
    "cum_hazard_baseline_old_new = np.interp(np.unique(new_time), np.unique(old_time), cum_hazard_baseline_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(time).shape # should I take the unique one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.2666666507720947,
          2.299999952316284,
          4.866666793823242,
          5.833333492279053,
          6.833333492279053,
          7.866666793823242,
          10.866666793823242,
          11.066666603088379,
          11.300000190734863,
          14.100000381469727,
          15.300000190734863,
          15.366666793823242,
          16.566667556762695,
          17.133333206176758,
          17.200000762939453,
          19.100000381469727,
          19.566667556762695,
          20.133333206176758,
          20.433332443237305,
          20.66666603088379,
          21.299999237060547,
          21.566667556762695,
          21.600000381469727,
          22.46666717529297,
          23.03333282470703,
          23.766666412353516,
          23.933332443237305,
          24.299999237060547,
          24.399999618530273,
          25.46666717529297,
          27.399999618530273,
          27.46666717529297,
          28.5,
          28.733333587646484,
          28.83333396911621,
          28.866666793823242,
          30.866666793823242,
          31.33333396911621,
          31.46666717529297,
          33.96666717529297,
          34.099998474121094,
          34.33333206176758,
          34.43333435058594,
          34.63333511352539,
          34.766666412353516,
          36.266666412353516,
          36.400001525878906,
          36.43333435058594,
          36.63333511352539,
          37.36666488647461,
          37.733333587646484,
          37.79999923706055,
          37.86666488647461,
          38.16666793823242,
          39.29999923706055,
          40,
          40.43333435058594,
          40.63333511352539,
          42.66666793823242,
          43.099998474121094,
          44.766666412353516,
          45.16666793823242,
          45.599998474121094,
          46.43333435058594,
          48.13333511352539,
          48.53333282470703,
          49.53333282470703,
          49.56666564941406,
          51.20000076293945,
          51.766666412353516,
          52.29999923706055,
          53.63333511352539,
          55.233333587646484,
          56.266666412353516,
          56.5,
          57.233333587646484,
          57.66666793823242,
          58.46666717529297,
          58.63333511352539,
          59.766666412353516,
          59.96666717529297,
          60.900001525878906,
          61.46666717529297,
          61.599998474121094,
          62.53333282470703,
          62.79999923706055,
          63.96666717529297,
          64.23332977294922,
          64.86666870117188,
          65.13333129882812,
          65.33333587646484,
          65.46666717529297,
          65.56666564941406,
          67.46666717529297,
          68.16666412353516,
          68.69999694824219,
          69.30000305175781,
          70.4000015258789,
          70.73332977294922,
          71.5,
          71.5999984741211,
          71.63333129882812,
          71.76667022705078,
          71.80000305175781,
          72.43333435058594,
          72.66666412353516,
          73.69999694824219,
          74.46666717529297,
          74.93333435058594,
          75.0999984741211,
          76.13333129882812,
          77.23332977294922,
          78.16666412353516,
          79.96666717529297,
          80.36666870117188,
          82.36666870117188,
          83.13333129882812,
          84.83333587646484,
          85.4000015258789,
          85.56666564941406,
          85.73332977294922,
          86.9000015258789,
          87.69999694824219,
          88.19999694824219,
          88.83333587646484,
          89.5999984741211,
          89.80000305175781,
          90.13333129882812,
          90.56666564941406,
          90.66666412353516,
          91,
          91.5,
          91.73332977294922,
          92.83333587646484,
          93.5,
          93.66666412353516,
          94.23332977294922,
          96.19999694824219,
          96.23332977294922,
          97.56666564941406,
          97.5999984741211,
          97.83333587646484,
          98.69999694824219,
          99.23332977294922,
          99.33333587646484,
          99.36666870117188,
          99.73332977294922,
          99.96666717529297,
          101.23332977294922,
          102.03333282470703,
          102.06666564941406,
          102.5,
          102.63333129882812,
          103.0999984741211,
          103.13333129882812,
          105,
          107.36666870117188,
          107.76667022705078,
          108.06666564941406,
          108.46666717529297,
          110.0999984741211,
          110.5999984741211,
          110.93333435058594,
          110.96666717529297,
          111.06666564941406,
          111.0999984741211,
          111.19999694824219,
          111.5999984741211,
          112.80000305175781,
          112.93333435058594,
          112.96666717529297,
          113.06666564941406,
          113.66666412353516,
          114.03333282470703,
          114.23332977294922,
          114.5999984741211,
          114.76667022705078,
          114.9000015258789,
          115.63333129882812,
          115.93333435058594,
          117.53333282470703,
          117.76667022705078,
          118.19999694824219,
          118.53333282470703,
          118.9000015258789,
          119.30000305175781,
          119.36666870117188,
          120.13333129882812,
          120.43333435058594,
          122.76667022705078,
          123.33333587646484,
          123.73332977294922,
          124.76667022705078,
          125.03333282470703,
          125.86666870117188,
          126.4000015258789,
          127.93333435058594,
          128.36666870117188,
          128.39999389648438,
          128.6999969482422,
          128.96665954589844,
          129.8000030517578,
          130.36666870117188,
          131.3000030517578,
          132.1999969482422,
          132.76666259765625,
          133.23333740234375,
          133.73333740234375,
          135.3333282470703,
          136.46665954589844,
          139.60000610351562,
          140.56666564941406,
          142.1666717529297,
          142.6666717529297,
          143,
          143.1666717529297,
          144.46665954589844,
          144.96665954589844,
          145.73333740234375,
          146.73333740234375,
          147.8333282470703,
          148.03334045410156,
          148.76666259765625,
          148.86666870117188,
          149.39999389648438,
          149.86666870117188,
          150.46665954589844,
          151.1666717529297,
          151.1999969482422,
          152.93333435058594,
          153,
          153.89999389648438,
          153.96665954589844,
          156.8000030517578,
          157.43333435058594,
          157.53334045410156,
          160.39999389648438,
          161.13333129882812,
          161.6666717529297,
          161.76666259765625,
          161.93333435058594,
          163.1999969482422,
          163.86666870117188,
          164.03334045410156,
          164.3333282470703,
          164.60000610351562,
          164.93333435058594,
          165.1666717529297,
          165.43333435058594,
          167.10000610351562,
          167.43333435058594,
          167.93333435058594,
          168.3000030517578,
          168.3333282470703,
          168.60000610351562,
          169.8333282470703,
          170.8000030517578,
          172.96665954589844,
          173.8333282470703,
          173.93333435058594,
          174.26666259765625,
          174.63333129882812,
          175.10000610351562,
          175.63333129882812,
          176.06666564941406,
          179.43333435058594,
          179.8000030517578,
          180.73333740234375,
          180.76666259765625,
          181.46665954589844,
          183.1999969482422,
          183.26666259765625,
          184.76666259765625,
          185.76666259765625,
          186.53334045410156,
          186.60000610351562,
          186.63333129882812,
          186.8333282470703,
          187.03334045410156,
          187.6999969482422,
          187.8333282470703,
          188.36666870117188,
          188.73333740234375,
          189.03334045410156,
          189.73333740234375,
          191.1666717529297,
          193.89999389648438,
          194,
          194.1999969482422,
          194.60000610351562,
          195.8000030517578,
          195.86666870117188,
          196.46665954589844,
          196.86666870117188,
          197.3333282470703,
          199.23333740234375,
          199.26666259765625,
          200.3333282470703,
          200.60000610351562,
          201.46665954589844,
          202.23333740234375,
          203.53334045410156,
          205.60000610351562,
          205.8000030517578,
          205.89999389648438,
          207.46665954589844,
          208.1999969482422,
          208.8000030517578,
          208.96665954589844,
          210.43333435058594,
          211.13333129882812,
          211.73333740234375,
          213.03334045410156,
          213.36666870117188,
          216.03334045410156,
          216.73333740234375,
          218.23333740234375,
          219.10000610351562,
          219.63333129882812,
          225.5,
          227.93333435058594,
          228.60000610351562,
          228.8000030517578,
          229.3333282470703,
          231.53334045410156,
          234.23333740234375,
          234.53334045410156,
          234.6999969482422,
          236.93333435058594,
          237.13333129882812,
          237.26666259765625,
          238.36666870117188,
          239.1666717529297,
          240.1999969482422,
          241.26666259765625,
          241.3000030517578,
          242.56666564941406,
          243.76666259765625,
          243.89999389648438,
          250.13333129882812,
          253.06666564941406,
          254.26666259765625,
          255.10000610351562,
          255.26666259765625,
          256,
          256.5,
          257.76666259765625,
          258.1333312988281,
          259.9333190917969,
          259.9666748046875,
          260.0333251953125,
          261.20001220703125,
          262.6333312988281,
          263.0333251953125,
          264.76666259765625,
          267.3999938964844,
          270.4333190917969,
          272.20001220703125,
          274.3666687011719,
          278.3666687011719,
          285.4333190917969,
          286.0666809082031,
          307.9333190917969,
          335.73333740234375,
          351
         ],
         "xaxis": "x",
         "y": [
          0.0001929213641294889,
          0.0001929213641294889,
          0.0011044788580040993,
          0.0014464199107824926,
          0.0016291728375492241,
          0.0018013750779500477,
          0.003724882400997782,
          0.0037763562492372097,
          0.003836409194906543,
          0.005478868188237049,
          0.007737450925291968,
          0.007897978267282052,
          0.00989368251036327,
          0.011003667634620816,
          0.011019940525857188,
          0.012666152298414012,
          0.012973596085696046,
          0.014344569619821836,
          0.014474051721008671,
          0.014559096235859879,
          0.015447344288667661,
          0.015585565024604736,
          0.015602842245862265,
          0.01679754180350417,
          0.017253341107792503,
          0.018363840159045106,
          0.018783605261731052,
          0.01917415803263358,
          0.01925098279105191,
          0.02068162985307321,
          0.02323973194773185,
          0.023453905541636056,
          0.024713910372567323,
          0.025029945003185387,
          0.025083877847297712,
          0.025101855119107338,
          0.028542711189450867,
          0.02958393708583635,
          0.029768841112086584,
          0.032661906389616184,
          0.03273614591433793,
          0.03287537313225017,
          0.03295897374164943,
          0.033219221951902425,
          0.03401369076537438,
          0.036777483123227164,
          0.036928336977976275,
          0.03696606502401975,
          0.037343646033484626,
          0.03841977326887267,
          0.03868005938442357,
          0.03878464987053519,
          0.03893681920441729,
          0.04033542796807171,
          0.041926716309459856,
          0.04289888038607503,
          0.043020633265859136,
          0.043076826985129185,
          0.04747484333401561,
          0.04903302048911921,
          0.052549405816866575,
          0.05340559858127707,
          0.054265914675593566,
          0.05636915923863653,
          0.058834113439958646,
          0.05976996309292817,
          0.061640867106064326,
          0.06170436725431644,
          0.06471157169138764,
          0.06587306032259567,
          0.06677986352082804,
          0.06912657187196994,
          0.07123262109108178,
          0.0730481032125933,
          0.07335958072572436,
          0.07416160345978617,
          0.07523431970098916,
          0.07577320035118744,
          0.07590839196940652,
          0.0774004600062573,
          0.07767282193394474,
          0.07825856033605348,
          0.07849331492536182,
          0.07849331492536182,
          0.079870070801498,
          0.08014687068834074,
          0.08286683957827097,
          0.08293699317426866,
          0.08398458028929762,
          0.0843077280960838,
          0.08463124879916196,
          0.08482032332475778,
          0.08497165193695312,
          0.08614262296134068,
          0.0870555940713523,
          0.08773505114443042,
          0.08830792134862216,
          0.08912122430515174,
          0.08992955165386063,
          0.09067555965510875,
          0.09089529059279966,
          0.09096853423869664,
          0.09096853423869664,
          0.09096853423869664,
          0.09116508870402605,
          0.09155838512883958,
          0.09244601127985727,
          0.09333765005056602,
          0.09375528672623139,
          0.09385483731509234,
          0.0959097457158821,
          0.09634313065250416,
          0.09771633406789118,
          0.10064127113924942,
          0.10084817339099504,
          0.10519366875480923,
          0.10593500828277674,
          0.10906304936094079,
          0.11016168875126238,
          0.11022087689832454,
          0.11036884726597991,
          0.11324057423617444,
          0.11537621908852236,
          0.11543175536014344,
          0.11652017727343854,
          0.11879719819641739,
          0.11888209340794506,
          0.12001251428481337,
          0.12147018476367138,
          0.12175606655037813,
          0.12221361079859211,
          0.12324825810203933,
          0.12364052513931632,
          0.1252209524286728,
          0.12575805131532666,
          0.12584582718493814,
          0.12639041324109876,
          0.12828808692978064,
          0.12830125019352054,
          0.13079965676746422,
          0.13083569869198994,
          0.1310880725205913,
          0.13210261565833742,
          0.13319580682500753,
          0.13319580682500753,
          0.13319580682500753,
          0.1341129529701669,
          0.13449806113682933,
          0.13683084041730448,
          0.13802011871331069,
          0.13802011871331069,
          0.13877873618008496,
          0.13877873618008496,
          0.14002466478533554,
          0.14005018788969942,
          0.14438441579571112,
          0.14733175804318932,
          0.14733175804318932,
          0.14773099756417857,
          0.14821232637235227,
          0.15015888318354426,
          0.15015888318354426,
          0.1513916141798416,
          0.1513916141798416,
          0.1513916141798416,
          0.15152950159009848,
          0.15180527641061223,
          0.15263609203861306,
          0.155994642025539,
          0.155994642025539,
          0.155994642025539,
          0.155994642025539,
          0.155994642025539,
          0.15684618428225253,
          0.15684618428225253,
          0.1577027253565985,
          0.1577027253565985,
          0.15813357410201417,
          0.15856542807719373,
          0.15856542807719373,
          0.16071606945540243,
          0.16206791013077604,
          0.16384813633323203,
          0.16455616266013645,
          0.16504188005006315,
          0.16519143933534292,
          0.16541691225585714,
          0.16654783918087127,
          0.16654783918087127,
          0.16900543780874105,
          0.1707158376929118,
          0.1707158376929118,
          0.17349898261921018,
          0.17380685906975044,
          0.17718369784774152,
          0.17828887399693594,
          0.1798784232673188,
          0.18087362201844964,
          0.18087362201844964,
          0.18147570709489497,
          0.18167682143211766,
          0.18288675086259087,
          0.18288675086259087,
          0.18365186636917208,
          0.18493973098877417,
          0.18604189832027182,
          0.18618532745190472,
          0.18633899884169502,
          0.18755705337108836,
          0.18835927090212468,
          0.19080632388151342,
          0.1917318956878952,
          0.19452084246574552,
          0.19530706531196224,
          0.1956505026503697,
          0.1958794608759747,
          0.19761059712460455,
          0.19883118841807626,
          0.20054337406112935,
          0.20173554541057356,
          0.2041506045367409,
          0.2041506045367409,
          0.2058974460217832,
          0.20598499798057043,
          0.20644673800652147,
          0.2072185717392494,
          0.2078411893864171,
          0.21045482616809472,
          0.21048998859357407,
          0.21483227939695346,
          0.21483227939695346,
          0.21696373505979658,
          0.21729372600325988,
          0.2201232732272892,
          0.2201232732272892,
          0.2201232732272892,
          0.22559436743175343,
          0.22559436743175343,
          0.22559436743175343,
          0.22559436743175343,
          0.22559436743175343,
          0.22840625961285163,
          0.22856534667022993,
          0.22876421459512614,
          0.22912215137105396,
          0.22984169980502475,
          0.23020485347707126,
          0.23129535275971722,
          0.23202700398193699,
          0.23202700398193699,
          0.23202700398193699,
          0.23248573360610866,
          0.23360384917240432,
          0.23369728910827564,
          0.23425809985891718,
          0.23686458355400558,
          0.23957324145765843,
          0.2462167542311213,
          0.247723571974157,
          0.24788299781086343,
          0.24849279889639606,
          0.25003583136494323,
          0.2506119943106307,
          0.2506119943106307,
          0.25348117928717456,
          0.2589915546301971,
          0.2589915546301971,
          0.259429534063068,
          0.2595754826565056,
          0.2607443563708742,
          0.26252356528317516,
          0.26252356528317516,
          0.26344893447966955,
          0.26532739246617565,
          0.26644908351239033,
          0.26655631651964085,
          0.26660992075123513,
          0.26693161977298674,
          0.26725334333880046,
          0.2679414335070651,
          0.26817079689648665,
          0.26839216137016597,
          0.2695609959914439,
          0.2700844076564767,
          0.27020071840183696,
          0.27220625085326017,
          0.2762947815663579,
          0.27656309781202376,
          0.2784439868099519,
          0.27980857086296884,
          0.2828535629611012,
          0.2828535629611012,
          0.2828535629611012,
          0.2851100026627611,
          0.2851100026627611,
          0.2944324547033914,
          0.2944324547033914,
          0.29563669069556503,
          0.29563669069556503,
          0.2968714123276067,
          0.3031619856410024,
          0.30523805781949215,
          0.30834151725294356,
          0.3085621193653929,
          0.3088929972877734,
          0.31099735862739886,
          0.31234585156566064,
          0.31330594429325626,
          0.3137059493579444,
          0.3160198206150937,
          0.31744495030754954,
          0.3200104922963069,
          0.3240049991283927,
          0.32645721487269974,
          0.3303179202924005,
          0.331001123039887,
          0.3386287856985136,
          0.3417579850742902,
          0.3433382958984266,
          0.36238960059140085,
          0.37614896150340116,
          0.37944693209613506,
          0.3802377987856981,
          0.38210604508353935,
          0.38451529884198893,
          0.39461073908411626,
          0.398078248779199,
          0.398078248779199,
          0.4014439415950443,
          0.4023111445239052,
          0.4028892798098125,
          0.40790582773879697,
          0.40790582773879697,
          0.41056720557345133,
          0.41056720557345133,
          0.41056720557345133,
          0.4133203577524202,
          0.4144136189846296,
          0.41496024960073424,
          0.42838649986958227,
          0.446360887757565,
          0.4493349993421531,
          0.4531072091587519,
          0.4531072091587519,
          0.4543467017529894,
          0.45589609113759205,
          0.4578546181622782,
          0.46086955761468124,
          0.4611435745836387,
          0.4611435745836387,
          0.4611435745836387,
          0.4611435745836387,
          0.46444674646511963,
          0.46598825355775897,
          0.4819393530633957,
          0.49377851912987314,
          0.5077498579324945,
          0.5077498579324945,
          0.5077498579324945,
          0.5188587252936154,
          0.5804950939760198,
          0.5821150466058421,
          0.7189827691734102,
          0.8340230819287282,
          1.1507049200668695
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(x =np.unique(new_time), y = cum_hazard_baseline_old_new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cindex_train_METABRIC</th>\n",
       "      <th>cindex_test_METABRIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.606150</td>\n",
       "      <td>0.559541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.609315</td>\n",
       "      <td>0.611044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617208</td>\n",
       "      <td>0.608548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.446914</td>\n",
       "      <td>0.460198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643331</td>\n",
       "      <td>0.649819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cindex_train_METABRIC  cindex_test_METABRIC\n",
       "0               0.606150              0.559541\n",
       "1               0.609315              0.611044\n",
       "2               0.617208              0.608548\n",
       "3               0.446914              0.460198\n",
       "4               0.643331              0.649819"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.3 , 0.7 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([2,4,5,6,9,14])\n",
    "new_times = np.array([3,4,5])\n",
    "y = np.array([0.2,0.3,0.7,0.7,0.8,0.9])\n",
    "np.interp(new_times, t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4.2])\n",
    "b = np.array([2.5, 3.5, 4.5, 5.5, 6.5])\n",
    "\n",
    "closest_indices = np.abs(a[:, np.newaxis] - b).argmin(axis=1)\n",
    "\n",
    "print(closest_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5, 2.5, 3.5, 4.5, 5.5],\n",
       "       [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "       [0.5, 0.5, 1.5, 2.5, 3.5],\n",
       "       [1.5, 0.5, 0.5, 1.5, 2.5],\n",
       "       [2.5, 1.5, 0.5, 0.5, 1.5]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(a[:, np.newaxis] - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[closest_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EfronLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define models to apply\u001b[39;00m\n\u001b[1;32m      2\u001b[0m loss_functions \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbreslow_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mefron_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m#, 'deephit_loss'] #, 'cind_loss', 'aft_loss', 'efron_loss', 'aft_loss', 'ah_loss', 'deephit_loss'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m criterion_functions \u001b[39m=\u001b[39m [BreslowLoss, EfronLoss] \u001b[39m#, deephit_loss1_pycox] #, cind_loss, efron_likelihood, aft_likelihood, ah_likelihood, deephit_loss1_pycox\u001b[39;00m\n\u001b[1;32m      4\u001b[0m scoring_functions \u001b[39m=\u001b[39m [breslow_likelihood_torch, efron_likelihood_torch] \u001b[39m#, deephit_loss1_pycox] #, cind_loss, efron_likelihood, aft_likelihood, ah_likelihood, deephit_loss1_pycox]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m n_models \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(criterion_functions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EfronLoss' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define models to apply\n",
    "loss_functions = ['breslow_loss', 'efron_loss']#, 'deephit_loss'] #, 'cind_loss', 'aft_loss', 'efron_loss', 'aft_loss', 'ah_loss', 'deephit_loss'\n",
    "criterion_functions = [BreslowLoss, EfronLoss] #, deephit_loss1_pycox] #, cind_loss, efron_likelihood, aft_likelihood, ah_likelihood, deephit_loss1_pycox\n",
    "scoring_functions = [breslow_likelihood_torch, efron_likelihood_torch] #, deephit_loss1_pycox] #, cind_loss, efron_likelihood, aft_likelihood, ah_likelihood, deephit_loss1_pycox]\n",
    "\n",
    "n_models = len(criterion_functions)\n",
    "\n",
    "# dict of outer scores\n",
    "outer_scores = {'breslow_loss':[], 'efron_loss':[]} #, 'efron_loss':[],  'aft_loss':[], 'ah_loss':[], 'deephit_loss':[]#,'deephit_loss' 'cind_loss':[],'aft_loss':[]\n",
    "\n",
    "# Load dataset\n",
    "data, target = load_metabric(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X, y = load_metabric(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=False)\n",
    "\n",
    "# deephit data adaptation\n",
    "time, event = transform_back(target.to_numpy())\n",
    "data['time'] = time\n",
    "data['event'] = event\n",
    "df = discretizer_df(data, n_cuts=100, type = 'equidistant', min_time=0.0)\n",
    "\n",
    "y_deep = transform(df.time.to_numpy(), df.event.to_numpy())\n",
    "n = len(np.unique(np.absolute(y_deep)))\n",
    "y_deephit = np.tile(y_deep, (n,1)).T\n",
    "X_deephit = df.iloc[:,:-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "# example\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataframe\n",
    "df = pd.DataFrame({'age': [25, 30, 35],\n",
    "                   'income': [50000, 60000, 70000],\n",
    "                   'gender': ['male', 'female', 'male'],\n",
    "                   'is_married': [True, False, True],\n",
    "                   'num_children': [2, 0, 1],\n",
    "                   'target': [0, 1, 1]})\n",
    "\n",
    "# Select columns by data type\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "boolean_cols = df.select_dtypes(include=bool).columns\n",
    "\n",
    "# Define the feature mapper\n",
    "mapper = DataFrameMapper([\n",
    "    (numeric_cols, StandardScaler()),\n",
    "    (categorical_cols, OneHotEncoder()),\n",
    "    (boolean_cols, None)\n",
    "])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = make_pipeline(mapper, LogisticRegression())\n",
    "\n",
    "# Split the data into input features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Add your own code here\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        # Add your own code here\n",
    "        return X_transformed\n",
    "    \n",
    "ct = make_column_transformer(\n",
    "        [(StandardScaler(), make_column_selector(dtype_include=['float32'])), \n",
    "        (LabelBinarizer(), make_column_selector(dtype_include='bool'))],remainder='passthrough'\n",
    "        #(BoolToNumericTransformer(), make_column_selector(dtype_include=['bool']))\n",
    "        )\n",
    "\n",
    "data = load_rgbsg(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "X  = data.data\n",
    "X = ct.fit_transform(X)\n",
    "print(X.shape)\n",
    "np.savetxt('testX.csv',X,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
