{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "from xgbsurv.datasets import (load_metabric, load_flchain, load_rgbsg, load_support, load_tcga)\n",
    "from xgbsurv.models.utils import sort_X_y_pandas, transform_back, transform\n",
    "from xgbsurv.models.breslow_final import get_cumulative_hazard_function_breslow, breslow_estimator_loop\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.decomposition import PCA\n",
    "from loss_functions_pytorch import AFTLoss, aft_likelihood_torch\n",
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import EarlyStopping, Callback, LRScheduler\n",
    "from skorch.dataset import ValidSplit\n",
    "from pycox.evaluation import EvalSurv\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform\n",
    "import random\n",
    "import os\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters, put into function\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 1\n",
    "#n_iter_cind = 200\n",
    "early_stopping_rounds=15\n",
    "base_score = 0.0\n",
    "\n",
    "param_grid_aft = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    #'estimator__lr': scloguniform(0.001,0.01), # scheduler unten einbauen\n",
    "    # use callback instead\n",
    "    'estimator__lr':[0.01]\n",
    "    #'max_epochs':  scrandint(10,20), # corresponds to num_rounds\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    \"\"\"Sets all seeds within torch and adjacent libraries.\n",
    "\n",
    "    Args:\n",
    "        seed: Random seed to be used by the seeding functions.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "\n",
    "class FixSeed(Callback):\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "    def initialize(self):\n",
    "        seed_torch(self.seed)\n",
    "        return super().initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Scorer\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "\n",
    "        #y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, np.ndarray):\n",
    "            y_pred = torch.from_numpy(y_pred)\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "        if isinstance(y_pred, pd.Series):\n",
    "            y_pred = torch.tensor(y_pred.values)\n",
    "        if isinstance(y_true, pd.Series):\n",
    "            y_true = torch.tensor(y_true.values)\n",
    "        # change order of this later\n",
    "        score = aft_likelihood_torch(y_pred, y_true).to(torch.float32)\n",
    "        return score.numpy()\n",
    "\n",
    "scoring_function = make_scorer(custom_scoring_function, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Custom Splitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, n_layers, input_units, num_nodes, dropout, out_features):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.in_features = input_units\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dropout = dropout\n",
    "        self.out_features = out_features\n",
    "        model = []\n",
    "        # first layer\n",
    "        model.append(torch.nn.Linear(input_units, num_nodes))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout))\n",
    "        model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            model.append(torch.nn.Linear(num_nodes, num_nodes))\n",
    "            #init.kaiming_normal_(model[-1].weight, nonlinearity='relu')\n",
    "            model.append(torch.nn.ReLU())\n",
    "            model.append(torch.nn.Dropout(dropout))\n",
    "            model.append(torch.nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "        # output layer\n",
    "        model.append(torch.nn.Linear(num_nodes, out_features))\n",
    "    \n",
    "        self.layers = nn.Sequential(*model)\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     if isinstance(layer, nn.Linear):\n",
    "        #         #nn.init.uniform_(layer.weight, a=-0.5, b=0.5)\n",
    "        #         nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.to(torch.float32)\n",
    "        res = self.layers(X)\n",
    "        #print(res)\n",
    "        return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStandardScaler(StandardScaler):\n",
    "    \n",
    "    def __init__(self, copy=True, with_mean=True, with_std=True):\n",
    "        super().__init__(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = super().transform(X, y)\n",
    "        return X_transformed.astype(np.float32)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        return X_transformed.astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stratified inner k-fold cross-validation\n",
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        print('split', X.dtypes)\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "inner_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "        model = '_aft_'\n",
    "        dataset_name = filename.split('_')[0]\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                        'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        ct = make_column_transformer(\n",
    "                #(OneHotEncoder(sparse_output=False), make_column_selector(dtype_include=['category', 'object']))\n",
    "                (StandardScaler(), make_column_selector(dtype_include=['float32'], dtype_exclude=['category', 'object', 'int']))\n",
    "                ,remainder='passthrough')\n",
    "\n",
    "        pipe = Pipeline([('scaler',ct),\n",
    "                        ('estimator', net)])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_aft, scoring = scoring_function, n_jobs=-1, \n",
    "                                    n_iter=2, refit=True)\n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "                X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "                print(X_train.shape, type(X_train))\n",
    "                print(y_train.shape, type(y_train))\n",
    "                print(X_test.shape, type(X_test))\n",
    "                print(y_test.shape, type(y_test))\n",
    "                # save splits and data\n",
    "                savetxt('splits/train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                #savetxt('splits/X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                #savetxt('splits/X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                #savetxt('splits/y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                #savetxt('splits/y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "                strat = np.sign(y_train)\n",
    "                valid_split = ValidSplit(cv=0.1, stratified=strat, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                rs.fit(X_train, y_train)\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        # df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_best_settings = pd.concat([df_best_params,df_best_model])\n",
    "        df_best_settings.to_csv('metrics/'+model+'metric_summary_'+filename, index=False)\n",
    "\n",
    "        return df_best_settings\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_metabric\n",
      "split MKI67                float32\n",
      "EGFR                 float32\n",
      "PGR                  float32\n",
      "ERBB2                float32\n",
      "hormone_treatment      uint8\n",
      "radiotherapy           uint8\n",
      "chemotherapy           uint8\n",
      "ER_positive            uint8\n",
      "age                  float32\n",
      "dtype: object\n",
      "(1522, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(1522,) <class 'pandas.core.series.Series'>\n",
      "(381, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(381,) <class 'pandas.core.series.Series'>\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2717\u001b[0m        \u001b[32m3.0177\u001b[0m  0.1014\n",
      "  epoch    train_loss    valid_loss     dur  epoch    train_loss    valid_loss     dur\n",
      "\n",
      "-------  ------------  ------------  ------\n",
      "-------  ------------  ------------  ------      1        \u001b[36m2.8383\u001b[0m        \u001b[32m2.7725\u001b[0m  0.0989\n",
      "\n",
      "      1        \u001b[36m3.2536\u001b[0m        \u001b[32m2.9432\u001b[0m  0.0974\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.0511\u001b[0m        \u001b[32m2.9934\u001b[0m  0.1036\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2496\u001b[0m        \u001b[32m2.9338\u001b[0m  0.1041\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.8888\u001b[0m        \u001b[32m2.7712\u001b[0m  0.1132\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2645\u001b[0m        \u001b[32m2.9767\u001b[0m  0.1186\n",
      "      2        \u001b[36m2.7723\u001b[0m        \u001b[32m2.7541\u001b[0m  0.0207\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.0817\u001b[0m        \u001b[32m3.0149\u001b[0m  0.1232\n",
      "      2        \u001b[36m3.1709\u001b[0m        2.9468  0.0212\n",
      "      2        \u001b[36m2.9976\u001b[0m        \u001b[32m2.9798\u001b[0m  0.0217\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.3084\u001b[0m        \u001b[32m3.0490\u001b[0m  0.1249\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2888\u001b[0m        \u001b[32m2.9767\u001b[0m  0.1252\n",
      "      2        \u001b[36m3.1851\u001b[0m        3.0192  0.0336\n",
      "      2        \u001b[36m3.1985\u001b[0m        2.9662  0.0381\n",
      "      3        \u001b[36m2.7259\u001b[0m        2.7700  0.0215\n",
      "      3        \u001b[36m2.9837\u001b[0m        \u001b[32m2.9780\u001b[0m  0.0227\n",
      "      3        \u001b[36m3.1553\u001b[0m        \u001b[32m2.9308\u001b[0m  0.0261\n",
      "      3        \u001b[36m3.1662\u001b[0m        \u001b[32m3.0126\u001b[0m  0.0293\n",
      "      2        \u001b[36m3.0381\u001b[0m        \u001b[32m2.9763\u001b[0m  0.0408\n",
      "      4        \u001b[36m2.6971\u001b[0m        2.7605  0.0202\n",
      "      2        \u001b[36m3.1952\u001b[0m        \u001b[32m3.0315\u001b[0m  0.0418\n",
      "      3        \u001b[36m3.1674\u001b[0m        2.9443  0.0280\n",
      "      2        \u001b[36m3.1812\u001b[0m        \u001b[32m2.9597\u001b[0m  0.0511\n",
      "      2        \u001b[36m2.7687\u001b[0m        2.7996  0.0571\n",
      "      4        \u001b[36m3.1370\u001b[0m        2.9330  0.0220\n",
      "      4        \u001b[36m2.9591\u001b[0m        \u001b[32m2.9612\u001b[0m  0.0248\n",
      "      2        \u001b[36m3.2071\u001b[0m        \u001b[32m2.9616\u001b[0m  0.0488\n",
      "      4        \u001b[36m3.1549\u001b[0m        3.0136  0.0233\n",
      "      4        \u001b[36m3.1470\u001b[0m        2.9436  0.0243\n",
      "      5        2.7018        2.7715  0.0267\n",
      "      5        \u001b[36m3.1133\u001b[0m        2.9405  0.0205\n",
      "      5        2.9602        2.9657  0.0265\n",
      "      3        \u001b[36m2.7239\u001b[0m        \u001b[32m2.7534\u001b[0m  0.0389\n",
      "      3        \u001b[36m3.1365\u001b[0m        \u001b[32m2.9531\u001b[0m  0.0404\n",
      "      3        \u001b[36m2.9885\u001b[0m        \u001b[32m2.9603\u001b[0m  0.0462\n",
      "      5        \u001b[36m3.1373\u001b[0m        2.9530  0.0203\n",
      "      6        3.1211        2.9517  0.0204\n",
      "      6        \u001b[36m2.6748\u001b[0m        2.7697  0.0265\n",
      "      6        \u001b[36m2.9473\u001b[0m        2.9658  0.0213\n",
      "      5        \u001b[36m3.1462\u001b[0m        3.0210  0.0355\n",
      "      3        \u001b[36m3.1593\u001b[0m        \u001b[32m3.0180\u001b[0m  0.0532\n",
      "      3        \u001b[36m3.1598\u001b[0m        \u001b[32m2.9393\u001b[0m  0.0529\n",
      "      7        \u001b[36m3.1071\u001b[0m        2.9572  0.0220\n",
      "      6        \u001b[36m3.1324\u001b[0m        2.9510  0.0291\n",
      "      7        2.9511        \u001b[32m2.9596\u001b[0m  0.0200\n",
      "      7        2.6909        2.7949  0.0260\n",
      "      4        \u001b[36m3.1073\u001b[0m        \u001b[32m2.9414\u001b[0m  0.0393\n",
      "      4        \u001b[36m2.6994\u001b[0m        2.7774  0.0429\n",
      "      6        \u001b[36m3.1363\u001b[0m        3.0283  0.0306\n",
      "      4        \u001b[36m2.9596\u001b[0m        2.9645  0.0429\n",
      "      8        \u001b[36m3.1023\u001b[0m        2.9489  0.0205\n",
      "      8        2.9551        2.9652  0.0200\n",
      "      7        3.1337        2.9747  0.0208\n",
      "      4        \u001b[36m3.1403\u001b[0m        \u001b[32m3.0104\u001b[0m  0.0450\n",
      "      8        2.6842        2.7836  0.0274\n",
      "      4        \u001b[36m3.1458\u001b[0m        2.9790  0.0470\n",
      "      7        3.1408        3.0207  0.0285\n",
      "      8        \u001b[36m3.1062\u001b[0m        2.9741  0.0207\n",
      "      9        \u001b[36m3.1007\u001b[0m        2.9512  0.0275\n",
      "      9        2.9474        2.9662  0.0242\n",
      "      5        3.1175        3.0092  0.0460\n",
      "      5        \u001b[36m2.6874\u001b[0m        2.8029  0.0458\n",
      "      9        \u001b[36m2.6721\u001b[0m        2.7800  0.0273\n",
      "      5        \u001b[36m2.9477\u001b[0m        \u001b[32m2.9547\u001b[0m  0.0452\n",
      "      9        3.1138        2.9707  0.0204\n",
      "     10        \u001b[36m3.0824\u001b[0m        2.9472  0.0209\n",
      "Restoring best model from epoch 3.\n",
      "      5        \u001b[36m3.1183\u001b[0m        2.9809  0.0390\n",
      "      8        \u001b[36m3.1249\u001b[0m        3.0147  0.0317\n",
      "     10        \u001b[36m2.9309\u001b[0m        2.9671  0.0285\n",
      "Restoring best model from epoch 7.\n",
      "      5        \u001b[36m3.1189\u001b[0m        3.0325  0.0471\n",
      "     10        \u001b[36m2.6663\u001b[0m        2.7817  0.0198\n",
      "Restoring best model from epoch 2.\n",
      "     10        \u001b[36m3.1039\u001b[0m        2.9694  0.0206\n",
      "Restoring best model from epoch 1.\n",
      "      9        3.1281        3.0251  0.0319\n",
      "      6        \u001b[36m2.6641\u001b[0m        2.7956  0.0500\n",
      "      6        3.1080        \u001b[32m2.9379\u001b[0m  0.0520\n",
      "      6        2.9562        2.9738  0.0496\n",
      "      6        \u001b[36m3.1072\u001b[0m        2.9445  0.0413\n",
      "     10        \u001b[36m3.1143\u001b[0m        3.0223  0.0231\n",
      "Restoring best model from epoch 3.\n",
      "      6        3.1312        3.0188  0.0584\n",
      "      7        \u001b[36m2.6617\u001b[0m        2.7864  0.0392\n",
      "      7        \u001b[36m3.0942\u001b[0m        2.9636  0.0422\n",
      "      7        \u001b[36m2.9165\u001b[0m        2.9660  0.0472\n",
      "      7        \u001b[36m3.0858\u001b[0m        3.0100  0.0441\n",
      "      7        \u001b[36m3.1059\u001b[0m        3.0329  0.0409\n",
      "      8        \u001b[36m2.6382\u001b[0m        2.8298  0.0390\n",
      "      8        \u001b[36m3.0754\u001b[0m        2.9439  0.0401\n",
      "      8        2.9272        3.0068  0.0397\n",
      "      8        \u001b[36m3.0753\u001b[0m        2.9926  0.0403\n",
      "      8        \u001b[36m3.0999\u001b[0m        3.0422  0.0400\n",
      "      9        \u001b[36m2.6290\u001b[0m        2.8061  0.0389\n",
      "      9        \u001b[36m3.0628\u001b[0m        2.9691  0.0397\n",
      "      9        \u001b[36m2.9114\u001b[0m        3.0211  0.0392\n",
      "      9        3.0859        2.9786  0.0393\n",
      "      9        \u001b[36m3.0929\u001b[0m        3.0418  0.0400\n",
      "     10        \u001b[36m2.6108\u001b[0m        2.8031  0.0385\n",
      "Restoring best model from epoch 3.\n",
      "     10        \u001b[36m3.0559\u001b[0m        2.9839  0.0398\n",
      "Restoring best model from epoch 6.\n",
      "     10        2.9122        3.0335  0.0387\n",
      "Restoring best model from epoch 5.\n",
      "     10        \u001b[36m3.0684\u001b[0m        2.9801  0.0397\n",
      "Restoring best model from epoch 3.\n",
      "     10        \u001b[36m3.0802\u001b[0m        3.0308  0.0429\n",
      "Restoring best model from epoch 4.\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1128\u001b[0m        \u001b[32m3.2313\u001b[0m  0.0321\n",
      "      2        \u001b[36m3.0439\u001b[0m        3.2431  0.0269\n",
      "      3        \u001b[36m3.0086\u001b[0m        \u001b[32m3.2142\u001b[0m  0.0267\n",
      "      4        3.0092        3.2299  0.0266\n",
      "      5        \u001b[36m2.9942\u001b[0m        \u001b[32m3.2105\u001b[0m  0.0260\n",
      "      6        \u001b[36m2.9864\u001b[0m        3.2214  0.0270\n",
      "      7        3.0021        \u001b[32m3.2056\u001b[0m  0.0260\n",
      "      8        2.9998        \u001b[32m3.2056\u001b[0m  0.0256\n",
      "      9        \u001b[36m2.9804\u001b[0m        \u001b[32m3.2036\u001b[0m  0.0281\n",
      "     10        2.9822        3.2160  0.0264\n",
      "Restoring best model from epoch 9.\n",
      "(1522, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(1522,) <class 'pandas.core.series.Series'>\n",
      "(381, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(381,) <class 'pandas.core.series.Series'>\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5977\u001b[0m  0.0038\n",
      "      2        2.5977  0.0039\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0165\u001b[0m  0.0045\n",
      "      3        2.5977  0.0035\n",
      "      2        3.0165  0.0038\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4154\u001b[0m  0.0048\n",
      "      4        2.5977  0.0041\n",
      "      3        3.0165  0.0037\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4656\u001b[0m  0.0044\n",
      "      5        2.5977  0.0036\n",
      "      4        3.0165  0.0040\n",
      "      2        3.4154  0.0070\n",
      "      2        3.4656  0.0045\n",
      "      5        3.0165  0.0038\n",
      "      6        2.5977  0.0043\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4675\u001b[0m  0.0044\n",
      "      3        3.4154  0.0051\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1147\u001b[0m        \u001b[32m2.9936\u001b[0m  0.0457\n",
      "      3        3.4656  0.0041\n",
      "      6        3.0165  0.0045\n",
      "      2        3.4675  0.0042\n",
      "      7        2.5977  0.0054\n",
      "      4        3.4154  0.0041\n",
      "      4        3.4656  0.0046\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1487\u001b[0m        \u001b[32m3.4272\u001b[0m  0.0419\n",
      "      7        3.0165  0.0040\n",
      "      3        3.4675  0.0041\n",
      "      8        2.5977  0.0036\n",
      "      5        3.4154  0.0040\n",
      "      5        3.4656  0.0041\n",
      "      8        3.0165  0.0037\n",
      "      4        3.4675  0.0043\n",
      "      9        2.5977  0.0036\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2162\u001b[0m        \u001b[32m3.4530\u001b[0m  0.0430\n",
      "      6        3.4154  0.0039\n",
      "     10        2.5977  0.0035\n",
      "Restoring best model from epoch 1.\n",
      "      5        3.4675  0.0041\n",
      "      9        3.0165  0.0052\n",
      "      6        3.4656  0.0053\n",
      "      7        3.4154  0.0039\n",
      "      6        3.4675  0.0041\n",
      "     10        3.0165  0.0041\n",
      "Restoring best model from epoch 1.\n",
      "      8        3.4154  0.0039\n",
      "      7        3.4656  0.0049\n",
      "      7        3.4675  0.0042\n",
      "      8        3.4656  0.0044\n",
      "      9        3.4154  0.0052\n",
      "      8        3.4675  0.0041\n",
      "      9        3.4656  0.0043\n",
      "     10        3.4154  0.0041\n",
      "Restoring best model from epoch 1.\n",
      "      9        3.4675  0.0043\n",
      "     10        3.4656  0.0041\n",
      "Restoring best model from epoch 1.\n",
      "     10        3.4675  0.0042\n",
      "Restoring best model from epoch 1.\n",
      "      2        \u001b[36m3.0533\u001b[0m        2.9975  0.0466\n",
      "      2        \u001b[36m3.1224\u001b[0m        3.4362  0.0454\n",
      "      2        \u001b[36m3.1519\u001b[0m        3.4587  0.0422\n",
      "      3        \u001b[36m3.0247\u001b[0m        3.0007  0.0437\n",
      "      3        \u001b[36m3.0650\u001b[0m        3.4687  0.0434\n",
      "      3        \u001b[36m3.1064\u001b[0m        3.4718  0.0429\n",
      "      4        \u001b[36m2.9963\u001b[0m        2.9958  0.0422\n",
      "      4        \u001b[36m3.0609\u001b[0m        3.4644  0.0421\n",
      "      4        3.1197        \u001b[32m3.4435\u001b[0m  0.0434\n",
      "      5        3.0098        3.0342  0.0409\n",
      "      5        \u001b[36m3.0589\u001b[0m        3.4377  0.0404\n",
      "      5        \u001b[36m3.0721\u001b[0m        3.4773  0.0410\n",
      "      6        3.0193        2.9976  0.0414\n",
      "      6        \u001b[36m3.0453\u001b[0m        3.4468  0.0418\n",
      "      6        3.0933        3.4744  0.0432\n",
      "      7        \u001b[36m2.9829\u001b[0m        2.9940  0.0402\n",
      "      7        \u001b[36m3.0357\u001b[0m        3.4369  0.0421\n",
      "      7        \u001b[36m3.0616\u001b[0m        3.4679  0.0422\n",
      "      8        2.9869        \u001b[32m2.9902\u001b[0m  0.0399\n",
      "      8        3.0376        3.4340  0.0425\n",
      "      8        3.0840        3.4741  0.0423\n",
      "      9        2.9831        \u001b[32m2.9856\u001b[0m  0.0404\n",
      "      9        3.0361        3.4332  0.0405\n",
      "      9        3.0724        3.4839  0.0411\n",
      "     10        2.9840        \u001b[32m2.9819\u001b[0m  0.0404\n",
      "     10        \u001b[36m3.0183\u001b[0m        3.4321  0.0410\n",
      "Restoring best model from epoch 1.\n",
      "     10        \u001b[36m3.0538\u001b[0m        3.4778  0.0418\n",
      "Restoring best model from epoch 4.\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.9979\u001b[0m        \u001b[32m2.6152\u001b[0m  0.0414\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1648\u001b[0m        \u001b[32m3.3975\u001b[0m  0.0459\n",
      "      2        \u001b[36m2.9012\u001b[0m        \u001b[32m2.6054\u001b[0m  0.0392\n",
      "      2        \u001b[36m3.1170\u001b[0m        \u001b[32m3.3715\u001b[0m  0.0405\n",
      "      3        \u001b[36m2.8709\u001b[0m        \u001b[32m2.5800\u001b[0m  0.0394\n",
      "      3        \u001b[36m3.0638\u001b[0m        3.3918  0.0390\n",
      "      4        \u001b[36m2.8488\u001b[0m        2.5803  0.0402\n",
      "      4        \u001b[36m3.0631\u001b[0m        \u001b[32m3.3572\u001b[0m  0.0384\n",
      "      5        \u001b[36m2.8419\u001b[0m        \u001b[32m2.5766\u001b[0m  0.0392\n",
      "      5        \u001b[36m3.0512\u001b[0m        3.3707  0.0393\n",
      "      6        2.8576        2.5941  0.0380\n",
      "      6        3.0563        \u001b[32m3.3540\u001b[0m  0.0393\n",
      "      7        \u001b[36m2.8291\u001b[0m        \u001b[32m2.5742\u001b[0m  0.0387\n",
      "      7        \u001b[36m3.0399\u001b[0m        \u001b[32m3.3481\u001b[0m  0.0401\n",
      "      8        2.8298        \u001b[32m2.5554\u001b[0m  0.0389\n",
      "      8        3.0499        \u001b[32m3.3433\u001b[0m  0.0388\n",
      "      9        \u001b[36m2.8197\u001b[0m        2.5749  0.0379\n",
      "      9        \u001b[36m3.0269\u001b[0m        3.3507  0.0399\n",
      "     10        2.8217        2.5690  0.0379\n",
      "Restoring best model from epoch 8.\n",
      "     10        3.0324        3.3548  0.0396\n",
      "Restoring best model from epoch 8.\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1993\u001b[0m        \u001b[32m3.1562\u001b[0m  0.0406\n",
      "      2        3.4516        \u001b[32m3.1402\u001b[0m  0.0316\n",
      "      3        3.3271        \u001b[32m3.1331\u001b[0m  0.0260\n",
      "      4        \u001b[36m3.1493\u001b[0m        3.1398  0.0284\n",
      "      5        \u001b[36m3.0370\u001b[0m        3.1555  0.0266\n",
      "      6        \u001b[36m3.0368\u001b[0m        3.1638  0.0275\n",
      "      7        3.0664        3.1597  0.0305\n",
      "      8        3.0595        3.1483  0.0276\n",
      "      9        3.0376        3.1368  0.0236\n",
      "     10        \u001b[36m3.0097\u001b[0m        3.1345  0.0280\n",
      "Restoring best model from epoch 3.\n",
      "(1522, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(1522,) <class 'pandas.core.series.Series'>\n",
      "(381, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(381,) <class 'pandas.core.series.Series'>\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6267\u001b[0m  0.0041\n",
      "      2        2.6267  0.0037\n",
      "      3        2.6267  0.0036\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.9729\u001b[0m  0.0044\n",
      "      4        2.6267  0.0035\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.3771\u001b[0m  0.0045\n",
      "      5        2.6267  0.0035\n",
      "      2        2.9729  0.0038\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.3291\u001b[0m  0.0042\n",
      "      2        3.3771  0.0041\n",
      "      6        2.6267  0.0035\n",
      "      3        2.9729  0.0037\n",
      "      2        3.3291  0.0039\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1090\u001b[0m        \u001b[32m2.9631\u001b[0m  0.0452\n",
      "      7        2.6267  0.0035\n",
      "      4        2.9729  0.0036\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1827\u001b[0m        \u001b[32m3.3325\u001b[0m  0.0426\n",
      "      3        3.3291  0.0039\n",
      "      3        3.3771  0.0064\n",
      "      8        2.6267  0.0035\n",
      "      5        2.9729  0.0037\n",
      "      4        3.3291  0.0039\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.9327\u001b[0m        \u001b[32m2.6415\u001b[0m  0.0560\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1930\u001b[0m        \u001b[32m3.2869\u001b[0m  0.0431\n",
      "      9        2.6267  0.0035\n",
      "      6        2.9729  0.0036\n",
      "      5        3.3291  0.0040\n",
      "      4        3.3771  0.0080\n",
      "     10        2.6267  0.0035\n",
      "Restoring best model from epoch 1.\n",
      "      7        2.9729  0.0036\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.5725\u001b[0m  0.0045\n",
      "      6        3.3291  0.0038\n",
      "      5        3.3771  0.0041\n",
      "      7        3.3291  0.0039\n",
      "      6        3.3771  0.0040\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2063\u001b[0m        \u001b[32m3.5560\u001b[0m  0.0500\n",
      "      8        2.9729  0.0084\n",
      "      2        3.5725  0.0079\n",
      "      8        3.3291  0.0039\n",
      "      7        3.3771  0.0040\n",
      "      9        2.9729  0.0038\n",
      "      9        3.3291  0.0038\n",
      "      8        3.3771  0.0039\n",
      "     10        2.9729  0.0037\n",
      "Restoring best model from epoch 1.\n",
      "     10        3.3291  0.0038\n",
      "Restoring best model from epoch 1.      3        3.5725  0.0083\n",
      "\n",
      "      9        3.3771  0.0049\n",
      "      4        3.5725  0.0045\n",
      "     10        3.3771  0.0041\n",
      "Restoring best model from epoch 1.\n",
      "      5        3.5725  0.0043\n",
      "      2        \u001b[36m3.0182\u001b[0m        \u001b[32m2.9490\u001b[0m  0.0416\n",
      "      6        3.5725  0.0042\n",
      "      7        3.5725  0.0042\n",
      "      2        \u001b[36m3.0957\u001b[0m        \u001b[32m3.2377\u001b[0m  0.0438\n",
      "      2        \u001b[36m3.1188\u001b[0m        \u001b[32m3.2915\u001b[0m  0.0486\n",
      "      8        3.5725  0.0047\n",
      "      2        \u001b[36m2.8540\u001b[0m        \u001b[32m2.6326\u001b[0m  0.0468\n",
      "      9        3.5725  0.0042\n",
      "     10        3.5725  0.0044\n",
      "Restoring best model from epoch 1.\n",
      "      2        \u001b[36m3.0970\u001b[0m        \u001b[32m3.5328\u001b[0m  0.0441\n",
      "      3        \u001b[36m2.9823\u001b[0m        \u001b[32m2.9275\u001b[0m  0.0423\n",
      "      3        \u001b[36m3.0829\u001b[0m        3.2406  0.0438\n",
      "      3        \u001b[36m2.8188\u001b[0m        2.6413  0.0420\n",
      "      3        \u001b[36m3.0820\u001b[0m        \u001b[32m3.2679\u001b[0m  0.0439\n",
      "      3        \u001b[36m3.0772\u001b[0m        \u001b[32m3.5208\u001b[0m  0.0424\n",
      "      4        2.9937        2.9490  0.0424\n",
      "      4        \u001b[36m2.8097\u001b[0m        2.6460  0.0419\n",
      "      4        \u001b[36m3.0555\u001b[0m        3.2800  0.0427\n",
      "      4        \u001b[36m3.0706\u001b[0m        3.3024  0.0420\n",
      "      4        \u001b[36m3.0642\u001b[0m        3.5481  0.0413\n",
      "      5        \u001b[36m2.9640\u001b[0m        2.9421  0.0415\n",
      "      5        \u001b[36m2.7875\u001b[0m        \u001b[32m2.6266\u001b[0m  0.0411\n",
      "      5        \u001b[36m3.0579\u001b[0m        3.2895  0.0419\n",
      "      5        \u001b[36m3.0454\u001b[0m        3.2722  0.0423\n",
      "      5        \u001b[36m3.0432\u001b[0m        3.5721  0.0417\n",
      "      6        2.9698        2.9401  0.0410\n",
      "      6        2.7914        \u001b[32m2.6214\u001b[0m  0.0404\n",
      "      6        \u001b[36m3.0533\u001b[0m        3.3092  0.0412\n",
      "      6        3.0527        3.2591  0.0416\n",
      "      6        3.0502        3.5357  0.0419\n",
      "      7        \u001b[36m2.9515\u001b[0m        2.9569  0.0415\n",
      "      7        \u001b[36m2.7693\u001b[0m        2.6304  0.0408\n",
      "      7        \u001b[36m3.0485\u001b[0m        3.2954  0.0410\n",
      "      7        \u001b[36m3.0380\u001b[0m        3.2455  0.0411\n",
      "      7        \u001b[36m3.0386\u001b[0m        3.5503  0.0432\n",
      "      8        \u001b[36m2.9482\u001b[0m        2.9605  0.0419\n",
      "      8        \u001b[36m2.7646\u001b[0m        2.6419  0.0412\n",
      "      8        \u001b[36m3.0334\u001b[0m        3.3042  0.0411\n",
      "      8        \u001b[36m3.0127\u001b[0m        3.2515  0.0423\n",
      "      8        \u001b[36m3.0200\u001b[0m        3.5552  0.0414\n",
      "      9        2.9618        2.9471  0.0408\n",
      "      9        \u001b[36m2.7625\u001b[0m        2.6360  0.0404\n",
      "      9        \u001b[36m3.0136\u001b[0m        3.3179  0.0415\n",
      "      9        3.0250        3.2479  0.0418\n",
      "      9        3.0265        3.5443  0.0415\n",
      "     10        \u001b[36m2.9453\u001b[0m        2.9462  0.0407\n",
      "Restoring best model from epoch 3.\n",
      "     10        2.7724        2.6373  0.0403\n",
      "Restoring best model from epoch 6.\n",
      "     10        3.0188        3.3119  0.0405\n",
      "Restoring best model from epoch 3.\n",
      "     10        3.0135        3.2478  0.0423\n",
      "Restoring best model from epoch 2.\n",
      "     10        3.0246        3.5345  0.0404\n",
      "Restoring best model from epoch 3.\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2351\u001b[0m        \u001b[32m3.0110\u001b[0m  0.0249\n",
      "      2        3.4770        \u001b[32m2.9977\u001b[0m  0.0262\n",
      "      3        3.3520        3.0011  0.0273\n",
      "      4        \u001b[36m3.1673\u001b[0m        3.0170  0.0296\n",
      "      5        \u001b[36m3.0521\u001b[0m        3.0355  0.0249\n",
      "      6        3.0592        3.0415  0.0258\n",
      "      7        3.0901        3.0357  0.0230\n",
      "      8        3.0770        3.0233  0.0259\n",
      "      9        3.0582        3.0209  0.0256\n",
      "     10        3.0568        3.0181  0.0258\n",
      "Restoring best model from epoch 2.\n",
      "(1523, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(1523,) <class 'pandas.core.series.Series'>\n",
      "(380, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(380,) <class 'pandas.core.series.Series'>\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.7628\u001b[0m  0.0040\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0177\u001b[0m  0.0041\n",
      "      2        2.7628  0.0051\n",
      "      3        2.7628  0.0036\n",
      "      2        3.0177  0.0049\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.8257\u001b[0m        \u001b[32m2.7602\u001b[0m  0.0427\n",
      "      3        3.0177  0.0038\n",
      "      4        2.7628  0.0047\n",
      "      5        2.7628  0.0036\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.0482\u001b[0m        \u001b[32m3.0200\u001b[0m  0.0441\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0655\u001b[0m  0.0042\n",
      "      4        3.0177  0.0071\n",
      "      6        2.7628  0.0044\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1886\u001b[0m        \u001b[32m3.0390\u001b[0m  0.0441\n",
      "      2        3.0655  0.0039\n",
      "      5        3.0177  0.0040\n",
      "      7        2.7628  0.0038\n",
      "      3        3.0655  0.0038\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2258\u001b[0m        \u001b[32m3.1463\u001b[0m  0.0463\n",
      "      8        2.7628  0.0036\n",
      "      6        3.0177  0.0047\n",
      "      4        3.0655  0.0038\n",
      "      7        3.0177  0.0040\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.3071\u001b[0m        \u001b[32m3.2811\u001b[0m  0.0432\n",
      "      9        2.7628  0.0052\n",
      "      5        3.0655  0.0038\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.1721\u001b[0m  0.0044\n",
      "      8        3.0177  0.0037\n",
      "     10        2.7628  0.0036\n",
      "Restoring best model from epoch 1.\n",
      "      6        3.0655  0.0038\n",
      "      2        3.1721  0.0040\n",
      "      9        3.0177  0.0037\n",
      "      7        3.0655  0.0038\n",
      "      3        3.1721  0.0040\n",
      "     10        3.0177  0.0038\n",
      "Restoring best model from epoch 1.\n",
      "      8        3.0655  0.0038\n",
      "      4        3.1721  0.0039\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.2905\u001b[0m  0.0044\n",
      "      9        3.0655  0.0042\n",
      "      5        3.1721  0.0054\n",
      "      2        3.2905  0.0041\n",
      "     10        3.0655  0.0042\n",
      "Restoring best model from epoch 1.\n",
      "      6        3.1721  0.0041\n",
      "      3        3.2905  0.0040\n",
      "      2        \u001b[36m2.7730\u001b[0m        2.7686  0.0480\n",
      "      7        3.1721  0.0042\n",
      "      4        3.2905  0.0050\n",
      "      8        3.1721  0.0039\n",
      "      2        \u001b[36m3.1490\u001b[0m        \u001b[32m3.0294\u001b[0m  0.0431\n",
      "      2        \u001b[36m3.0255\u001b[0m        \u001b[32m3.0190\u001b[0m  0.0489\n",
      "      5        3.2905  0.0041\n",
      "      9        3.1721  0.0040\n",
      "      6        3.2905  0.0041\n",
      "      2        \u001b[36m3.1291\u001b[0m        \u001b[32m3.1287\u001b[0m  0.0448\n",
      "     10        3.1721  0.0041\n",
      "Restoring best model from epoch 1.\n",
      "      7        3.2905  0.0040\n",
      "      2        \u001b[36m3.2165\u001b[0m        \u001b[32m3.2675\u001b[0m  0.0452\n",
      "      8        3.2905  0.0040\n",
      "      9        3.2905  0.0042\n",
      "     10        3.2905  0.0040\n",
      "Restoring best model from epoch 1.\n",
      "      3        \u001b[36m2.7571\u001b[0m        \u001b[32m2.7553\u001b[0m  0.0430\n",
      "      3        \u001b[36m3.1176\u001b[0m        3.0622  0.0427\n",
      "      3        \u001b[36m2.9679\u001b[0m        3.0325  0.0432\n",
      "      3        \u001b[36m3.1054\u001b[0m        3.1336  0.0418\n",
      "      3        \u001b[36m3.1860\u001b[0m        3.2720  0.0421\n",
      "      4        \u001b[36m2.7327\u001b[0m        2.7796  0.0423\n",
      "      4        \u001b[36m3.1096\u001b[0m        3.0322  0.0430\n",
      "      4        2.9893        3.0369  0.0430\n",
      "      4        \u001b[36m3.0763\u001b[0m        3.1366  0.0414\n",
      "      4        \u001b[36m3.1610\u001b[0m        3.2790  0.0426\n",
      "      5        \u001b[36m2.7321\u001b[0m        2.8023  0.0418\n",
      "      5        \u001b[36m3.0860\u001b[0m        3.0460  0.0416\n",
      "      5        \u001b[36m2.9422\u001b[0m        3.0257  0.0410\n",
      "      5        \u001b[36m3.0737\u001b[0m        3.1287  0.0412\n",
      "      5        3.1775        3.2686  0.0406\n",
      "      6        \u001b[36m2.7306\u001b[0m        2.7651  0.0412\n",
      "      6        3.0901        3.0624  0.0414\n",
      "      6        2.9517        3.0402  0.0431\n",
      "      6        \u001b[36m3.0704\u001b[0m        3.1327  0.0413\n",
      "      6        3.1714        3.2704  0.0415\n",
      "      7        \u001b[36m2.7114\u001b[0m        2.7819  0.0406\n",
      "      7        \u001b[36m3.0854\u001b[0m        3.0322  0.0411\n",
      "      7        2.9484        3.0290  0.0416\n",
      "      7        3.0741        3.1347  0.0415\n",
      "      7        3.1653        \u001b[32m3.2670\u001b[0m  0.0413\n",
      "      8        2.7119        2.7849  0.0408\n",
      "      8        \u001b[36m3.0784\u001b[0m        3.0390  0.0420\n",
      "      8        2.9440        3.0393  0.0408\n",
      "      8        \u001b[36m3.0614\u001b[0m        3.1367  0.0416\n",
      "      8        \u001b[36m3.1535\u001b[0m        3.2776  0.0410\n",
      "      9        \u001b[36m2.6869\u001b[0m        2.7858  0.0409\n",
      "      9        \u001b[36m3.0613\u001b[0m        3.0335  0.0409\n",
      "      9        \u001b[36m2.9160\u001b[0m        3.0353  0.0416\n",
      "      9        \u001b[36m3.0425\u001b[0m        3.1374  0.0419\n",
      "      9        \u001b[36m3.1426\u001b[0m        3.2778  0.0402\n",
      "     10        2.6985        2.7842  0.0409\n",
      "Restoring best model from epoch 3.\n",
      "     10        3.0694        3.0327  0.0411\n",
      "Restoring best model from epoch 2.\n",
      "     10        2.9343        3.0316  0.0407\n",
      "Restoring best model from epoch 2.\n",
      "     10        3.0515        3.1366  0.0408\n",
      "Restoring best model from epoch 2.\n",
      "     10        3.1470        3.2702  0.0418\n",
      "Restoring best model from epoch 7.\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1513\u001b[0m        \u001b[32m3.1471\u001b[0m  0.0237\n",
      "      2        3.3896        \u001b[32m3.1366\u001b[0m  0.0272\n",
      "      3        3.2526        \u001b[32m3.1301\u001b[0m  0.0271\n",
      "      4        \u001b[36m3.0823\u001b[0m        3.1344  0.0243\n",
      "      5        \u001b[36m2.9956\u001b[0m        3.1487  0.0251\n",
      "      6        3.0095        3.1549  0.0236\n",
      "      7        3.0236        3.1519  0.0266\n",
      "      8        3.0042        3.1431  0.0242\n",
      "      9        \u001b[36m2.9937\u001b[0m        3.1337  0.0261\n",
      "     10        \u001b[36m2.9777\u001b[0m        3.1319  0.0240\n",
      "Restoring best model from epoch 3.\n",
      "(1523, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(1523,) <class 'pandas.core.series.Series'>\n",
      "(380, 9) <class 'pandas.core.frame.DataFrame'>\n",
      "(380,) <class 'pandas.core.series.Series'>\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8080\u001b[0m  0.0039\n",
      "      2        2.8080  0.0036\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0874\u001b[0m  0.0042\n",
      "      3        2.8080  0.0036\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.3065\u001b[0m  0.0044\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m2.8823\u001b[0m        \u001b[32m2.7995\u001b[0m  0.0422\n",
      "      4        2.8080  0.0035\n",
      "      2        3.0874  0.0065\n",
      "      2        3.3065  0.0040\n",
      "      5        2.8080  0.0035\n",
      "      3        3.0874  0.0041\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.1552\u001b[0m  0.0042\n",
      "      3        3.3065  0.0039\n",
      "      6        2.8080  0.0035\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.0297\u001b[0m        \u001b[32m3.1090\u001b[0m  0.0471\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2065\u001b[0m        \u001b[32m3.2941\u001b[0m  0.0429\n",
      "      4        3.0874  0.0039\n",
      "      2        3.1552  0.0041\n",
      "      7        2.8080  0.0035\n",
      "      4        3.3065  0.0043\n",
      "      5        3.0874  0.0038\n",
      "      3        3.1552  0.0038\n",
      "      8        2.8080  0.0035\n",
      "      5        3.3065  0.0040\n",
      "      6        3.0874  0.0038\n",
      "      9        2.8080  0.0035\n",
      "      6        3.3065  0.0039\n",
      "      7        3.0874  0.0038\n",
      "     10        2.8080  0.0035\n",
      "Restoring best model from epoch 1.\n",
      "      4        3.1552  0.0077\n",
      "      7        3.3065  0.0039\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2647\u001b[0m        \u001b[32m3.1217\u001b[0m  0.0496\n",
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.2291\u001b[0m  0.0044\n",
      "      8        3.0874  0.0049\n",
      "      8        3.3065  0.0039\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.2814\u001b[0m        \u001b[32m3.2137\u001b[0m  0.0496\n",
      "      5        3.1552  0.0062\n",
      "      2        3.2291  0.0040\n",
      "      9        3.3065  0.0039\n",
      "      9        3.0874  0.0055\n",
      "      6        3.1552  0.0040\n",
      "      3        3.2291  0.0045\n",
      "     10        3.3065  0.0039\n",
      "Restoring best model from epoch 1.\n",
      "      7        3.1552  0.0039\n",
      "      4        3.2291  0.0039\n",
      "     10        3.0874  0.0068\n",
      "Restoring best model from epoch 1.\n",
      "      8        3.1552  0.0041\n",
      "      5        3.2291  0.0039\n",
      "      2        \u001b[36m2.8232\u001b[0m        \u001b[32m2.7870\u001b[0m  0.0453\n",
      "      9        3.1552  0.0039\n",
      "      6        3.2291  0.0039\n",
      "     10        3.1552  0.0039\n",
      "Restoring best model from epoch 1.\n",
      "      7        3.2291  0.0043\n",
      "      2        \u001b[36m2.9820\u001b[0m        \u001b[32m3.0618\u001b[0m  0.0421\n",
      "      8        3.2291  0.0040\n",
      "      9        3.2291  0.0039\n",
      "      2        \u001b[36m3.1219\u001b[0m        \u001b[32m3.2870\u001b[0m  0.0500\n",
      "     10        3.2291  0.0043\n",
      "Restoring best model from epoch 1.\n",
      "      2        \u001b[36m3.1928\u001b[0m        \u001b[32m3.0710\u001b[0m  0.0442\n",
      "      2        \u001b[36m3.1951\u001b[0m        \u001b[32m3.1841\u001b[0m  0.0468\n",
      "      3        \u001b[36m2.7712\u001b[0m        2.7872  0.0423\n",
      "      3        \u001b[36m2.9458\u001b[0m        3.0646  0.0426\n",
      "      3        \u001b[36m3.0988\u001b[0m        \u001b[32m3.2775\u001b[0m  0.0422\n",
      "      3        \u001b[36m3.1394\u001b[0m        \u001b[32m3.0534\u001b[0m  0.0432\n",
      "      3        \u001b[36m3.1614\u001b[0m        3.1955  0.0422\n",
      "      4        \u001b[36m2.7595\u001b[0m        \u001b[32m2.7740\u001b[0m  0.0423\n",
      "      4        2.9475        3.0793  0.0425\n",
      "      4        3.1002        \u001b[32m3.2542\u001b[0m  0.0425\n",
      "      4        3.1563        3.0707  0.0424\n",
      "      4        \u001b[36m3.1512\u001b[0m        3.1889  0.0425\n",
      "      5        \u001b[36m2.7538\u001b[0m        2.7787  0.0407\n",
      "      5        \u001b[36m2.9400\u001b[0m        3.0719  0.0409\n",
      "      5        \u001b[36m3.0904\u001b[0m        \u001b[32m3.2489\u001b[0m  0.0406\n",
      "      5        3.1402        3.0899  0.0414\n",
      "      5        3.1549        \u001b[32m3.1783\u001b[0m  0.0416\n",
      "      6        \u001b[36m2.7326\u001b[0m        2.8056  0.0407\n",
      "      6        \u001b[36m2.9279\u001b[0m        3.0722  0.0406\n",
      "      6        \u001b[36m3.0694\u001b[0m        3.2656  0.0418\n",
      "      6        \u001b[36m3.1348\u001b[0m        3.0751  0.0421\n",
      "      6        \u001b[36m3.1446\u001b[0m        \u001b[32m3.1753\u001b[0m  0.0415\n",
      "      7        2.7350        2.7831  0.0404\n",
      "      7        \u001b[36m2.9185\u001b[0m        3.0752  0.0416\n",
      "      7        3.0788        3.2669  0.0426\n",
      "      7        \u001b[36m3.1207\u001b[0m        3.0704  0.0413\n",
      "      7        \u001b[36m3.1361\u001b[0m        3.2104  0.0410\n",
      "      8        \u001b[36m2.7205\u001b[0m        2.8033  0.0406\n",
      "      8        \u001b[36m2.9150\u001b[0m        3.0700  0.0417\n",
      "      8        3.0720        3.2749  0.0420\n",
      "      8        \u001b[36m3.1162\u001b[0m        3.0590  0.0421\n",
      "      8        \u001b[36m3.1341\u001b[0m        3.1901  0.0413\n",
      "      9        2.7207        2.7825  0.0413\n",
      "      9        \u001b[36m2.9079\u001b[0m        3.0663  0.0412\n",
      "      9        \u001b[36m3.0563\u001b[0m        3.2566  0.0414\n",
      "      9        \u001b[36m3.0948\u001b[0m        3.0570  0.0422\n",
      "      9        \u001b[36m3.1292\u001b[0m        3.1852  0.0417\n",
      "     10        \u001b[36m2.7118\u001b[0m        2.7839  0.0401\n",
      "Restoring best model from epoch 4.\n",
      "     10        2.9227        3.0643  0.0411\n",
      "Restoring best model from epoch 2.\n",
      "     10        3.0603        3.2853  0.0415\n",
      "Restoring best model from epoch 5.\n",
      "     10        3.0966        3.0585  0.0403\n",
      "Restoring best model from epoch 3.\n",
      "     10        \u001b[36m3.1219\u001b[0m        3.1873  0.0407\n",
      "Restoring best model from epoch 6.\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.1224\u001b[0m        \u001b[32m3.1923\u001b[0m  0.0252\n",
      "      2        3.3468        \u001b[32m3.1822\u001b[0m  0.0257\n",
      "      3        3.2365        \u001b[32m3.1815\u001b[0m  0.0250\n",
      "      4        \u001b[36m3.0656\u001b[0m        3.1911  0.0267\n",
      "      5        \u001b[36m2.9538\u001b[0m        3.2049  0.0257\n",
      "      6        2.9603        3.2173  0.0255\n",
      "      7        2.9929        3.2210  0.0258\n",
      "      8        2.9842        3.2167  0.0258\n",
      "      9        2.9612        3.2060  0.0246\n",
      "     10        \u001b[36m2.9348\u001b[0m        3.2031  0.0248\n",
      "Restoring best model from epoch 3.\n"
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric,  load_flchain, load_rgbsg, load_support] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "data_set_fns_str = ['load_metabric', 'load_flchain', 'load_rgbsg', 'load_support'] \n",
    "one_hot_dict = {'load_flchain': ['mgus'], 'load_support':['cancer'], 'load_rgbsg':['grade']}\n",
    "agg_best_settings = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(data_set_fns_str[idx])\n",
    "    #if data_set_fns_str[idx] in one_hot_dict.keys():\n",
    "    #    X = pd.get_dummies(X, columns=one_hot_dict[data_set_fns_str[idx]])\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    \n",
    "    net = NeuralNet(\n",
    "        SurvivalModel, \n",
    "        module__n_layers = 1,\n",
    "        module__input_units = X.shape[1],\n",
    "        #module__num_nodes = 32,\n",
    "        #module__dropout = 0.1, # these could also be removed\n",
    "        module__out_features = 1,\n",
    "        # for split sizes when result size = 1\n",
    "        iterator_train__drop_last=True,\n",
    "        #iterator_valid__drop_last=True,\n",
    "        criterion=AFTLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer__weight_decay = 0.4,\n",
    "        batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "        callbacks=[\n",
    "            (\n",
    "                \"sched\",\n",
    "                LRScheduler(\n",
    "                    torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=5,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"es\",\n",
    "                EarlyStopping(\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=10,\n",
    "                    load_best=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"seed\", FixSeed(seed=42)),\n",
    "        ],\n",
    "        \n",
    "        #[EarlyStopping(patience=10)],\n",
    "        # add extensive callback, and random number seed\n",
    "        #TODO: enable stratification, verify\n",
    "        train_split=ValidSplit(0.2), # might cause lower performance in metrics, explain in thesis\n",
    "        #lr=0.001,\n",
    "        #max_epochs=1, #0,#100\n",
    "        #train_split=None,\n",
    "        verbose=1\n",
    "    )\n",
    "    df_best_settings = train_eval(X, y, net, n_iter, data.filename)\n",
    "    agg_best_settings.append(df_best_settings)\n",
    "\n",
    "df_final_settings = pd.concat([df for df in agg_best_settings])\n",
    "df_final_settings.to_csv('metrics/final_settings_deep_learning_aft_1.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA Train, Test, Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_breslow_tcga = {\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__n_layers': [1, 2, 4],\n",
    "    'estimator__module__num_nodes': [64, 128, 256, 512],\n",
    "    'estimator__module__dropout': scuniform(0.0,0.7),\n",
    "    'estimator__optimizer__weight_decay': [0.4, 0.2, 0.1, 0.05, 0.02, 0.01, 0],\n",
    "    'estimator__batch_size': [64, 128, 256, 512, 1024],\n",
    "    #lr not in paper because of learning rate finder\n",
    "    # note: setting learning rate higher would make exp(partial_hazard) explode\n",
    "    #'estimator__lr': scloguniform(0.001,0.01), # scheduler unten einbauen\n",
    "    # use callback instead\n",
    "    'estimator__lr':[0.01],\n",
    "    #'estimator__max_epochs':  scrandint(10,20), # corresponds to num_rounds\n",
    "    'pca__n_components': [8, 10, 12, 14, 16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(X, y, net, n_iter, filename):\n",
    "        model = 'ah_'\n",
    "        dataset_name = filename.split('_')[0]\n",
    "        # add IBS later\n",
    "        outer_scores = {'cindex_train_'+dataset_name:[], 'cindex_test_'+dataset_name:[],\n",
    "                        'ibs_train_'+dataset_name:[], 'ibs_test_'+dataset_name:[]}\n",
    "        best_params = {'best_params_'+dataset_name:[]}\n",
    "        best_model = {'best_model_'+dataset_name:[]}\n",
    "        ct = make_column_transformer(\n",
    "                #(OneHotEncoder(sparse_output=False), make_column_selector(dtype_include=['category', 'object']))\n",
    "                (StandardScaler(), make_column_selector(dtype_include=['float32']))\n",
    "                ,remainder='drop')\n",
    "        pipe = Pipeline([('scaler',ct),\n",
    "                         ('pca', PCA()),#n_components=10\n",
    "                        ('estimator', net)])\n",
    "        rs = RandomizedSearchCV(pipe, param_grid_breslow_tcga, scoring = scoring_function, n_jobs=-1, \n",
    "                                    n_iter=2, refit=True)\n",
    "        for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "                # Split data into training and testing sets for outer fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                X_train, y_train = sort_X_y_pandas(X_train, y_train)\n",
    "                X_test, y_test = sort_X_y_pandas(X_test, y_test)\n",
    "\n",
    "                #print(X_train.shape, type(X_train))\n",
    "                #print(y_train.shape, type(y_train))\n",
    "                #print(X_test.shape, type(X_test))\n",
    "                #print(y_test.shape, type(y_test))\n",
    "                # save splits and data\n",
    "                savetxt('splits/train_index_'+str(i)+'_'+filename, train_index, delimiter=',')\n",
    "                savetxt('splits/test_index_'+str(i)+'_'+filename, test_index, delimiter=',')\n",
    "                \n",
    "                savetxt('splits/X_train_'+str(i)+'_'+filename, X_train, delimiter=',')\n",
    "                savetxt('splits/X_test_'+str(i)+'_'+filename, X_test, delimiter=',')\n",
    "\n",
    "                savetxt('splits/y_train_'+str(i)+'_'+filename, y_train, delimiter=',')\n",
    "                savetxt('splits/y_test_'+str(i)+'_'+filename, y_test, delimiter=',')\n",
    "\n",
    "                strat = np.sign(y_train)\n",
    "                valid_split = ValidSplit(cv=0.1, stratified=strat, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                rs.fit(X_train, y_train)\n",
    "                best_preds_train = rs.best_estimator_.predict(X_train)\n",
    "                best_preds_test = rs.best_estimator_.predict(X_test)\n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "                # save hyperparameter settings\n",
    "                params = rs.best_estimator_.get_params\n",
    "                best_params['best_params_'+dataset_name] += [rs.best_params_]\n",
    "                best_model['best_model_'+dataset_name] += [params]\n",
    "        df_best_params = pd.DataFrame(best_params)\n",
    "        df_best_model = pd.DataFrame(best_model)\n",
    "        # df_outer_scores = pd.DataFrame(outer_scores)\n",
    "        df_best_settings = pd.concat([df_best_params,df_best_model])\n",
    "        df_best_settings.to_csv('metrics/'+model+'metric_summary_'+filename, index=False)\n",
    "\n",
    "        return df_best_settings\n",
    "        return \n",
    "\n",
    "                \n",
    "#cv=inner_custom_cv,pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_types = [\n",
    "    'BLCA',\n",
    "    'BRCA',\n",
    "    'HNSC',\n",
    "    'KIRC',\n",
    "    'LGG',\n",
    "    'LIHC',\n",
    "    'LUAD',\n",
    "    'LUSC',\n",
    "    'OV',\n",
    "    'STAD']\n",
    "import skorch.callbacks\n",
    "\n",
    "class InputShapeSetter(skorch.callbacks.Callback):\n",
    "    def on_train_begin(self, net, X, y):\n",
    "        net.set_params(module__input_units=X.shape[-1])\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types):\n",
    "    # get name of current dataset\n",
    "    data = load_tcga(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", cancer_type=cancer_type, as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "\n",
    "    net = NeuralNet(\n",
    "        SurvivalModel, \n",
    "        module__n_layers = 1,\n",
    "        module__input_units = X.shape[1],\n",
    "        #module__num_nodes = 32,\n",
    "        #module__dropout = 0.1, # these could also be removed\n",
    "        module__out_features = 1,\n",
    "        # for split sizes when result size = 1\n",
    "        iterator_train__drop_last=True,\n",
    "        #iterator_valid__drop_last=True,\n",
    "        criterion=AFTLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer__weight_decay = 0.4,\n",
    "        batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "        callbacks=[\n",
    "            (\n",
    "                \"sched\",\n",
    "                LRScheduler(\n",
    "                    torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=5,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"es\",\n",
    "                EarlyStopping(\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=10,\n",
    "                    load_best=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"seed\", FixSeed(seed=42)),\n",
    "            (\"Input Shape Setter\",InputShapeSetter())\n",
    "        ],#[EarlyStopping(patience=10)],#,InputShapeSetter()],\n",
    "        #TODO: enable stratification, verify\n",
    "        train_split=ValidSplit(0.2), # might cause lower performance in metrics, explain in thesis\n",
    "        #lr=0.001,\n",
    "        #max_epochs=1, #0,#100\n",
    "        #train_split=None,\n",
    "        verbose=1\n",
    "    )\n",
    "     = train_eval(X, y, net, n_iter, data.filename)\n",
    "    data_set_fns = [load_metabric,  load_flchain, load_rgbsg, load_support] #, load_flchain, load_rgbsg, load_support, load_tcga]\n",
    "data_set_fns_str = ['load_metabric', 'load_flchain', 'load_rgbsg', 'load_support'] \n",
    "one_hot_dict = {'load_flchain': ['mgus'], 'load_support':['cancer'], 'load_rgbsg':['grade']}\n",
    "agg_best_settings = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(data_set_fns_str[idx])\n",
    "    #if data_set_fns_str[idx] in one_hot_dict.keys():\n",
    "    #    X = pd.get_dummies(X, columns=one_hot_dict[data_set_fns_str[idx]])\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    \n",
    "    net = NeuralNet(\n",
    "        SurvivalModel, \n",
    "        module__n_layers = 1,\n",
    "        module__input_units = X.shape[1],\n",
    "        #module__num_nodes = 32,\n",
    "        #module__dropout = 0.1, # these could also be removed\n",
    "        module__out_features = 1,\n",
    "        # for split sizes when result size = 1\n",
    "        iterator_train__drop_last=True,\n",
    "        #iterator_valid__drop_last=True,\n",
    "        criterion=AFTLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer__weight_decay = 0.4,\n",
    "        batch_size=32, # separate train and valid->iterator_train__batch_size=128 and iterator_valid__batch_size=128 ?\n",
    "        callbacks=[\n",
    "            (\n",
    "                \"sched\",\n",
    "                LRScheduler(\n",
    "                    torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=5,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"es\",\n",
    "                EarlyStopping(\n",
    "                    monitor=\"valid_loss\",\n",
    "                    patience=10,\n",
    "                    load_best=True,\n",
    "                ),\n",
    "            ),\n",
    "            (\"seed\", FixSeed(seed=42)),\n",
    "        ],\n",
    "        \n",
    "        #[EarlyStopping(patience=10)],\n",
    "        # add extensive callback, and random number seed\n",
    "        #TODO: enable stratification, verify\n",
    "        train_split=ValidSplit(0.2), # might cause lower performance in metrics, explain in thesis\n",
    "        #lr=0.001,\n",
    "        #max_epochs=1, #0,#100\n",
    "        #train_split=None,\n",
    "        verbose=1\n",
    "    )\n",
    "    df_best_settings = train_eval(X, y, net, n_iter, data.filename)\n",
    "    agg_best_settings.append(df_best_settings)\n",
    "\n",
    "df_final_settings = pd.concat([df for df in agg_best_settings])\n",
    "df_final_settings.to_csv('metrics/final_settings_deep_learning_aft_tcga.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
