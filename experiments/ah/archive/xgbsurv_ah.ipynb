{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBSurv Breslow Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgbsurv.datasets import (load_metabric, load_flchain, load_rgbsg, load_support, load_tcga)\n",
    "from xgbsurv import XGBSurv\n",
    "from xgbsurv.evaluation import cindex_censored, ibs\n",
    "from xgbsurv.models.utils import sort_X_y\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform as scuniform\n",
    "from scipy.stats import randint as scrandint\n",
    "from scipy.stats import loguniform as scloguniform \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.decomposition import PCA\n",
    "# import models\n",
    "from xgbsurv.models.breslow_final import breslow_likelihood,get_cumulative_hazard_function_breslow\n",
    "from xgbsurv.models.efron_final import efron_likelihood\n",
    "from xgbsurv.models.cind_final import cind_loss\n",
    "from xgbsurv.models.deephit_pycox_final import deephit_loss1_pycox\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from xgbsurv.models.utils import sort_X_y_pandas, transform_back, transform\n",
    "from xgbsurv.preprocessing.dataset_preprocessing import discretizer_df\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path /Users/JUSC/Documents/xgbsurv/experiments/ah\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd() \n",
    "one_level_up = os.path.abspath(os.path.join(current_path,  \"..\"))\n",
    "two_levels_up = os.path.abspath(os.path.join(current_path,  \"..\",\"..\"))\n",
    "one_level_up\n",
    "sys.path.append(one_level_up+'/gbdt_pipeline')\n",
    "from gbdt_pipeline import get_gbdt_pipeline, train_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=CustomSplit(n_splits=5, random_state=42, shuffle=True),\n",
       "                   error_score=&#x27;raise&#x27;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x2bf665010&gt;),\n",
       "                                                                              (&#x27;onehotencoder&#x27;,\n",
       "                                                                               OneHotEncoder(handle_unknown=&#x27;in...\n",
       "                                        &#x27;estimator__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2c81509d0&gt;,\n",
       "                                        &#x27;estimator__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2be02b290&gt;,\n",
       "                                        &#x27;estimator__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2c84048d0&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(custom_scoring_function, greater_is_better=False, model=breslow),\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=CustomSplit(n_splits=5, random_state=42, shuffle=True),\n",
       "                   error_score=&#x27;raise&#x27;,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x2bf665010&gt;),\n",
       "                                                                              (&#x27;onehotencoder&#x27;,\n",
       "                                                                               OneHotEncoder(handle_unknown=&#x27;in...\n",
       "                                        &#x27;estimator__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2c81509d0&gt;,\n",
       "                                        &#x27;estimator__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2be02b290&gt;,\n",
       "                                        &#x27;estimator__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2c84048d0&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(custom_scoring_function, greater_is_better=False, model=breslow),\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x2bf665010&gt;),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at...\n",
       "                         grow_policy=None, importance_type=None,\n",
       "                         interaction_constraints=None, learning_rate=None,\n",
       "                         max_bin=None, max_cat_threshold=None,\n",
       "                         max_cat_to_onehot=None, max_delta_step=None,\n",
       "                         max_depth=None, max_leaves=None, min_child_weight=None,\n",
       "                         missing=nan, monotone_constraints=None,\n",
       "                         n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                         objective=CPUDispatcher(&lt;function breslow_objective at 0x177615260&gt;), ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;standardscaler&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x2bf665010&gt;),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x2be14e9d0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standardscaler</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x2bf665010&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x2be14e9d0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBSurv</label><div class=\"sk-toggleable__content\"><pre>XGBSurv(base_score=0.0, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "        colsample_bynode=None, colsample_bytree=None,\n",
       "        disable_default_eval_metric=True, early_stopping_rounds=10,\n",
       "        enable_categorical=False,\n",
       "        eval_metric=CPUDispatcher(&lt;function breslow_likelihood at 0x177603c40&gt;),\n",
       "        feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "        importance_type=None, interaction_constraints=None, learning_rate=None,\n",
       "        max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "        max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "        min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "        n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "        objective=CPUDispatcher(&lt;function breslow_objective at 0x177615260&gt;), ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=CustomSplit(n_splits=5, random_state=42, shuffle=True),\n",
       "                   error_score='raise',\n",
       "                   estimator=Pipeline(steps=[('scaler',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               <sklearn.compose._column_transformer.make_column_selector object at 0x2bf665010>),\n",
       "                                                                              ('onehotencoder',\n",
       "                                                                               OneHotEncoder(handle_unknown='in...\n",
       "                                        'estimator__reg_alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2c81509d0>,\n",
       "                                        'estimator__reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2be02b290>,\n",
       "                                        'estimator__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x2c84048d0>},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(custom_scoring_function, greater_is_better=False, model=breslow),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gbdt_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_outer_splits = 5\n",
    "n_inner_splits = 5\n",
    "rand_state = 42\n",
    "n_iter = 50 \n",
    "early_stopping_rounds=10\n",
    "base_score = 0.0\n",
    "validation_size = 0.2\n",
    "model = 'ah'\n",
    "\n",
    "\n",
    "# set seed for scipy\n",
    "np.random.seed(rand_state)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSplit(StratifiedKFold):\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        try:\n",
    "            if y.shape[1]>1:\n",
    "                y = y[:,0]\n",
    "        except:\n",
    "            pass\n",
    "        bins = np.sign(y)\n",
    "        return super().split(X, bins, groups=groups)\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "outer_custom_cv = CustomSplit(n_splits=n_outer_splits, shuffle=True, random_state=rand_state)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model & Train Test Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METABRIC_adapted.csv\n",
      "0\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "integration values 25881\n",
      "integration values 7124\n",
      "Concordance Index 0.581822149914686\n",
      "Integrated Brier Score: 0.18074823420114342\n",
      "{'model': 'ah', 'dataset': 'METABRIC', 'cindex_train': [0.6291334884081182], 'cindex_test': [0.581822149914686], 'ibs_train': [0.1656261749695436], 'ibs_score_test': [0.18074823420114342]}\n",
      "1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "integration values 168150\n",
      "integration values 34676\n",
      "Concordance Index 0.6122834274027021\n",
      "Integrated Brier Score: 0.1767488742531223\n",
      "{'model': 'ah', 'dataset': 'METABRIC', 'cindex_train': [0.7202357037632249], 'cindex_test': [0.6122834274027021], 'ibs_train': [0.15650829761410892], 'ibs_score_test': [0.1767488742531223]}\n",
      "2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "integration values 85930\n",
      "integration values 20094\n",
      "Concordance Index 0.6411196796384038\n",
      "Integrated Brier Score: 0.18757938093328688\n",
      "{'model': 'ah', 'dataset': 'METABRIC', 'cindex_train': [0.7588602406386371], 'cindex_test': [0.6411196796384038], 'ibs_train': [0.1662021293428825], 'ibs_score_test': [0.18757938093328688]}\n",
      "3\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "integration values 71464\n",
      "integration values 17594\n",
      "Concordance Index 0.6453209079850731\n",
      "Integrated Brier Score: 0.16800764050886255\n",
      "{'model': 'ah', 'dataset': 'METABRIC', 'cindex_train': [0.6627145572251589], 'cindex_test': [0.6453209079850731], 'ibs_train': [0.17632998431669394], 'ibs_score_test': [0.16800764050886255]}\n",
      "4\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "integration values 144059\n",
      "integration values 28329\n",
      "Concordance Index 0.6486583828561138\n",
      "Integrated Brier Score: 0.17083704710087605\n",
      "{'model': 'ah', 'dataset': 'METABRIC', 'cindex_train': [0.7604017145135566], 'cindex_test': [0.6486583828561138], 'ibs_train': [0.1575081367666988], 'ibs_score_test': [0.17083704710087605]}\n",
      "FLCHAIN_adapted.csv\n",
      "0\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "integration values 488348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m     19\u001b[0m pi \u001b[39m=\u001b[39m get_gbdt_pipeline()\n\u001b[0;32m---> 20\u001b[0m metric \u001b[39m=\u001b[39m train_gbdt(X, y, i, pi, train_index, test_index, model, dataset_name, validation_size)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(metric)\n\u001b[1;32m     22\u001b[0m metrics_list\u001b[39m.\u001b[39mappend(metric)\n",
      "File \u001b[0;32m~/Documents/xgbsurv/experiments/gbdt_pipeline/gbdt_pipeline.py:194\u001b[0m, in \u001b[0;36mtrain_gbdt\u001b[0;34m(X, y, i, pipeline, train_index, test_index, model, dataset_name, validation_size, tcga, n_iter)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[1;32m    192\u001b[0m params_df\u001b[39m.\u001b[39mto_csv(current_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/params/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mmodel\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_best_params_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mdataset_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 194\u001b[0m cum_hazard_train \u001b[39m=\u001b[39m cum_hazard_dict[model](\n\u001b[1;32m    195\u001b[0m         X_train\u001b[39m.\u001b[39;49mvalues, X_train\u001b[39m.\u001b[39;49mvalues, y_train\u001b[39m.\u001b[39;49mvalues, y_train\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m    196\u001b[0m         best_preds_train\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), best_preds_train\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    199\u001b[0m df_survival_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mcum_hazard_train)\n\u001b[1;32m    200\u001b[0m durations_train, events_train \u001b[39m=\u001b[39m transform_back(y_train\u001b[39m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgbsurv/models/eh_ah_final.py:420\u001b[0m, in \u001b[0;36mget_cumulative_hazard_function_ah\u001b[0;34m(X_train, X_test, y_train, y_test, predictor_train, predictor_test)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mintegration values\u001b[39m\u001b[39m'\u001b[39m,integration_values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    417\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, integration_values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    418\u001b[0m     integration_values[_] \u001b[39m=\u001b[39m (\n\u001b[1;32m    419\u001b[0m         integration_values[_ \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 420\u001b[0m         \u001b[39m+\u001b[39m quadrature(\n\u001b[1;32m    421\u001b[0m             func\u001b[39m=\u001b[39;49mhazard_function_integrate,\n\u001b[1;32m    422\u001b[0m             a\u001b[39m=\u001b[39;49mintegration_times[_ \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m],\n\u001b[1;32m    423\u001b[0m             b\u001b[39m=\u001b[39;49mintegration_times[_],\n\u001b[1;32m    424\u001b[0m             vec_func\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    425\u001b[0m         )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    426\u001b[0m     )\n\u001b[1;32m    427\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_samples):\n\u001b[1;32m    428\u001b[0m     cumulative_hazard[_] \u001b[39m=\u001b[39m (\n\u001b[1;32m    429\u001b[0m         integration_values[\n\u001b[1;32m    430\u001b[0m             np\u001b[39m.\u001b[39mdigitize(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[39m/\u001b[39m theta[_]\n\u001b[1;32m    436\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/scipy/integrate/_quadrature.py:365\u001b[0m, in \u001b[0;36mquadrature\u001b[0;34m(func, a, b, args, tol, rtol, maxiter, vec_func, miniter)\u001b[0m\n\u001b[1;32m    363\u001b[0m maxiter \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(miniter\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, maxiter)\n\u001b[1;32m    364\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(miniter, maxiter\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 365\u001b[0m     newval \u001b[39m=\u001b[39m fixed_quad(vfunc, a, b, (), n)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    366\u001b[0m     err \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(newval\u001b[39m-\u001b[39mval)\n\u001b[1;32m    367\u001b[0m     val \u001b[39m=\u001b[39m newval\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/scipy/integrate/_quadrature.py:245\u001b[0m, in \u001b[0;36mfixed_quad\u001b[0;34m(func, a, b, args, n)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGaussian quadrature is only available for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mfinite limits.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m y \u001b[39m=\u001b[39m (b\u001b[39m-\u001b[39ma)\u001b[39m*\u001b[39m(x\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2.0\u001b[39m \u001b[39m+\u001b[39m a\n\u001b[0;32m--> 245\u001b[0m \u001b[39mreturn\u001b[39;00m (b\u001b[39m-\u001b[39ma)\u001b[39m/\u001b[39m\u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(w\u001b[39m*\u001b[39mfunc(y, \u001b[39m*\u001b[39;49margs), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/scipy/integrate/_quadrature.py:282\u001b[0m, in \u001b[0;36mvectorize1.<locals>.vfunc\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    280\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\n\u001b[1;32m    281\u001b[0m \u001b[39m# call with first point to get output type\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m y0 \u001b[39m=\u001b[39m func(x[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    283\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x)\n\u001b[1;32m    284\u001b[0m dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(y0, \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m(y0))\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgbsurv/models/eh_ah_final.py:393\u001b[0m, in \u001b[0;36mget_cumulative_hazard_function_ah.<locals>.hazard_function_integrate\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhazard_function_integrate\u001b[39m(s):\n\u001b[0;32m--> 393\u001b[0m     \u001b[39mreturn\u001b[39;00m baseline_hazard_estimator_ah(\n\u001b[1;32m    394\u001b[0m         time\u001b[39m=\u001b[39;49ms,\n\u001b[1;32m    395\u001b[0m         time_train\u001b[39m=\u001b[39;49mtime_train,\n\u001b[1;32m    396\u001b[0m         event_train\u001b[39m=\u001b[39;49mevent_train,\n\u001b[1;32m    397\u001b[0m         predictor_train\u001b[39m=\u001b[39;49mpredictor_train,\n\u001b[1;32m    398\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_set_fns = [load_metabric,  load_flchain, load_rgbsg, load_support] \n",
    "metrics_list = []\n",
    "\n",
    "for idx, dataset in enumerate(data_set_fns):\n",
    "    model = 'ah'\n",
    "    # get name of current dataset\n",
    "    data = dataset(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\", as_frame=True)\n",
    "    filename = data.filename\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        print(i)\n",
    "        pi = get_gbdt_pipeline()\n",
    "        metric = train_gbdt(X, y, i, pi, train_index, test_index, model, dataset_name, validation_size)\n",
    "        print(metric)\n",
    "        metrics_list.append(metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(metrics_list)\n",
    "df = df0.applymap(lambda x: x[0] if isinstance(x, list) else x)\n",
    "df.to_csv(current_path+'/metrics/ah_results.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA Train, Test, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLCA_adapted.csv\n",
      "0\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Concordance Index 0.5795580110497237\n",
      "Integrated Brier Score: 0.22069817668662348\n",
      "{'model': 'breslow', 'dataset': 'BLCA', 'cindex_train': [0.8630849220103987], 'cindex_test': [0.5795580110497237], 'ibs_train': [0.1442221028427697], 'ibs_score_test': [0.22069817668662348]}\n",
      "1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgbsurv/base.py\", line 126, in fit\n    return super(XGBSurv, self).fit(X_train, y_train, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1025, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/training.py\", line 185, in train\n    bst.update(dtrain, i, obj)\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/core.py\", line 1923, in update\n    grad, hess = fobj(pred, dtrain)\n                 ^^^^^^^^^^^^^^^^^^\n  File \"/Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/xgboost/sklearn.py\", line 107, in inner\n    return func(labels, preds)\n           ^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: division by zero\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m     31\u001b[0m pi \u001b[39m=\u001b[39m get_gbdt_pipeline()\n\u001b[0;32m---> 32\u001b[0m metric \u001b[39m=\u001b[39m train_gbdt(X, y, i, pi, train_index, test_index, model, dataset_name, validation_size,tcga\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(metric)\n\u001b[1;32m     34\u001b[0m metrics_list\u001b[39m.\u001b[39mappend(metric)\n",
      "File \u001b[0;32m~/Documents/xgbsurv/experiments/gbdt_pipeline/gbdt_pipeline.py:180\u001b[0m, in \u001b[0;36mtrain_gbdt\u001b[0;34m(X, y, i, pipeline, train_index, test_index, model, dataset_name, validation_size, tcga, n_iter)\u001b[0m\n\u001b[1;32m    177\u001b[0m np\u001b[39m.\u001b[39msavetxt(current_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/splits/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mmodel\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_test_index_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mdataset_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m, test_index, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    179\u001b[0m pipeline \u001b[39m=\u001b[39m get_gbdt_pipeline(tcga\u001b[39m=\u001b[39mtcga,n_iter\u001b[39m=\u001b[39mn_iter)\n\u001b[0;32m--> 180\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train, estimator__eval_test_size\u001b[39m=\u001b[39;49mvalidation_size, estimator__verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    181\u001b[0m best_preds_train \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[1;32m    182\u001b[0m best_preds_test \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "cancer_types = [\n",
    "    'BLCA',\n",
    "    'BRCA',\n",
    "    'HNSC',\n",
    "    'KIRC',\n",
    "    'LGG',\n",
    "    'LIHC',\n",
    "    'LUAD',\n",
    "    'LUSC',\n",
    "    'OV',\n",
    "    'STAD'\n",
    "    ]\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for i, cancer_type in enumerate(cancer_types):\n",
    "    model = 'breslow'\n",
    "    # get name of current dataset\n",
    "    data = load_tcga(path=\"/Users/JUSC/Documents/xgbsurv/xgbsurv/datasets/data/\",cancer_type=cancer_type, as_frame=True)\n",
    "    filename = data.filename\n",
    "    X  = data.data #.astype(np.float32)\n",
    "    y = data.target #.values #.to_numpy()\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    X, y = sort_X_y_pandas(X, y)\n",
    "    dataset_name = filename.split('_')[0]\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(outer_custom_cv.split(X, y)):\n",
    "        print(i)\n",
    "        pi = get_gbdt_pipeline()\n",
    "        metric = train_gbdt(X, y, i, pi, train_index, test_index, model, dataset_name, validation_size,tcga=True)\n",
    "        print(metric)\n",
    "        metrics_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ibs_train_mean</th>\n",
       "      <th>ibs_train_std</th>\n",
       "      <th>ibs_test_mean</th>\n",
       "      <th>ibs_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  ibs_train_mean  ibs_train_std  ibs_test_mean  ibs_test_std\n",
       "0    BLCA          0.2142         0.0043         0.2228        0.0060\n",
       "0    BRCA          0.1905         0.0046         0.1964        0.0092\n",
       "0    HNSC          0.1833         0.0055         0.2038        0.0074"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.DataFrame(metrics_list)\n",
    "df = df0.applymap(lambda x: x[0] if isinstance(x, list) else x)\n",
    "df.to_csv('ah_tcga_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
