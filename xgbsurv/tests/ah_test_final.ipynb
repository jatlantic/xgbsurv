{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgbsurv.models.utils import transform, transform_back\n",
    "from xgbsurv.models.eh_final import eh_likelihood, eh_gradient\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood, ah_objective\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood, aft_objective\n",
    "import sys\n",
    "sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import eh_likelihood_torch, eh_likelihood_torch_2, aft_likelihood_torch, ah_likelihood_torch\n",
    "import torch\n",
    "import math\n",
    "torch.set_printoptions(precision=10)\n",
    "from torch.autograd.functional import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data function\n",
    "\n",
    "def ah_data_1(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]], requires_grad=True)#.reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]) #.reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event\n",
    "\n",
    "# create data function\n",
    "\n",
    "def ah_data_2(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038], requires_grad=True).reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]).reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, linear_predictor, time, event = ah_data_1(type='torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "- Compare loss to original function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare loss to original function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EH loss from paper\n",
    "\n",
    "def eaftloss(out, time, delta): ##loss function for AFT or EH\n",
    "    ia, ib = out.size()\n",
    "    if ib == 1: ###loss function for AFT\n",
    "        n = len(delta)\n",
    "        print('aft')\n",
    "        h = 1.30*math.pow(n,-0.2)\n",
    "        #h 1.304058*math.pow(n,-0.2)  ## 1.304058*n^(-1/5) or 1.587401*math.pow(n,-0.333333) 1.587401*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(out,torch.log(time)) \n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones([1,n], dtype = out.dtype)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)     \n",
    "        A = torch.t(delta)*log_Dk/n   \n",
    "        S1 = A.sum()  \n",
    "        \n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0], dtype = out.dtype), torch.tensor([1.0], dtype = out.dtype)).cdf\n",
    "        P = ncdf(DR/h)\n",
    "        CDF_sum = torch.sum(P, dim=0)/n\n",
    "        Q = torch.log(CDF_sum)\n",
    "        S2 = -(delta*Q.view(n,1)).sum()/n\n",
    "             \n",
    "        S0 = -(delta*torch.log(time)).sum()/n\n",
    "        \n",
    "        S = S0 + S1 + S2 \n",
    "        S = -S\n",
    "    else: ### loss function for Extended hazard model\n",
    "        print('not aft model')\n",
    "        n = len(out[:,0])\n",
    "        h = 1.30*math.pow(n,-0.2)  ## or 1.59*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        g1 = out[:,0].view(n,1)\n",
    "        g2 = out[:,1].view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(g1,torch.log(time)) \n",
    "        \n",
    "        S1 =  (delta*g2).sum()/n\n",
    "        S2 = -(delta*R).sum()/n\n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones(1,n)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)  ## Dk would be zero as learning rate too large!\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)    \n",
    "        \n",
    "        S3 = (torch.t(delta)*log_Dk).sum()/n    \n",
    "        \n",
    "        # Phi((Rj-Ri)/h)\n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0])).cdf\n",
    "        P = ncdf(DR/h) \n",
    "        L = torch.exp(g2-g1)\n",
    "        LL = torch.mm(L,rawones)\n",
    "        LP_sum = torch.sum(LL*P, dim=0)/n\n",
    "        Q = torch.log(LP_sum)\n",
    "        \n",
    "        S4 = -(delta*Q.view(n,1)).sum()/n\n",
    "        \n",
    "        S = S1 + S2 + S3 + S4  \n",
    "        S = -S\n",
    "    return S\n",
    "\n",
    "def normal_density(a):  \n",
    "    b = 0.3989423*torch.exp(-0.5*torch.pow(a,2.0))\n",
    "    return b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AH Loss Original Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not aft model\n",
      "tensor(1.4591797590, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_1(type='torch')\n",
    "aft_loss_paper = eaftloss(linear_predictor, time, event)\n",
    "print(aft_loss_paper )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AH Loss Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check bandwidth, check dims vector for aft, go through code step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4591798782, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "ah_loss_own_torch = ah_likelihood_torch(linear_predictor.reshape(-1),y.reshape(-1))\n",
    "print(ah_loss_own_torch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AH Loss Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591796657817264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "ah_loss_own_numba = ah_likelihood(\n",
    "     y, linear_predictor\n",
    ")\n",
    "ah_loss_own_numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ah_loss_own_torch.detach().numpy() ,ah_loss_own_torch.detach().numpy(),ah_loss_own_numba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data function\n",
    "\n",
    "def ah_data_1(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]], requires_grad=True)#.reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]) #.reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event\n",
    "\n",
    "# create data function\n",
    "\n",
    "def ah_data_2(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038])\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038], dtype=torch.float32, requires_grad=True).reshape(-1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]],dtype=torch.float32).reshape(-1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Own Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(-1.4591798782, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ah_loss_own_torch \u001b[39m=\u001b[39m ah_likelihood_torch(linear_predictor,y)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, ah_loss_own_torch)\n\u001b[0;32m----> 5\u001b[0m ah_likelihood_torch\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(linear_predictor\u001b[39m.\u001b[39mis_leaf)\n\u001b[1;32m      7\u001b[0m \u001b[39m#linear_predictor.retain_grad()\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "#linear_predictor, y  = linear_predictor.reshape(-1), y.reshape(-1)\n",
    "ah_loss_own_torch = ah_likelihood_torch(linear_predictor,y)\n",
    "print('loss', ah_loss_own_torch)\n",
    "ah_loss_own_torch.backward()\n",
    "print(linear_predictor.is_leaf)\n",
    "#linear_predictor.retain_grad()\n",
    "grad_torch = linear_predictor.grad\n",
    "print('grad_torch', grad_torch.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AH Grad Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not aft model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0295691416, -0.0943050757],\n",
       "        [ 0.0034586210,  0.0204732958],\n",
       "        [ 0.0027502086,  0.0190855525],\n",
       "        [ 0.0024057813,  0.0286891609],\n",
       "        [-0.0071458369,  0.0496945158],\n",
       "        [-0.0419657491, -0.0426752158],\n",
       "        [ 0.0149004273, -0.0379221700],\n",
       "        [-0.0320366025,  0.0642739236],\n",
       "        [-0.0018672049, -0.0085368231],\n",
       "        [ 0.0299312249,  0.0012228340]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_1(type='torch')\n",
    "ah_loss_paper = eaftloss(linear_predictor, time, event)\n",
    "ah_loss_paper.backward()\n",
    "ah_grad_paper = linear_predictor.grad\n",
    "ah_grad_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02956914,  0.00345863,  0.00275022,  0.00240579, -0.00714583,\n",
       "       -0.04196575,  0.01490039, -0.03203659, -0.0018672 ,  0.02993121])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "grad_own, hess_own = ah_objective(\n",
    "    y, linear_predictor\n",
    ")\n",
    "grad_own"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(grad_own, ah_grad_paper[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1197987571,  0.0018476250, -0.0024721003,  0.0112646371,\n",
       "         0.0286145564,  0.0186578501, -0.0733677074,  0.0219786447,\n",
       "        -0.0648421198, -0.0534176268], grad_fn=<DiagBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.autograd.functional import hessian as hess_torch\n",
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "print(y.shape, linear_predictor.shape)\n",
    "hessian_matrix = hess_torch(ah_likelihood_torch, (linear_predictor, y), create_graph=True)\n",
    "diag_hessian = hessian_matrix[0][0].diag()\n",
    "diag_hessian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1671356 , 0.09057899, 0.08653509, 0.10661001, 0.1241162 ,\n",
       "       0.18680498, 0.242457  , 0.08737591, 0.30874032, 0.27100193])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "grad_own, hess_own = ah_objective(\n",
    "    y, linear_predictor\n",
    ")\n",
    "hess_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
