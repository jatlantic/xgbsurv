{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgbsurv.models.utils import transform, transform_back\n",
    "from xgbsurv.models.eh_final import eh_likelihood, eh_gradient\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood, ah_objective\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood, aft_objective\n",
    "import sys\n",
    "#sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "#from loss_functions_pytorch import eh_likelihood_torch, eh_likelihood_torch_2, aft_likelihood_torch, ah_likelihood_torch\n",
    "sys.path.append('/Users/JUSC/Documents/xgbsurv/experiments/deep_learning/')\n",
    "from loss_functions_pytorch import ah_likelihood_torch\n",
    "import torch\n",
    "import math\n",
    "torch.set_printoptions(precision=10)\n",
    "from torch.autograd.functional import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data function\n",
    "\n",
    "def ah_data_1(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]], requires_grad=True)#.reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]) #.reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event\n",
    "\n",
    "# create data function\n",
    "\n",
    "def ah_data_2(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038], requires_grad=True).reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]).reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, linear_predictor, time, event = ah_data_1(type='torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "- Compare loss to original function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare loss to original function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EH loss from paper\n",
    "\n",
    "def eaftloss(out, time, delta): ##loss function for AFT or EH\n",
    "    ia, ib = out.size()\n",
    "    if ib == 1: ###loss function for AFT\n",
    "        n = len(delta)\n",
    "        print('aft')\n",
    "        h = 1.30*math.pow(n,-0.2)\n",
    "        #h 1.304058*math.pow(n,-0.2)  ## 1.304058*n^(-1/5) or 1.587401*math.pow(n,-0.333333) 1.587401*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(out,torch.log(time)) \n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones([1,n], dtype = out.dtype)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)     \n",
    "        A = torch.t(delta)*log_Dk/n   \n",
    "        S1 = A.sum()  \n",
    "        \n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0], dtype = out.dtype), torch.tensor([1.0], dtype = out.dtype)).cdf\n",
    "        P = ncdf(DR/h)\n",
    "        CDF_sum = torch.sum(P, dim=0)/n\n",
    "        Q = torch.log(CDF_sum)\n",
    "        S2 = -(delta*Q.view(n,1)).sum()/n\n",
    "             \n",
    "        S0 = -(delta*torch.log(time)).sum()/n\n",
    "        \n",
    "        S = S0 + S1 + S2 \n",
    "        S = -S\n",
    "    else: ### loss function for Extended hazard model\n",
    "        print('not aft model')\n",
    "        n = len(out[:,0])\n",
    "        h = 1.30*math.pow(n,-0.2)  ## or 1.59*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        g1 = out[:,0].view(n,1)\n",
    "        g2 = out[:,1].view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(g1,torch.log(time)) \n",
    "        \n",
    "        S1 =  (delta*g2).sum()/n\n",
    "        S2 = -(delta*R).sum()/n\n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones(1,n)\n",
    "\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)  ## Dk would be zero as learning rate too large!\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)    \n",
    "        \n",
    "        S3 = (torch.t(delta)*log_Dk).sum()/n    \n",
    "        \n",
    "        # Phi((Rj-Ri)/h)\n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0])).cdf\n",
    "        P = ncdf(DR/h) \n",
    "        L = torch.exp(g2-g1)\n",
    "        LL = torch.mm(L,rawones)\n",
    "        LP_sum = torch.sum(LL*P, dim=0)/n\n",
    "        Q = torch.log(LP_sum)\n",
    "        \n",
    "        S4 = -(delta*Q.view(n,1)).sum()/n\n",
    "        \n",
    "        S = S1 + S2 + S3 + S4  \n",
    "        S = -S\n",
    "    return S\n",
    "\n",
    "def normal_density(a):  \n",
    "    b = 0.3989423*torch.exp(-0.5*torch.pow(a,2.0))\n",
    "    return b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AH Loss Original Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not aft model\n",
      "tensor(1.4591797590, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_1(type='torch')\n",
    "aft_loss_paper = eaftloss(linear_predictor, time, event)\n",
    "print(aft_loss_paper )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AH Loss Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check bandwidth, check dims vector for aft, go through code step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2782210112, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "ah_loss_own_torch = ah_likelihood_torch(linear_predictor.reshape(-1),y.reshape(-1))\n",
    "print(ah_loss_own_torch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AH Loss Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591796657817264"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "ah_loss_own_numba = ah_likelihood(\n",
    "     y, linear_predictor\n",
    ")\n",
    "ah_loss_own_numba = ah_loss_own_numba/np.sum(event)\n",
    "ah_loss_own_numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ah_loss_own_torch.detach().numpy() ,ah_loss_own_torch.detach().numpy(),ah_loss_own_numba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Larger Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "not aft model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "hazard = log_hazard = np.random.normal(0, 1, 1000)\n",
    "df = pd.read_csv('/Users/JUSC/Documents/xgbsurv_benchmarking/implementation_testing/simulation_data/survival_simulation_1000.csv')\n",
    "y = transform(df.time.values, df.event.values)\n",
    "ah_loss_own_numba = ah_likelihood(\n",
    "     y=y, linear_predictor=hazard\n",
    ")\n",
    "zero_col = np.zeros((hazard.shape[0], 1))\n",
    "# Use hstack to add the zero_col to arr\n",
    "new_haz = np.hstack((hazard.reshape(hazard.shape[0],1), zero_col))\n",
    "print(new_haz.shape)\n",
    "ah_loss_paper = eaftloss(torch.tensor(new_haz).float(), torch.tensor(df.time).float(), torch.tensor(df.event).float())\n",
    "np.allclose(ah_loss_paper, ah_loss_own_numba/df.event.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not aft model\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# grad\n",
    "linear_predictor = torch.tensor(new_haz, requires_grad=True).float()\n",
    "ah_loss_paper = eaftloss(linear_predictor, torch.tensor(df.time).float(), torch.tensor(df.event).float())\n",
    "ah_loss_paper.backward()\n",
    "ah_grad_paper = linear_predictor.grad\n",
    "print(ah_grad_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527.3451380090039"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ah_loss_own_numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data function\n",
    "\n",
    "def ah_data_1(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254925, 0.        ],\n",
    "       [0.8607798 , 0.        ],\n",
    "       [0.43557394, 0.        ],\n",
    "       [0.94059044, 0.        ],\n",
    "       [0.8446509 , 0.        ],\n",
    "       [0.23657039, 0.        ],\n",
    "       [0.7462968 , 0.        ],\n",
    "       [0.99700767, 0.        ],\n",
    "       [0.2818277 , 0.        ],\n",
    "       [0.44495037, 0.        ]], requires_grad=True)#.reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]) #.reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event\n",
    "\n",
    "# create data function\n",
    "\n",
    "def ah_data_2(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038])\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([0.67254923,\n",
    "        0.86077982,\n",
    "        0.43557393,\n",
    "        0.94059047,\n",
    "        0.8446509 ,\n",
    "        0.23657039,\n",
    "        0.74629685,\n",
    "        0.99700768,\n",
    "        0.28182768,\n",
    "        0.44495038], dtype=torch.float32, requires_grad=True).reshape(-1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]],dtype=torch.float32).reshape(-1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Own Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(-1.4591798782, grad_fn=<MulBackward0>)\n",
      "False\n",
      "grad_torch None\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "#linear_predictor, y  = linear_predictor.reshape(-1), y.reshape(-1)\n",
    "ah_loss_own_torch = ah_likelihood_torch(linear_predictor,y)\n",
    "print('loss', ah_loss_own_torch)\n",
    "ah_loss_own_torch.retain_grad()\n",
    "ah_loss_own_torch.backward()\n",
    "print(linear_predictor.is_leaf)\n",
    "grad_torch = linear_predictor.grad\n",
    "print('grad_torch', linear_predictor.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AH Grad Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not aft model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0295691416, -0.0943050757],\n",
       "        [ 0.0034586228,  0.0204732940],\n",
       "        [ 0.0027502105,  0.0190855525],\n",
       "        [ 0.0024057813,  0.0286891609],\n",
       "        [-0.0071458332,  0.0496945158],\n",
       "        [-0.0419657454, -0.0426752195],\n",
       "        [ 0.0149004273, -0.0379221700],\n",
       "        [-0.0320366025,  0.0642739236],\n",
       "        [-0.0018671975, -0.0085368231],\n",
       "        [ 0.0299312323,  0.0012228265]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_1(type='torch')\n",
    "ah_loss_paper = eaftloss(linear_predictor, time, event)\n",
    "ah_loss_paper.backward()\n",
    "ah_grad_paper = linear_predictor.grad\n",
    "ah_grad_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02956914,  0.00345863,  0.00275022,  0.00240579, -0.00714583,\n",
       "       -0.04196575,  0.01490039, -0.03203659, -0.0018672 ,  0.02993121])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "grad_own, hess_own = ah_objective(\n",
    "    y, linear_predictor\n",
    ")\n",
    "grad_own = grad_own/np.sum(event)\n",
    "grad_own"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(grad_own, ah_grad_paper[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1197987571,  0.0018476250, -0.0024721003,  0.0112646371,\n",
       "         0.0286145564,  0.0186578501, -0.0733677074,  0.0219786447,\n",
       "        -0.0648421049, -0.0534176268], grad_fn=<DiagonalBackward0_copy>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.autograd.functional import hessian as hess_torch\n",
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "print(y.shape, linear_predictor.shape)\n",
    "hessian_matrix = hess_torch(ah_likelihood_torch, (linear_predictor, y), create_graph=True)\n",
    "diag_hessian = hessian_matrix[0][0].diag()\n",
    "diag_hessian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "grad_own, hess_own = ah_objective(\n",
    "    y, linear_predictor\n",
    ")\n",
    "hess_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
