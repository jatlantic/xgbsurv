{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgbsurv.models.utils import transform, transform_back\n",
    "from xgbsurv.models.eh_final import eh_likelihood, eh_gradient\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood, ah_objective\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood, aft_objective\n",
    "import sys\n",
    "sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import eh_likelihood_torch, eh_likelihood_torch_2, aft_likelihood_torch, ah_likelihood_torch\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data function\n",
    "\n",
    "def ah_data(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254923, 0.0],\n",
    "        [0.86077982, 0.0],\n",
    "        [0.43557393, 0.0],\n",
    "        [0.94059047, 0.0],\n",
    "        [0.8446509 , 0.0],\n",
    "        [0.23657039, 0.0],\n",
    "        [0.74629685, 0.0],\n",
    "        [0.99700768, 0.0],\n",
    "        [0.28182768, 0.0],\n",
    "        [0.44495038, 0.0]],dtype='float32')\n",
    "        y = np.array([[1., -3., -3., -4., -7.,  8.,  9.,  -11.,  13.,  16.]],dtype='float32')\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254923, 0.0],\n",
    "        [0.86077982, 0.0],\n",
    "        [0.43557393, 0.0],\n",
    "        [0.94059047, 0.0],\n",
    "        [0.8446509 , 0.0],\n",
    "        [0.23657039, 0.0],\n",
    "        [0.74629685, 0.0],\n",
    "        [0.99700768, 0.0],\n",
    "        [0.28182768, 0.0],\n",
    "        [0.44495038, 0.0]], requires_grad=True)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]])\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, linear_predictor, time, event = ah_data(type='torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "- Compare loss to original function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare loss to original function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EH loss from paper\n",
    "\n",
    "def eaftloss(out, time, delta): ##loss function for AFT or EH\n",
    "    ia, ib = out.size()\n",
    "    if ib == 1: ###loss function for AFT\n",
    "        n = len(delta)\n",
    "        h = 1.30*math.pow(n,-0.2)\n",
    "        #h 1.304058*math.pow(n,-0.2)  ## 1.304058*n^(-1/5) or 1.587401*math.pow(n,-0.333333) 1.587401*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(out,torch.log(time)) \n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones([1,n], dtype = out.dtype)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)     \n",
    "        A = torch.t(delta)*log_Dk/n   \n",
    "        S1 = A.sum()  \n",
    "        \n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0], dtype = out.dtype), torch.tensor([1.0], dtype = out.dtype)).cdf\n",
    "        P = ncdf(DR/h)\n",
    "        CDF_sum = torch.sum(P, dim=0)/n\n",
    "        Q = torch.log(CDF_sum)\n",
    "        S2 = -(delta*Q.view(n,1)).sum()/n\n",
    "             \n",
    "        S0 = -(delta*torch.log(time)).sum()/n\n",
    "        \n",
    "        S = S0 + S1 + S2 \n",
    "        S = -S\n",
    "    else: ### loss function for Extended hazard model\n",
    "        n = len(out[:,0])\n",
    "        h = 1.30*math.pow(n,-0.2)  ## or 1.59*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        g1 = out[:,0].view(n,1)\n",
    "        g2 = out[:,1].view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(g1,torch.log(time)) \n",
    "        \n",
    "        S1 =  (delta*g2).sum()/n\n",
    "        S2 = -(delta*R).sum()/n\n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones(1,n)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)  ## Dk would be zero as learning rate too large!\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)    \n",
    "        \n",
    "        S3 = (torch.t(delta)*log_Dk).sum()/n    \n",
    "        \n",
    "        # Phi((Rj-Ri)/h)\n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0])).cdf\n",
    "        P = ncdf(DR/h) \n",
    "        L = torch.exp(g2-g1)\n",
    "        LL = torch.mm(L,rawones)\n",
    "        LP_sum = torch.sum(LL*P, dim=0)/n\n",
    "        Q = torch.log(LP_sum)\n",
    "        \n",
    "        S4 = -(delta*Q.view(n,1)).sum()/n\n",
    "        \n",
    "        S = S1 + S2 + S3 + S4  \n",
    "        S = -S\n",
    "    return S\n",
    "\n",
    "def normal_density(a):  \n",
    "    b = 0.3989423*torch.exp(-0.5*torch.pow(a,2.0))\n",
    "    return b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Original Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4592, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data(type='torch')\n",
    "eaftloss(linear_predictor, time, event)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss My Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67254925, 0.        ],\n",
       "       [0.8607798 , 0.        ],\n",
       "       [0.43557394, 0.        ],\n",
       "       [0.94059044, 0.        ],\n",
       "       [0.8446509 , 0.        ],\n",
       "       [0.23657039, 0.        ],\n",
       "       [0.7462968 , 0.        ],\n",
       "       [0.99700767, 0.        ],\n",
       "       [0.2818277 , 0.        ],\n",
       "       [0.44495037, 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data(type='np')\n",
    "#linear_predictor = linear_predictor[:,0]\n",
    "linear_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.792222201115036"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eh_likelihood(\n",
    "     y, linear_predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(array(float64, 2d, C), array(bool, 2d, C))\n \nThere are 22 candidate implementations:\n    - Of which 20 did not match due to:\n    Overload of function 'getitem': File: <numerous>: Line N/A.\n      With argument(s): '(array(float64, 2d, C), array(bool, 2d, C))':\n     No match.\n    - Of which 2 did not match due to:\n    Overload in function 'GetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 166.\n      With argument(s): '(array(float64, 2d, C), array(bool, 2d, C))':\n     Rejected as the implementation raised a specific error:\n       NumbaTypeError: unsupported array index type array(bool, 2d, C) in [array(bool, 2d, C)]\n  raised from /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/numba/core/typing/arraydecl.py:72\n\nDuring: typing of intrinsic-call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_aft_final.py (47)\n\nFile \"../../../../miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_aft_final.py\", line 47:\ndef aft_likelihood(\n    <source elided>\n    (_, kernel_matrix, integrated_kernel_matrix,) = difference_kernels(\n        a=R_linear_predictor, b=R_linear_predictor[event_mask], bandwidth=bandwidth\n        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y, linear_predictor, time, event \u001b[39m=\u001b[39m ah_data(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnp\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m aft_likelihood(\n\u001b[1;32m      3\u001b[0m      y, linear_predictor[:,\u001b[39m0\u001b[39;49m]\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mrstrip()\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThis error may have been caused \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby the following argument(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00margs_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[39m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39;49m\u001b[39mtyping\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mUnsupportedError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[39m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39m\u001b[39munsupported_error\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(array(float64, 2d, C), array(bool, 2d, C))\n \nThere are 22 candidate implementations:\n    - Of which 20 did not match due to:\n    Overload of function 'getitem': File: <numerous>: Line N/A.\n      With argument(s): '(array(float64, 2d, C), array(bool, 2d, C))':\n     No match.\n    - Of which 2 did not match due to:\n    Overload in function 'GetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 166.\n      With argument(s): '(array(float64, 2d, C), array(bool, 2d, C))':\n     Rejected as the implementation raised a specific error:\n       NumbaTypeError: unsupported array index type array(bool, 2d, C) in [array(bool, 2d, C)]\n  raised from /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/numba/core/typing/arraydecl.py:72\n\nDuring: typing of intrinsic-call at /Users/JUSC/miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_aft_final.py (47)\n\nFile \"../../../../miniconda3/envs/xgbsurv/lib/python3.10/site-packages/xgbsurv/models/eh_aft_final.py\", line 47:\ndef aft_likelihood(\n    <source elided>\n    (_, kernel_matrix, integrated_kernel_matrix,) = difference_kernels(\n        a=R_linear_predictor, b=R_linear_predictor[event_mask], bandwidth=bandwidth\n        ^\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data(type='np')\n",
    "aft_likelihood(\n",
    "     y, linear_predictor[:,0]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare Pytorch loss with numpy loss\n",
    "\n",
    "- let's keep bandwidth fixed for that\n",
    "- random data\n",
    "\n",
    "linear_predictor = np.array([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]])\n",
    "\n",
    "y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mock data\n",
    "linear_predictor = np.array([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]])\n",
    "linear_predictor = linear_predictor[:,0]\n",
    "linear_predictor_torch = torch.tensor(linear_predictor, requires_grad=True)\n",
    "\n",
    "y = np.array([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],\n",
    "              [1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]).reshape(10,2)\n",
    "y_torch = torch.from_numpy(y[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare Pytorch gradient with gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10978369  0.0032265   0.00291     0.00932027 -0.00986356 -0.02184597\n",
      "  0.00447101  0.01240073  0.07544714  0.03371756]\n"
     ]
    }
   ],
   "source": [
    "a1 = ah_likelihood_torch(linear_predictor_torch, y_torch)\n",
    "a1.backward()\n",
    "#print(linear_predictor_torch.grad)\n",
    "print(linear_predictor_torch.grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67254923, 0.86077982, 0.43557393, 0.94059047, 0.8446509 ,\n",
       "       0.23657039, 0.74629685, 0.99700768, 0.28182768, 0.44495038])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10978369, -0.00322649, -0.00290998, -0.0093203 ,  0.00986353,\n",
       "        0.02184597, -0.004471  , -0.01240071, -0.07544713, -0.03371757])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ah_objective(\n",
    "    time=np.abs(y[:,0]),\n",
    "    event=(y[:,0] > 0).astype(int),\n",
    "    linear_predictor=linear_predictor\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67254923, 0.86077982, 0.43557393, 0.94059047, 0.8446509 ,\n",
       "       0.23657039, 0.74629685, 0.99700768, 0.28182768, 0.44495038])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(linear_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,  -3.,  -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.,   1.,  -3.,\n",
       "         -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_torch.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,  -3.,  -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.,   1.,  -3.,\n",
       "         -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_torch.tile(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m bandwidth \u001b[39m=\u001b[39m \u001b[39m1.30\u001b[39m \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mpow(n_samples, \u001b[39m-\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      4\u001b[0m linear_predictor_torch \u001b[39m=\u001b[39m linear_predictor_torch[:,\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m l1\u001b[39m=\u001b[39m aft_likelihood_torch(y_torch, linear_predictor_torch[:,\u001b[39m1\u001b[39;49m], sample_weight\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, bandwidth \u001b[39m=\u001b[39m bandwidth )\n\u001b[1;32m      6\u001b[0m l1\u001b[39m.\u001b[39mretain_grad()\n\u001b[1;32m      7\u001b[0m l1\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "import math\n",
    "n_samples: int = y.shape[0]\n",
    "bandwidth = 1.30 * math.pow(n_samples, -0.2)\n",
    "linear_predictor_torch = linear_predictor_torch[:,1]\n",
    "l1= aft_likelihood_torch(y_torch, linear_predictor_torch[:,1], sample_weight=1.0, bandwidth = bandwidth )\n",
    "l1.retain_grad()\n",
    "l1.backward()\n",
    "print(linear_predictor_torch.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
