{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_np = np.array([1.0,1.0,1.0,3.0,5.0,5.0,5.0,8.0])\n",
    "event_np = np.array([1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0])\n",
    "time_torch = torch.tensor(time_np)\n",
    "event_torch = torch.tensor(event_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KaplanMeier(time: np.array, event: np.array, \n",
    "                cens_dist: bool = False\n",
    ") -> tuple[np.array, np.array] | tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : npt.NDArray[float]\n",
    "        _description_\n",
    "    event : npt.NDArray[int]\n",
    "        _description_\n",
    "    cens_dist : bool, optional\n",
    "        _description_, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[npt.NDArray[float], npt.NDArray[float]] | tuple[npt.NDArray[float], npt.NDArray[float], npt.NDArray[int]]\n",
    "        _description_\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Kaplan, E. L. and Meier, P., \"Nonparametric estimation from incomplete observations\",\n",
    "           Journal of The American Statistical Association, vol. 53, pp. 457-481, 1958.\n",
    "    .. [2] S. Pölsterl, “scikit-survival: A Library for Time-to-Event Analysis Built on Top of scikit-learn,”\n",
    "           Journal of Machine Learning Research, vol. 21, no. 212, pp. 1–6, 2020.\n",
    "    \"\"\"\n",
    "    # similar approach to sksurv, but no loops\n",
    "    # even and censored is other way round in sksurv ->clarify\n",
    "    #time, event = transform_back(y)\n",
    "    # order, remove later\n",
    "    is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "    \n",
    "    if is_sorted(time) == False:\n",
    "        order = np.argsort(time, kind=\"mergesort\")\n",
    "        time = time[order]\n",
    "        event = event[order]\n",
    "    \n",
    "    times = np.unique(time)\n",
    "    idx = np.digitize(time, np.unique(time))\n",
    "    # numpy diff nth discrete difference over index, add 1 at the beginning\n",
    "    breaks = np.flatnonzero(np.concatenate(([1], np.diff(idx))))\n",
    "\n",
    "    # flatnonzero return indices that are nonzero in flattened version\n",
    "    n_events = np.add.reduceat(event, breaks, axis=0)\n",
    "    n_at_risk = np.sum(np.unique((np.outer(time,time)>=np.square(time)).astype(int).T,axis=0),axis=1)[::-1]\n",
    "    print(n_at_risk)\n",
    "    \n",
    "    # censoring distribution for ipcw estimation\n",
    "    #n_censored a vector, with 1 at censoring position, zero elsewhere\n",
    "    n_events = n_events.astype(np.float32)\n",
    "    n_at_risk = n_at_risk.astype(np.float32)\n",
    "    if cens_dist:\n",
    "        n_at_risk -= n_events\n",
    "        # for each unique time step how many observations are censored\n",
    "        censored = 1-event\n",
    "        n_censored = np.add.reduceat(censored, breaks, axis=0)\n",
    "        mask = (n_events != 0)\n",
    "        vals = 1-np.divide(\n",
    "        n_censored, n_at_risk,\n",
    "        out=np.zeros(times.shape[0], dtype=float),\n",
    "        where=n_censored != 0,\n",
    "    )\n",
    "        estimates = np.cumprod(vals)\n",
    "        return times, estimates, n_censored\n",
    "\n",
    "\n",
    "    else:\n",
    "        vals = 1-np.divide(\n",
    "        n_events, n_at_risk,\n",
    "        out=np.zeros(times.shape[0], dtype=float),\n",
    "        where=n_events != 0,\n",
    "        )\n",
    "        estimates = np.cumprod(vals)\n",
    "        return times, estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 5 4 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1., 3., 5., 8.]), array([1. , 1. , 0.5, 0.5]), array([0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KaplanMeier(time_np, event_np, cens_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 3., 5., 5., 5., 8.])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KaplanMeier_torch(time: np.array, event: np.array, \n",
    "                cens_dist: bool = False\n",
    ") -> tuple[np.array, np.array] | tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : npt.NDArray[float]\n",
    "        _description_\n",
    "    event : npt.NDArray[int]\n",
    "        _description_\n",
    "    cens_dist : bool, optional\n",
    "        _description_, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[npt.NDArray[float], npt.NDArray[float]] | tuple[npt.NDArray[float], npt.NDArray[float], npt.NDArray[int]]\n",
    "        _description_\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Kaplan, E. L. and Meier, P., \"Nonparametric estimation from incomplete observations\",\n",
    "           Journal of The American Statistical Association, vol. 53, pp. 457-481, 1958.\n",
    "    .. [2] S. Pölsterl, “scikit-survival: A Library for Time-to-Event Analysis Built on Top of scikit-learn,”\n",
    "           Journal of Machine Learning Research, vol. 21, no. 212, pp. 1–6, 2020.\n",
    "    \"\"\"\n",
    "    # similar approach to sksurv, but no loops\n",
    "    # even and censored is other way round in sksurv ->clarify\n",
    "    #time, event = transform_back(y)\n",
    "    # order, remove later\n",
    "    #is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "    \n",
    "    # if is_sorted(time) == False:\n",
    "    #     order = np.argsort(time, kind=\"mergesort\")\n",
    "    #     time = time[order]\n",
    "    #     event = event[order]\n",
    "    \n",
    "    times = torch.unique(time)\n",
    "    #idx = np.digitize(time, np.unique(time))\n",
    "    # numpy diff nth discrete difference over index, add 1 at the beginning\n",
    "    #breaks = np.flatnonzero(np.concatenate(([1], np.diff(idx))))\n",
    "\n",
    "    # flatnonzero return indices that are nonzero in flattened version\n",
    "    #n_events = np.add.reduceat(event, breaks, axis=0)\n",
    "    unique_times, inverse_indices = time.unique(return_inverse=True)\n",
    "\n",
    "    # Prepare a tensor for the event counts\n",
    "    event_counts = torch.zeros_like(unique_times)\n",
    "\n",
    "    # Add up the events for each unique time using scatter_add_\n",
    "    event_counts.scatter_add_(0, inverse_indices, event)\n",
    "    n_events = event_counts\n",
    "    n_at_risk = torch.unique((torch.outer(time,time)>=np.square(time)).int().T, dim=0).sum(axis=1).flip(0)\n",
    "    print('n_at_risk', n_at_risk)\n",
    "    n_at_risk = n_at_risk.float()\n",
    "    n_events = n_events.float()\n",
    "    # censoring distribution for ipcw estimation\n",
    "    #n_censored a vector, with 1 at censoring position, zero elsewhere\n",
    "    print('n_at_risk shape',n_at_risk.shape)\n",
    "    print('n_events shape',n_events.shape)\n",
    "    if cens_dist:\n",
    "        n_at_risk -= n_events\n",
    "        # for each unique time step how many observations are censored\n",
    "        censored = 1-event\n",
    "        n_censored = torch.zeros_like(unique_times)\n",
    "        #n_censored = np.add.reduceat(censored, breaks, axis=0)\n",
    "        n_censored.scatter_add_(0, inverse_indices, censored)\n",
    "        mask = (n_censored != 0)\n",
    "        c = torch.zeros_like(times)\n",
    "        # apply the division operation only where mask is True\n",
    "        c[mask] = n_censored[mask] / n_at_risk[mask] \n",
    "        vals = 1-c\n",
    "        estimates = torch.cumprod(vals, dim=0)\n",
    "        return times, estimates, n_censored\n",
    "\n",
    "\n",
    "    else:\n",
    "        mask = (n_events != 0)\n",
    "        vals = 1-torch.divide(\n",
    "        n_events[mask], n_at_risk[mask],\n",
    "        #rounding_mode=None,\n",
    "        out=torch.zeros(times.shape[0]),\n",
    "        #where=mask,\n",
    "        )\n",
    "        print(vals)\n",
    "        estimates = torch.cumprod(vals, dim=0)\n",
    "        return times, estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KaplanMeier(time_np, event_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KaplanMeier_torch(time_torch, event_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 3., 5., 8.], dtype=float32),\n",
       " array([1. , 1. , 0.5, 0.5]),\n",
       " array([0., 0., 1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KaplanMeier(time_np.astype(np.float32), event_np.astype(np.float32),cens_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_at_risk tensor([8, 5, 4, 1])\n",
      "n_at_risk shape torch.Size([4])\n",
      "n_events shape torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3., 5., 8.], dtype=torch.float64),\n",
       " tensor([1.0000, 1.0000, 0.5000, 0.5000], dtype=torch.float64),\n",
       " tensor([0., 0., 1., 0.], dtype=torch.float64))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KaplanMeier_torch(time_torch, event_torch,cens_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IPCW Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipcw_estimate(time: np.array, event: np.array) -> tuple[np.array, np.array]:\n",
    "\n",
    "    unique_time, cens_dist, n_censored = KaplanMeier(time, event, cens_dist=True) \n",
    "    #print(cens_dist)\n",
    "    # similar approach to sksurv\n",
    "    idx = np.searchsorted(unique_time, time)\n",
    "    est = 1.0/cens_dist[idx] # improve as divide by zero\n",
    "    est[n_censored[idx]!=0] = 0\n",
    "    # in R mboost there is a maxweight of 5\n",
    "    est[est>5] = 5\n",
    "    return unique_time, est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipcw_estimate_torch(time: np.array, event: np.array) -> tuple[np.array, np.array]:\n",
    "\n",
    "    print(time.shape, event.shape)\n",
    "    unique_time, cens_dist, n_censored = KaplanMeier_torch(time, event, cens_dist=True) \n",
    "    #print(cens_dist)\n",
    "    # similar approach to sksurv\n",
    "    idx = torch.searchsorted(unique_time, time)\n",
    "    est = 1.0/cens_dist[idx] # improve as divide by zero\n",
    "    est[n_censored[idx]!=0] = 0\n",
    "    # in R mboost there is a maxweight of 5\n",
    "    est[est>5] = 5\n",
    "    return unique_time, est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 3., 5., 8.]), array([1., 1., 1., 1., 0., 0., 0., 2.]))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipcw_estimate(time_np, event_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) torch.Size([8])\n",
      "n_at_risk tensor([8, 5, 4, 1])\n",
      "n_at_risk shape torch.Size([4])\n",
      "n_events shape torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3., 5., 8.], dtype=torch.float64),\n",
       " tensor([1., 1., 1., 1., 0., 0., 0., 2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipcw_estimate_torch(time_torch, event_torch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_torch(time: torch.Tensor, event: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Transforms time, event into XGBoost digestable format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : npt.NDArray[float]\n",
    "        Survival time.\n",
    "    event : npt.NDArray[int]\n",
    "        Boolean event indicator. Zero value is taken as censored event.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : npt.NDArray[float]\n",
    "        Transformed array containing survival time and event where negative value is taken as censored event.\n",
    "    \"\"\"\n",
    "    #if isinstance(time, pd.Series):\n",
    "    #    time = time.to_numpy()\n",
    "    #    event = event.to_numpy()\n",
    "    event_mod = event.clone()\n",
    "    event_mod[event_mod==0] = -1\n",
    "    if (time==0).any():\n",
    "        raise RuntimeError('Data contains zero time value!')\n",
    "        # alternative: time[time==0] = np.finfo(float).eps\n",
    "    y = event_mod*time\n",
    "    return y.to(torch.float32)\n",
    "\n",
    "\n",
    "def transform_back_torch(y: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Transforms XGBoost digestable format variable y into time and event.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : npt.NDArray[float]\n",
    "        Array containing survival time and event where negative value is taken as censored event.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[npt.NDArray[float],npt.NDArray[int]]\n",
    "        Survival time and event.\n",
    "    \"\"\"\n",
    "    time = torch.abs(y)\n",
    "    event = (torch.abs(y) == y)\n",
    "    event = event # for numba\n",
    "    return time.to(torch.float32), event.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(y, approach: str='paper') -> np.array:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : npt.NDArray[float]\n",
    "        Sorted array containing survival time and event where negative value is taken as censored event.\n",
    "    approach : str, optional\n",
    "        Choose mboost implementation or paper implementation of c-boosting, by default 'paper'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npt.NDArray[float]\n",
    "        Array of weights.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] 1. Mayr, A. & Schmid, M. Boosting the concordance index for survival data–a unified framework to derive and evaluate biomarker combinations. \n",
    "       PloS one 9, e84483 (2014).\n",
    "\n",
    "    \"\"\"\n",
    "    time, event = transform_back(y) \n",
    "    n = event.shape[0]\n",
    "\n",
    "    _, ipcw_new = ipcw_estimate(time, event)\n",
    "\n",
    "    ipcw = ipcw_new #ipcw_old\n",
    "    survtime = time\n",
    "    wweights = np.full((n,n), np.square(ipcw)).T # good here\n",
    "\n",
    "    weightsj = np.full((n,n), survtime).T\n",
    "\n",
    "    weightsk = np.full((n,n), survtime) #byrow = TRUE in R, in np automatic no T required\n",
    "\n",
    "    if approach == 'mboost':\n",
    "        # implementing   weightsI <- ifelse(weightsj == weightsk, .5, (weightsj < weightsk) + 0) - diag(.5, n,n)\n",
    "        # from mboost github repo\n",
    "        weightsI = np.empty((n,n))\n",
    "        weightsI[weightsj == weightsk] = 0.5\n",
    "        weightsI = (weightsj < weightsk).astype(int)\n",
    "        weightsI = weightsI - np.diag(0.5*np.ones(n))\n",
    "    if approach == 'paper':\n",
    "        weightsI = (weightsj < weightsk).astype(int) \n",
    "\n",
    "    wweights = wweights * weightsI \n",
    "    \n",
    "    wweights = wweights / np.sum(wweights)\n",
    "\n",
    "    return wweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights_torch(y, approach: str='paper') -> np.array:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : npt.NDArray[float]\n",
    "        Sorted array containing survival time and event where negative value is taken as censored event.\n",
    "    approach : str, optional\n",
    "        Choose mboost implementation or paper implementation of c-boosting, by default 'paper'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npt.NDArray[float]\n",
    "        Array of weights.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] 1. Mayr, A. & Schmid, M. Boosting the concordance index for survival data–a unified framework to derive and evaluate biomarker combinations. \n",
    "       PloS one 9, e84483 (2014).\n",
    "\n",
    "    \"\"\"\n",
    "    time, event = transform_back_torch(y) \n",
    "    print('time shape', time.shape)\n",
    "    print('event shape', event.shape)\n",
    "    n = event.shape[0]\n",
    "\n",
    "    _, ipcw_new = ipcw_estimate_torch(time, event)\n",
    "\n",
    "    ipcw = ipcw_new #ipcw_old consider copy\n",
    "    survtime = time\n",
    "\n",
    "    fill = np.square(ipcw)\n",
    "    wweights = fill.repeat(n,1).T\n",
    "    # wweights = torch.full((n,n), np.square(ipcw)).T # good here\n",
    "\n",
    "    # weightsj = torch.full((n,n), survtime).T\n",
    "    weightsj = survtime.repeat(n,1).T\n",
    "    # weightsk = torch.full((n,n), survtime) #byrow = TRUE in R, in np automatic no T required\n",
    "    weightsk = survtime.repeat(n,1)\n",
    "    \n",
    "    if approach == 'mboost':\n",
    "        # implementing   weightsI <- ifelse(weightsj == weightsk, .5, (weightsj < weightsk) + 0) - diag(.5, n,n)\n",
    "        # from mboost github repo\n",
    "        weightsI = torch.empty((n,n))\n",
    "        weightsI[weightsj == weightsk] = 0.5\n",
    "        weightsI = (weightsj < weightsk).astype(int)\n",
    "        weightsI = weightsI - torch.diag(0.5*np.ones(n))\n",
    "    if approach == 'paper':\n",
    "        weightsI = (weightsj < weightsk).int()\n",
    "\n",
    "    wweights = wweights * weightsI \n",
    "    \n",
    "    wweights = wweights / torch.sum(wweights)\n",
    "\n",
    "    return wweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgbsurv.models.utils import transform\n",
    "predictor = log_hazard = np.random.normal(0, 1, 1000)\n",
    "df = pd.read_csv('/Users/JUSC/Documents/xgbsurv_benchmarking/implementation_testing/simulation_data/survival_simulation_1000.csv')\n",
    "y = transform(df.time.to_numpy(), df.event.to_numpy())\n",
    "y_torch = torch.tensor(y)\n",
    "predictor_torch = torch.tensor(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/dh6mkdzs31lc5pkqymtdbh180000gp/T/ipykernel_6861/2412397353.py:7: RuntimeWarning: divide by zero encountered in divide\n",
      "  est = 1.0/cens_dist[idx] # improve as divide by zero\n"
     ]
    }
   ],
   "source": [
    "wweights0 = compute_weights(y, approach='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time shape torch.Size([1000])\n",
      "event shape torch.Size([1000])\n",
      "torch.Size([1000]) torch.Size([1000])\n",
      "n_at_risk tensor([1000,  999,  998,  997,  996,  995,  994,  993,  992,  991,  990,  989,\n",
      "         988,  987,  986,  985,  984,  983,  982,  981,  980,  979,  978,  977,\n",
      "         976,  975,  974,  973,  972,  971,  970,  969,  968,  967,  966,  965,\n",
      "         964,  963,  962,  961,  960,  959,  958,  957,  956,  955,  954,  953,\n",
      "         952,  951,  950,  949,  948,  947,  946,  945,  944,  943,  942,  941,\n",
      "         940,  939,  938,  937,  936,  935,  934,  933,  932,  931,  930,  929,\n",
      "         928,  927,  926,  925,  924,  923,  922,  921,  920,  919,  918,  917,\n",
      "         916,  915,  914,  913,  912,  911,  910,  909,  908,  907,  906,  905,\n",
      "         904,  903,  902,  901,  900,  899,  898,  897,  896,  895,  894,  893,\n",
      "         892,  891,  890,  889,  888,  887,  886,  885,  884,  883,  882,  881,\n",
      "         880,  879,  878,  877,  876,  875,  874,  873,  872,  871,  870,  869,\n",
      "         868,  867,  866,  865,  864,  863,  862,  861,  860,  859,  858,  857,\n",
      "         856,  855,  854,  853,  852,  851,  850,  849,  848,  847,  846,  845,\n",
      "         844,  843,  842,  841,  840,  839,  838,  837,  836,  835,  834,  833,\n",
      "         832,  831,  830,  829,  828,  827,  826,  825,  824,  823,  822,  821,\n",
      "         820,  819,  818,  817,  816,  815,  814,  813,  812,  811,  810,  809,\n",
      "         808,  807,  806,  805,  804,  803,  802,  801,  800,  799,  798,  797,\n",
      "         796,  795,  794,  793,  792,  791,  790,  789,  788,  787,  786,  785,\n",
      "         784,  783,  782,  781,  780,  779,  778,  777,  776,  775,  774,  773,\n",
      "         772,  771,  770,  769,  768,  767,  766,  765,  764,  763,  762,  761,\n",
      "         760,  759,  758,  757,  756,  755,  754,  753,  752,  751,  750,  749,\n",
      "         748,  747,  746,  745,  744,  743,  742,  741,  740,  739,  738,  737,\n",
      "         736,  735,  734,  733,  732,  731,  730,  729,  728,  727,  726,  725,\n",
      "         724,  723,  722,  721,  720,  719,  718,  717,  716,  715,  714,  713,\n",
      "         712,  711,  710,  709,  708,  707,  706,  705,  704,  703,  702,  701,\n",
      "         700,  699,  698,  697,  696,  695,  694,  693,  692,  691,  690,  689,\n",
      "         688,  687,  686,  685,  684,  683,  682,  681,  680,  679,  678,  677,\n",
      "         676,  675,  674,  673,  672,  671,  670,  669,  668,  667,  666,  665,\n",
      "         664,  663,  662,  661,  660,  659,  658,  657,  656,  655,  654,  653,\n",
      "         652,  651,  650,  649,  648,  647,  646,  645,  644,  643,  642,  641,\n",
      "         640,  639,  638,  637,  636,  635,  634,  633,  632,  631,  630,  629,\n",
      "         628,  627,  626,  625,  624,  623,  622,  621,  620,  619,  618,  617,\n",
      "         616,  615,  614,  613,  612,  611,  610,  609,  608,  607,  606,  605,\n",
      "         604,  603,  602,  601,  600,  599,  598,  597,  596,  595,  594,  593,\n",
      "         592,  591,  590,  589,  588,  587,  586,  585,  584,  583,  582,  581,\n",
      "         580,  579,  578,  577,  576,  575,  574,  573,  572,  571,  570,  569,\n",
      "         568,  567,  566,  565,  564,  563,  562,  561,  560,  559,  558,  557,\n",
      "         556,  555,  554,  553,  552,  551,  550,  549,  548,  547,  546,  545,\n",
      "         544,  543,  542,  541,  540,  539,  538,  537,  536,  535,  534,  533,\n",
      "         532,  531,  530,  529,  528,  527,  526,  525,  524,  523,  522,  521,\n",
      "         520,  519,  518,  517,  516,  515,  514,  513,  512,  511,  510,  509,\n",
      "         508,  507,  506,  505,  504,  503,  502,  501,  500,  499,  498,  497,\n",
      "         496,  495,  494,  493,  492,  491,  490,  489,  488,  487,  486,  485,\n",
      "         484,  483,  482,  481,  480,  479,  478,  477,  476,  475,  474,  473,\n",
      "         472,  471,  470,  469,  468,  467,  466,  465,  464,  463,  462,  461,\n",
      "         460,  459,  458,  457,  456,  455,  454,  453,  452,  451,  450,  449,\n",
      "         448,  447,  446,  445,  444,  443,  442,  441,  440,  439,  438,  437,\n",
      "         436,  435,  434,  433,  432,  431,  430,  429,  428,  427,  426,  425,\n",
      "         424,  423,  422,  421,  420,  419,  418,  417,  416,  415,  414,  413,\n",
      "         412,  411,  410,  409,  408,  407,  406,  405,  404,  403,  402,  401,\n",
      "         400,  399,  398,  397,  396,  395,  394,  393,  392,  391,  390,  389,\n",
      "         388,  387,  386,  385,  384,  383,  382,  381,  380,  379,  378,  377,\n",
      "         376,  375,  374,  373,  372,  371,  370,  369,  368,  367,  366,  365,\n",
      "         364,  363,  362,  361,  360,  359,  358,  357,  356,  355,  354,  353,\n",
      "         352,  351,  350,  349,  348,  347,  346,  345,  344,  343,  342,  341,\n",
      "         340,  339,  338,  337,  336,  335,  334,  333,  332,  331,  330,  329,\n",
      "         328,  327,  326,  325,  324,  323,  322,  321,  320,  319,  318,  317,\n",
      "         316,  315,  314,  313,  312,  311,  310,  309,  308,  307,  306,  305,\n",
      "         304,  303,  302,  301,  300,  299,  298,  297,  296,  295,  294,  293,\n",
      "         292,  291,  290,  289,  288,  287,  286,  285,  284,  283,  282,  281,\n",
      "         280,  279,  278,  277,  276,  275,  274,  273,  272,  271,  270,  269,\n",
      "         268,  267,  266,  265,  264,  263,  262,  261,  260,  259,  258,  257,\n",
      "         256,  255,  254,  253,  252,  251,  250,  249,  248,  247,  246,  245,\n",
      "         244,  243,  242,  241,  240,  239,  238,  237,  236,  235,  234,  233,\n",
      "         232,  231,  230,  229,  228,  227,  226,  225,  224,  223,  222,  221,\n",
      "         220,  219,  218,  217,  216,  215,  214,  213,  212,  211,  210,  209,\n",
      "         208,  207,  206,  205,  204,  203,  202,  201,  200,  199,  198,  197,\n",
      "         196,  195,  194,  193,  192,  191,  190,  189,  188,  187,  186,  185,\n",
      "         184,  183,  182,  181,  180,  179,  178,  177,  176,  175,  174,  173,\n",
      "         172,  171,  170,  169,  168,  167,  166,  165,  164,  163,  162,  161,\n",
      "         160,  159,  158,  157,  156,  155,  154,  153,  152,  151,  150,  149,\n",
      "         148,  147,  146,  145,  144,  143,  142,  141,  140,  139,  138,  137,\n",
      "         136,  135,  134,  133,  132,  131,  130,  129,  128,  127,  126,  125,\n",
      "         124,  123,  122,  121,  120,  119,  118,  117,  116,  115,  114,  113,\n",
      "         112,  111,  110,  109,  108,  107,  106,  105,  104,  103,  102,  101,\n",
      "         100,   99,   98,   97,   96,   95,   94,   93,   92,   91,   90,   89,\n",
      "          88,   87,   86,   85,   84,   83,   82,   81,   80,   79,   78,   77,\n",
      "          76,   75,   74,   73,   72,   71,   70,   69,   68,   67,   66,   65,\n",
      "          64,   63,   62,   61,   60,   59,   58,   57,   56,   55,   54,   53,\n",
      "          52,   51,   50,   49,   48,   47,   46,   45,   44,   43,   42,   41,\n",
      "          40,   39,   38,   37,   36,   35,   34,   33,   32,   31,   30,   29,\n",
      "          28,   27,   26,   25,   24,   23,   22,   21,   20,   19,   18,   17,\n",
      "          16,   15,   14,   13,   12,   11,   10,    9,    8,    7,    6,    5,\n",
      "           4,    3,    2,    1])\n",
      "n_at_risk shape torch.Size([1000])\n",
      "n_events shape torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "wweights1 = compute_weights_torch(y_torch, approach='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(wweights0, wweights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgbsurv.models.utils import transform_back\n",
    "\n",
    "def cind_loss(y, predictor, sigma = 0.1) ->np.array:\n",
    "    # f corresponds to predictor in paper\n",
    "    time, _ = transform_back(y)\n",
    "    n = time.shape[0]\n",
    "    etaj = np.full((n,n), predictor)\n",
    "    etak = np.full((n,n), predictor).T\n",
    "    x = (etak - etaj) \n",
    "    weights_out = compute_weights(y)\n",
    "    c_loss = 1/(1+np.exp(x/sigma))*weights_out\n",
    "    return -np.sum(c_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cind_loss_torch(y: np.array, predictor: np.array, sigma: np.array = 0.1) -> np.array:\n",
    "    # f corresponds to predictor in paper\n",
    "    time, _ = transform_back_torch(y)\n",
    "    n = time.shape[0]\n",
    "    #etaj = np.full((n,n), predictor)\n",
    "    etaj = predictor.repeat(n,1)\n",
    "    #etak = np.full((n,n), predictor).T\n",
    "    etak = predictor.repeat(n,1).T\n",
    "    x = (etak - etaj) \n",
    "    weights_out = compute_weights_torch(y)\n",
    "    c_loss = 1/(1+torch.exp(x/sigma))*weights_out\n",
    "    return -torch.sum(c_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/dh6mkdzs31lc5pkqymtdbh180000gp/T/ipykernel_6861/2412397353.py:7: RuntimeWarning: divide by zero encountered in divide\n",
      "  est = 1.0/cens_dist[idx] # improve as divide by zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.5122171753396544"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cind_loss(y, predictor, sigma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time shape torch.Size([1000])\n",
      "event shape torch.Size([1000])\n",
      "torch.Size([1000]) torch.Size([1000])\n",
      "n_at_risk tensor([1000,  999,  998,  997,  996,  995,  994,  993,  992,  991,  990,  989,\n",
      "         988,  987,  986,  985,  984,  983,  982,  981,  980,  979,  978,  977,\n",
      "         976,  975,  974,  973,  972,  971,  970,  969,  968,  967,  966,  965,\n",
      "         964,  963,  962,  961,  960,  959,  958,  957,  956,  955,  954,  953,\n",
      "         952,  951,  950,  949,  948,  947,  946,  945,  944,  943,  942,  941,\n",
      "         940,  939,  938,  937,  936,  935,  934,  933,  932,  931,  930,  929,\n",
      "         928,  927,  926,  925,  924,  923,  922,  921,  920,  919,  918,  917,\n",
      "         916,  915,  914,  913,  912,  911,  910,  909,  908,  907,  906,  905,\n",
      "         904,  903,  902,  901,  900,  899,  898,  897,  896,  895,  894,  893,\n",
      "         892,  891,  890,  889,  888,  887,  886,  885,  884,  883,  882,  881,\n",
      "         880,  879,  878,  877,  876,  875,  874,  873,  872,  871,  870,  869,\n",
      "         868,  867,  866,  865,  864,  863,  862,  861,  860,  859,  858,  857,\n",
      "         856,  855,  854,  853,  852,  851,  850,  849,  848,  847,  846,  845,\n",
      "         844,  843,  842,  841,  840,  839,  838,  837,  836,  835,  834,  833,\n",
      "         832,  831,  830,  829,  828,  827,  826,  825,  824,  823,  822,  821,\n",
      "         820,  819,  818,  817,  816,  815,  814,  813,  812,  811,  810,  809,\n",
      "         808,  807,  806,  805,  804,  803,  802,  801,  800,  799,  798,  797,\n",
      "         796,  795,  794,  793,  792,  791,  790,  789,  788,  787,  786,  785,\n",
      "         784,  783,  782,  781,  780,  779,  778,  777,  776,  775,  774,  773,\n",
      "         772,  771,  770,  769,  768,  767,  766,  765,  764,  763,  762,  761,\n",
      "         760,  759,  758,  757,  756,  755,  754,  753,  752,  751,  750,  749,\n",
      "         748,  747,  746,  745,  744,  743,  742,  741,  740,  739,  738,  737,\n",
      "         736,  735,  734,  733,  732,  731,  730,  729,  728,  727,  726,  725,\n",
      "         724,  723,  722,  721,  720,  719,  718,  717,  716,  715,  714,  713,\n",
      "         712,  711,  710,  709,  708,  707,  706,  705,  704,  703,  702,  701,\n",
      "         700,  699,  698,  697,  696,  695,  694,  693,  692,  691,  690,  689,\n",
      "         688,  687,  686,  685,  684,  683,  682,  681,  680,  679,  678,  677,\n",
      "         676,  675,  674,  673,  672,  671,  670,  669,  668,  667,  666,  665,\n",
      "         664,  663,  662,  661,  660,  659,  658,  657,  656,  655,  654,  653,\n",
      "         652,  651,  650,  649,  648,  647,  646,  645,  644,  643,  642,  641,\n",
      "         640,  639,  638,  637,  636,  635,  634,  633,  632,  631,  630,  629,\n",
      "         628,  627,  626,  625,  624,  623,  622,  621,  620,  619,  618,  617,\n",
      "         616,  615,  614,  613,  612,  611,  610,  609,  608,  607,  606,  605,\n",
      "         604,  603,  602,  601,  600,  599,  598,  597,  596,  595,  594,  593,\n",
      "         592,  591,  590,  589,  588,  587,  586,  585,  584,  583,  582,  581,\n",
      "         580,  579,  578,  577,  576,  575,  574,  573,  572,  571,  570,  569,\n",
      "         568,  567,  566,  565,  564,  563,  562,  561,  560,  559,  558,  557,\n",
      "         556,  555,  554,  553,  552,  551,  550,  549,  548,  547,  546,  545,\n",
      "         544,  543,  542,  541,  540,  539,  538,  537,  536,  535,  534,  533,\n",
      "         532,  531,  530,  529,  528,  527,  526,  525,  524,  523,  522,  521,\n",
      "         520,  519,  518,  517,  516,  515,  514,  513,  512,  511,  510,  509,\n",
      "         508,  507,  506,  505,  504,  503,  502,  501,  500,  499,  498,  497,\n",
      "         496,  495,  494,  493,  492,  491,  490,  489,  488,  487,  486,  485,\n",
      "         484,  483,  482,  481,  480,  479,  478,  477,  476,  475,  474,  473,\n",
      "         472,  471,  470,  469,  468,  467,  466,  465,  464,  463,  462,  461,\n",
      "         460,  459,  458,  457,  456,  455,  454,  453,  452,  451,  450,  449,\n",
      "         448,  447,  446,  445,  444,  443,  442,  441,  440,  439,  438,  437,\n",
      "         436,  435,  434,  433,  432,  431,  430,  429,  428,  427,  426,  425,\n",
      "         424,  423,  422,  421,  420,  419,  418,  417,  416,  415,  414,  413,\n",
      "         412,  411,  410,  409,  408,  407,  406,  405,  404,  403,  402,  401,\n",
      "         400,  399,  398,  397,  396,  395,  394,  393,  392,  391,  390,  389,\n",
      "         388,  387,  386,  385,  384,  383,  382,  381,  380,  379,  378,  377,\n",
      "         376,  375,  374,  373,  372,  371,  370,  369,  368,  367,  366,  365,\n",
      "         364,  363,  362,  361,  360,  359,  358,  357,  356,  355,  354,  353,\n",
      "         352,  351,  350,  349,  348,  347,  346,  345,  344,  343,  342,  341,\n",
      "         340,  339,  338,  337,  336,  335,  334,  333,  332,  331,  330,  329,\n",
      "         328,  327,  326,  325,  324,  323,  322,  321,  320,  319,  318,  317,\n",
      "         316,  315,  314,  313,  312,  311,  310,  309,  308,  307,  306,  305,\n",
      "         304,  303,  302,  301,  300,  299,  298,  297,  296,  295,  294,  293,\n",
      "         292,  291,  290,  289,  288,  287,  286,  285,  284,  283,  282,  281,\n",
      "         280,  279,  278,  277,  276,  275,  274,  273,  272,  271,  270,  269,\n",
      "         268,  267,  266,  265,  264,  263,  262,  261,  260,  259,  258,  257,\n",
      "         256,  255,  254,  253,  252,  251,  250,  249,  248,  247,  246,  245,\n",
      "         244,  243,  242,  241,  240,  239,  238,  237,  236,  235,  234,  233,\n",
      "         232,  231,  230,  229,  228,  227,  226,  225,  224,  223,  222,  221,\n",
      "         220,  219,  218,  217,  216,  215,  214,  213,  212,  211,  210,  209,\n",
      "         208,  207,  206,  205,  204,  203,  202,  201,  200,  199,  198,  197,\n",
      "         196,  195,  194,  193,  192,  191,  190,  189,  188,  187,  186,  185,\n",
      "         184,  183,  182,  181,  180,  179,  178,  177,  176,  175,  174,  173,\n",
      "         172,  171,  170,  169,  168,  167,  166,  165,  164,  163,  162,  161,\n",
      "         160,  159,  158,  157,  156,  155,  154,  153,  152,  151,  150,  149,\n",
      "         148,  147,  146,  145,  144,  143,  142,  141,  140,  139,  138,  137,\n",
      "         136,  135,  134,  133,  132,  131,  130,  129,  128,  127,  126,  125,\n",
      "         124,  123,  122,  121,  120,  119,  118,  117,  116,  115,  114,  113,\n",
      "         112,  111,  110,  109,  108,  107,  106,  105,  104,  103,  102,  101,\n",
      "         100,   99,   98,   97,   96,   95,   94,   93,   92,   91,   90,   89,\n",
      "          88,   87,   86,   85,   84,   83,   82,   81,   80,   79,   78,   77,\n",
      "          76,   75,   74,   73,   72,   71,   70,   69,   68,   67,   66,   65,\n",
      "          64,   63,   62,   61,   60,   59,   58,   57,   56,   55,   54,   53,\n",
      "          52,   51,   50,   49,   48,   47,   46,   45,   44,   43,   42,   41,\n",
      "          40,   39,   38,   37,   36,   35,   34,   33,   32,   31,   30,   29,\n",
      "          28,   27,   26,   25,   24,   23,   22,   21,   20,   19,   18,   17,\n",
      "          16,   15,   14,   13,   12,   11,   10,    9,    8,    7,    6,    5,\n",
      "           4,    3,    2,    1])\n",
      "n_at_risk shape torch.Size([1000])\n",
      "n_events shape torch.Size([1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.5122, dtype=torch.float64)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cind_loss_torch(y_torch, predictor_torch, sigma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
