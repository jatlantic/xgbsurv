{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgbsurv.models.utils import transform, transform_back\n",
    "from xgbsurv.models.eh_final import eh_likelihood, eh_gradient\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood, ah_objective\n",
    "from xgbsurv.models.eh_aft_final import aft_likelihood, aft_objective\n",
    "import sys\n",
    "sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import eh_likelihood_torch, eh_likelihood_torch_2, aft_likelihood_torch, ah_likelihood_torch\n",
    "import torch\n",
    "import math\n",
    "torch.set_printoptions(precision=10)\n",
    "from torch.autograd.functional import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data function\n",
    "\n",
    "def eh_data(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]]) #.reshape(1,10)\n",
    "        y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]], requires_grad=True)#.reshape(10,1)\n",
    "        y = torch.tensor([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]], dtype=torch.float32) #.reshape(10,1)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event\n",
    "\n",
    "def eh_data_2(type='np'):\n",
    "    #h2==0 scenario\n",
    "    if type=='np':\n",
    "        linear_predictor = np.array([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]]) #.reshape(1,10)\n",
    "        # attention reshape changes order in certain way\n",
    "        y = np.array([[1, 1],[ -3, -3],[-3,-3],[ -4,-4],[ -7,-7],[ 8,8],[ 9,9],[ -11,-11],[ 13,13],[ 16,16]],dtype=np.float32)\n",
    "        #y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],dtype=np.float32) #.reshape(1,10)\n",
    "        time = np.array([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = np.array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=np.float32)\n",
    "    if type=='torch':\n",
    "        linear_predictor = torch.tensor([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]], requires_grad=True)#.reshape(10,1)\n",
    "        y = torch.tensor([[1, 1],[ -3, -3],[-3,-3],[ -4,-4],[ -7,-7],[ 8,8],[ 9,9],[ -11,-11],[ 13,13],[ 16,16]],dtype=torch.float32).view(10,2)\n",
    "        time = torch.tensor([[ 1,  3,  3,  4,  7,  8,  9, 11, 13, 16]])\n",
    "        event = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 1, 1]],dtype=torch.float32).reshape(10,1)\n",
    "\n",
    "    return y, linear_predictor, time, event\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, linear_predictor, time, event = eh_data(type='torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "- Compare loss to original function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare loss to original function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_back_torch(y: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Transforms XGBoost digestable format variable y into time and event.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : npt.NDArray[float]\n",
    "        Array containing survival time and event where negative value is taken as censored event.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[npt.NDArray[float],npt.NDArray[int]]\n",
    "        Survival time and event.\n",
    "    \"\"\"\n",
    "    time = torch.abs(y)\n",
    "    event = (torch.abs(y) == y)\n",
    "    event = event # for numba\n",
    "    return time, event.float()\n",
    "\n",
    "def eaftloss(out, y): ##loss function for AFT or EH\n",
    "    time, delta = transform_back_torch(y)\n",
    "    ia, ib = out.size()\n",
    "    if ib == 1: ###loss function for AFT\n",
    "        n = len(delta)\n",
    "        print('aft')\n",
    "        h = 1.30*math.pow(n,-0.2)\n",
    "        #h 1.304058*math.pow(n,-0.2)  ## 1.304058*n^(-1/5) or 1.587401*math.pow(n,-0.333333) 1.587401*n^(-1/3)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(out,torch.log(time)) \n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones([1,n], dtype = out.dtype)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)     \n",
    "        A = torch.t(delta)*log_Dk/n   \n",
    "        S1 = A.sum()  \n",
    "        \n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0], dtype = out.dtype), torch.tensor([1.0], dtype = out.dtype)).cdf\n",
    "        P = ncdf(DR/h)\n",
    "        CDF_sum = torch.sum(P, dim=0)/n\n",
    "        Q = torch.log(CDF_sum)\n",
    "        S2 = -(delta*Q.view(n,1)).sum()/n\n",
    "             \n",
    "        S0 = -(delta*torch.log(time)).sum()/n\n",
    "        \n",
    "        S = S0 + S1 + S2 \n",
    "        S = -S\n",
    "    else: ### loss function for Extended hazard model\n",
    "        print('eh model')\n",
    "        print(y)\n",
    "        n = len(out[:,0])\n",
    "        h = 1.30*math.pow(n,-0.2)  ## or 1.59*n^(-1/3)\n",
    "        print('bandwidth', h)\n",
    "        time = time.view(n,1)\n",
    "        delta = delta.view(n,1)\n",
    "        g1 = out[:,0].view(n,1)\n",
    "        g2 = out[:,1].view(n,1)\n",
    "        \n",
    "        # R = g(Xi) + log(Oi)\n",
    "        R = torch.add(g1,torch.log(time)) \n",
    "        \n",
    "        S1 =  (delta*g2).sum()/n\n",
    "        S2 = -(delta*R).sum()/n\n",
    "        print('S1,S2', S1, S2)\n",
    "        \n",
    "        # Rj - Ri\n",
    "        rawones = torch.ones(1,n)\n",
    "        R1 = torch.mm(R,rawones)\n",
    "        R2 = torch.mm(torch.t(rawones),torch.t(R))\n",
    "        DR = R1 - R2 \n",
    "        \n",
    "        # K[(Rj-Ri)/h]\n",
    "        K = normal_density(DR/h)\n",
    "        Del = torch.mm(delta, rawones)\n",
    "        DelK = Del*K \n",
    "        \n",
    "        # (1/nh) *sum_j Deltaj * K[(Rj-Ri)/h]\n",
    "        Dk = torch.sum(DelK, dim=0)/(n*h)  ## Dk would be zero as learning rate too large!\n",
    "        \n",
    "        # log {(1/nh) * Deltaj * K[(Rj-Ri)/h]}    \n",
    "        log_Dk = torch.log(Dk)    \n",
    "        \n",
    "        S3 = (torch.t(delta)*log_Dk).sum()/n    \n",
    "        \n",
    "        # Phi((Rj-Ri)/h)\n",
    "        ncdf=torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0])).cdf\n",
    "        P = ncdf(DR/h) \n",
    "        L = torch.exp(g2-g1)\n",
    "        LL = torch.mm(L,rawones)\n",
    "        LP_sum = torch.sum(LL*P, dim=0)/n\n",
    "        Q = torch.log(LP_sum)\n",
    "        \n",
    "        S4 = -(delta*Q.view(n,1)).sum()/n\n",
    "        print(S1+ S2, S3, S4)\n",
    "        S = S1 + S2 + S3 + S4  \n",
    "        S = -S\n",
    "    return S\n",
    "\n",
    "def normal_density(a):  \n",
    "    b = 0.3989423*torch.exp(-0.5*torch.pow(a,2.0))\n",
    "    return b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EH Loss Original Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eh model\n",
      "tensor([[  1.,  -3.,  -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.]])\n",
      "bandwidth 0.8202445478242513\n",
      "S1,S2 tensor(0.0945473462, grad_fn=<DivBackward0>) tensor(-1.1996399164, grad_fn=<DivBackward0>)\n",
      "tensor(-1.1050925255, grad_fn=<AddBackward0>) tensor(-0.9911370277, grad_fn=<DivBackward0>) tensor(0.6148166060, grad_fn=<DivBackward0>)\n",
      "tensor(1.4814128876, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y, linear_predictor, time, event = eh_data(type='torch')\n",
    "aft_loss_paper = eaftloss(linear_predictor, y)\n",
    "print(aft_loss_paper ) #-1.1941503219595515"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EH Loss Pytorch Torch Version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check bandwidth, check dims vector for aft, go through code step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2]) torch.Size([10, 2])\n",
      "bandwidth tensor(0.8202445507)\n",
      "tensor(0.0945473462, grad_fn=<DivBackward0>) tensor(1.1996399164, grad_fn=<DivBackward0>) tensor(-0.9911370277, grad_fn=<DivBackward0>) tensor(-0.6148166656, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4814128876, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = eh_data_2(type='torch')\n",
    "print(linear_predictor.shape,y.shape)\n",
    "eh_loss_own_torch = eh_likelihood_torch_2(linear_predictor,y)\n",
    "eh_loss_own_torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EH Loss Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2) (10, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.48141275238739"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = eh_data_2(type='np')\n",
    "print(linear_predictor.shape,y.shape)\n",
    "eh_loss_own_numba = eh_likelihood(\n",
    "     y, linear_predictor\n",
    ")\n",
    "eh_loss_own_numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EH Loss Pytorch Numba Version - WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, linear_predictor, time, event = eh_data_2(type='torch')\n",
    "# print(linear_predictor.shape,y.shape)\n",
    "# eh_loss_own_torch_numba = eh_likelihood_torch(linear_predictor,y)\n",
    "# eh_loss_own_torch_numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(eh_loss_own_numba ,eh_loss_own_torch.detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EH Grad Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eh model\n",
      "tensor([[  1.,  -3.,  -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.]])\n",
      "bandwidth 0.8202445478242513\n",
      "S1,S2 tensor(0.0945473462, grad_fn=<DivBackward0>) tensor(-1.1996399164, grad_fn=<DivBackward0>)\n",
      "tensor(-1.1050925255, grad_fn=<AddBackward0>) tensor(-0.9911370277, grad_fn=<DivBackward0>) tensor(0.6148166060, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0281834509, -0.0957000479],\n",
       "        [ 0.0066343807,  0.0305879973],\n",
       "        [ 0.0060651265,  0.0306768492],\n",
       "        [ 0.0036482103,  0.0305661000],\n",
       "        [-0.0052330643,  0.0427651592],\n",
       "        [-0.0456178114, -0.0296885744],\n",
       "        [ 0.0081371665, -0.0313907117],\n",
       "        [-0.0278914571,  0.0571271330],\n",
       "        [-0.0044439435, -0.0231527984],\n",
       "        [ 0.0305179432, -0.0117911026]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = eh_data(type='torch')\n",
    "eh_loss_paper = eaftloss(linear_predictor, y)\n",
    "eh_loss_paper.backward()\n",
    "eh_grad_paper = linear_predictor.grad\n",
    "eh_grad_paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([-0.09570005,  0.030588  ,  0.03067684,  0.0305661 ,  0.04276516,\n",
    "       -0.02968857, -0.03139072,  0.05712713, -0.0231528 , -0.01179111])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Own Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, linear_predictor, time, event = eh_data_2(type='torch')\n",
    "# #linear_predictor, y  = linear_predictor.reshape(-1), y.reshape(-1)\n",
    "# ah_loss_own_torch = eh_likelihood_torch(linear_predictor,y)\n",
    "# print('loss', eh_loss_own_torch)\n",
    "# eh_loss_own_torch.backward()\n",
    "# print(linear_predictor.is_leaf)\n",
    "# #linear_predictor.retain_grad()\n",
    "# grad_torch = linear_predictor.grad\n",
    "# print('grad_torch', grad_torch.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02818345, -0.09570005],\n",
       "       [ 0.00663439,  0.030588  ],\n",
       "       [ 0.00606514,  0.03067684],\n",
       "       [ 0.00364822,  0.0305661 ],\n",
       "       [-0.00523305,  0.04276516],\n",
       "       [-0.04561782, -0.02968857],\n",
       "       [ 0.00813714, -0.03139072],\n",
       "       [-0.02789145,  0.05712713],\n",
       "       [-0.00444395, -0.0231528 ],\n",
       "       [ 0.03051793, -0.01179111]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = eh_data_2(type='np')\n",
    "grad_own = eh_gradient(\n",
    "    y, linear_predictor\n",
    ")\n",
    "grad_own"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(grad_own, eh_grad_paper)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ah_data_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m hessian \u001b[39mas\u001b[39;00m hess_torch\n\u001b[0;32m----> 2\u001b[0m y, linear_predictor, time, event \u001b[39m=\u001b[39m ah_data_2(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape, linear_predictor\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m hessian_matrix \u001b[39m=\u001b[39m hess_torch(ah_likelihood_torch, (linear_predictor, y), create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ah_data_2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.autograd.functional import hessian as hess_torch\n",
    "y, linear_predictor, time, event = ah_data_2(type='torch')\n",
    "print(y.shape, linear_predictor.shape)\n",
    "hessian_matrix = hess_torch(ah_likelihood_torch, (linear_predictor, y), create_graph=True)\n",
    "diag_hessian = hessian_matrix[0][0].diag()\n",
    "diag_hessian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1671356 , 0.09057899, 0.08653509, 0.10661001, 0.1241162 ,\n",
       "       0.18680498, 0.242457  , 0.08737591, 0.30874032, 0.27100193])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, linear_predictor, time, event = ah_data_2(type='np')\n",
    "grad_own, hess_own = ah_objective(\n",
    "    y, linear_predictor\n",
    ")\n",
    "hess_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
