{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgbsurv.models.eh_final import eh_likelihood, eh_gradient\n",
    "from xgbsurv.models.eh_ah_final import ah_likelihood\n",
    "import sys\n",
    "sys.path.append('/Users/JUSC/Documents/xgbsurv_benchmarking/deep_learning/')\n",
    "from loss_functions_pytorch import eh_likelihood_torch, eh_likelihood_torch_2, aft_likelihood_torch, ah_likelihood_torch\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare Pytorch loss with numpy loss\n",
    "\n",
    "- let's keep bandwidth fixed for that\n",
    "- random data\n",
    "\n",
    "linear_predictor = np.array([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]])\n",
    "\n",
    "y = np.array([1, -3, -3, -4, -7,  8,  9,  -11,  13,  16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mock data\n",
    "linear_predictor = np.array([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]])\n",
    "linear_predictor_torch = torch.from_numpy(linear_predictor)\n",
    "\n",
    "y = np.array([[1, -3, -3, -4, -7,  8,  9,  -11,  13,  16],\n",
    "              [1, -3, -3, -4, -7,  8,  9,  -11,  13,  16]]).reshape(10,2)\n",
    "y_torch = torch.from_numpy(y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = np.repeat(linear_predictor[:,0],2).reshape(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.597173328739984"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = eh_likelihood(y, linear_predictor)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1= eh_likelihood_torch(y_torch, linear_predictor_torch)\n",
    "#l1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isclose(l,l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eh_likelihood_torch_2(y_torch, linear_predictor_torch).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare Pytorch gradient with gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mock data\n",
    "linear_predictor_torch =  torch.tensor([[0.67254923, 0.03356795],\n",
    "       [0.86077982, 0.65922692],\n",
    "       [0.43557393, 0.75447972],\n",
    "       [0.94059047, 0.30572004],\n",
    "       [0.8446509 , 0.07916267],\n",
    "       [0.23657039, 0.44693716],\n",
    "       [0.74629685, 0.32637245],\n",
    "       [0.99700768, 0.10225456],\n",
    "       [0.28182768, 0.05405025],\n",
    "       [0.44495038, 0.08454563]], requires_grad=True)\n",
    "\n",
    "\n",
    "linear_predictor_torch =torch.tensor(np.repeat(linear_predictor[:,0],2).reshape(10,2), requires_grad=True)\n",
    "y_torch = torch.tensor([1., -3., -3., -4., -7.,  8.,  9.,  -11.,  13.,  16.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6725, 0.6725],\n",
       "        [0.8608, 0.8608],\n",
       "        [0.4356, 0.4356],\n",
       "        [0.9406, 0.9406],\n",
       "        [0.8447, 0.8447],\n",
       "        [0.2366, 0.2366],\n",
       "        [0.7463, 0.7463],\n",
       "        [0.9970, 0.9970],\n",
       "        [0.2818, 0.2818],\n",
       "        [0.4450, 0.4450]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predictor_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02967589 -0.09394635]\n",
      " [ 0.00416697  0.02602212]\n",
      " [ 0.00214852  0.01591823]\n",
      " [ 0.00302787  0.03937925]\n",
      " [-0.00916972  0.06180726]\n",
      " [-0.0424455  -0.06107999]\n",
      " [ 0.01515106 -0.03006867]\n",
      " [-0.04652952  0.09290624]\n",
      " [ 0.00476166 -0.03522046]\n",
      " [ 0.03921276 -0.01571763]]\n"
     ]
    }
   ],
   "source": [
    "l1= eh_likelihood_torch_2(linear_predictor_torch, y_torch)\n",
    "#l1.retain_grad()\n",
    "l1.backward()\n",
    "#print(linear_predictor_torch.grad)\n",
    "print(linear_predictor_torch.grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a1 \u001b[39m=\u001b[39m ah_likelihood_torch(linear_predictor_torch, y_torch)\n\u001b[1;32m      2\u001b[0m a1\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m      3\u001b[0m \u001b[39m#print(linear_predictor_torch.grad)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/xgbsurv_benchmarking/deep_learning/loss_functions_pytorch.py:445\u001b[0m, in \u001b[0;36mah_likelihood_torch\u001b[0;34m(linear_predictor, y_torch, sample_weight, bandwidth)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bandwidth:\n\u001b[1;32m    443\u001b[0m     bandwidth \u001b[39m=\u001b[39m \u001b[39m1.30\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mpow(n_samples, torch\u001b[39m.\u001b[39mtensor(\u001b[39m-\u001b[39m\u001b[39m0.2\u001b[39m))\n\u001b[1;32m    444\u001b[0m R_linear_predictor: torch\u001b[39m.\u001b[39mtensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(\n\u001b[0;32m--> 445\u001b[0m     time \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mexp(linear_predictor)\n\u001b[1;32m    446\u001b[0m )\n\u001b[1;32m    448\u001b[0m inverse_sample_size_bandwidth: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (n_samples \u001b[39m*\u001b[39m bandwidth)\n\u001b[1;32m    449\u001b[0m event_mask \u001b[39m=\u001b[39m event\u001b[39m.\u001b[39mbool()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a1 = ah_likelihood_torch(linear_predictor_torch, y_torch)\n",
    "a1.backward()\n",
    "#print(linear_predictor_torch.grad)\n",
    "print(linear_predictor_torch.grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15160797, -0.00500409, -0.003691  ,  0.18905714,  0.26316123,\n",
       "        0.05587306, -0.00582405, -0.01833184,  0.04190684,  0.15520722])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = np.array([[1., -3., -3., -4., -7.,  8.,  9.,  -11.,  13.,  16.],\n",
    "              [1., -3., -3., -4., -7.,  8.,  9.,  -11.,  13.,  16.]]).reshape(10,2)\n",
    "eh_gradient(y, np.array(linear_predictor)) #.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67254923, 0.67254923],\n",
       "       [0.86077982, 0.86077982],\n",
       "       [0.43557393, 0.43557393],\n",
       "       [0.94059047, 0.94059047],\n",
       "       [0.8446509 , 0.8446509 ],\n",
       "       [0.23657039, 0.23657039],\n",
       "       [0.74629685, 0.74629685],\n",
       "       [0.99700768, 0.99700768],\n",
       "       [0.28182768, 0.28182768],\n",
       "       [0.44495038, 0.44495038]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(linear_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,  -3.,  -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.,   1.,  -3.,\n",
       "         -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_torch.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,  -3.,  -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.,   1.,  -3.,\n",
       "         -3.,  -4.,  -7.,   8.,   9., -11.,  13.,  16.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_torch.tile(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m bandwidth \u001b[39m=\u001b[39m \u001b[39m1.30\u001b[39m \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mpow(n_samples, \u001b[39m-\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      4\u001b[0m linear_predictor_torch \u001b[39m=\u001b[39m linear_predictor_torch[:,\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m l1\u001b[39m=\u001b[39m aft_likelihood_torch(y_torch, linear_predictor_torch[:,\u001b[39m1\u001b[39;49m], sample_weight\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, bandwidth \u001b[39m=\u001b[39m bandwidth )\n\u001b[1;32m      6\u001b[0m l1\u001b[39m.\u001b[39mretain_grad()\n\u001b[1;32m      7\u001b[0m l1\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "import math\n",
    "n_samples: int = y.shape[0]\n",
    "bandwidth = 1.30 * math.pow(n_samples, -0.2)\n",
    "linear_predictor_torch = linear_predictor_torch[:,1]\n",
    "l1= aft_likelihood_torch(y_torch, linear_predictor_torch[:,1], sample_weight=1.0, bandwidth = bandwidth )\n",
    "l1.retain_grad()\n",
    "l1.backward()\n",
    "print(linear_predictor_torch.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgbsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
